{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed541fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1919ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_geohash</th>\n",
       "      <th>order_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_day</th>\n",
       "      <th>name</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>vendor_geohash</th>\n",
       "      <th>cuisine_origin</th>\n",
       "      <th>order_frequency</th>\n",
       "      <th>product_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>783e85338f1c</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>japanese garlic karaage don</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>084ab73246e6</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>chicken cutlet don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>30eba3cc2676</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>beef sukiyaki don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>3910309eea60</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>japanese beef yakiniku don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>20049fb602cb</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>teriyaki salmon don</td>\n",
       "      <td>8.0</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id customer_geohash  order_id vendor_id    product_id  day_of_week  \\\n",
       "0  1ba124d4e5            w21z7         0  212753d2  783e85338f1c            0   \n",
       "1  1ba124d4e5            w21z7         0  212753d2  084ab73246e6            0   \n",
       "2  1ba124d4e5            w21z7         0  212753d2  30eba3cc2676            0   \n",
       "3  1ba124d4e5            w21z7         0  212753d2  3910309eea60            0   \n",
       "4  1ba124d4e5            w21z7         0  212753d2  20049fb602cb            0   \n",
       "\n",
       "  order_time order_day                         name  unit_price  chain_id  \\\n",
       "0   12:03:29   85 days  japanese garlic karaage don         6.0  66c9978d   \n",
       "1   12:03:29   85 days           chicken cutlet don         6.8  66c9978d   \n",
       "2   12:03:29   85 days            beef sukiyaki don         6.8  66c9978d   \n",
       "3   12:03:29   85 days   japanese beef yakiniku don         6.8  66c9978d   \n",
       "4   12:03:29   85 days          teriyaki salmon don         8.0  66c9978d   \n",
       "\n",
       "  vendor_geohash cuisine_origin  order_frequency  product_rating  \n",
       "0          w21z7       japanese                1               4  \n",
       "1          w21z7       japanese                1               5  \n",
       "2          w21z7       japanese                1               3  \n",
       "3          w21z7       japanese                1               5  \n",
       "4          w21z7       japanese                1               5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/alnd/code/Alanoudis/food-delivery-rec/data/updated_data/full_data100k.csv\"\n",
    "full_data = pd.read_csv(file_path,index_col=0)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3823da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ab526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class AutomatedRecommendationSystem:\n",
    "    def __init__(self, data):\n",
    "        self.full_data = data\n",
    "        self.model = None\n",
    "        self.interaction_matrix = None\n",
    "        self.vendor_similarity = None\n",
    "        self.content_matrix = None\n",
    "        self.reverse_user_map = None\n",
    "        self.vendor_map = None\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    def prepare_data(self, data=None):\n",
    "        \"\"\"Prepare and preprocess the data\"\"\"\n",
    "        if data is None:\n",
    "            data = self.full_data\n",
    "\n",
    "        print(\"Preparing data...\")\n",
    "        df = data[['customer_id', 'vendor_id', 'order_frequency', 'product_rating']].copy()\n",
    "        df['score'] = df['order_frequency'] * df['product_rating']\n",
    "\n",
    "        # Encode users and vendors\n",
    "        df['user_code'] = df['customer_id'].astype('category').cat.codes\n",
    "        df['vendor_code'] = df['vendor_id'].astype('category').cat.codes\n",
    "\n",
    "        # Build interaction matrix\n",
    "        interaction_matrix = coo_matrix(\n",
    "            (df['score'], (df['user_code'], df['vendor_code']))\n",
    "        ).T.tocsr()\n",
    "\n",
    "        # Build lookup tables\n",
    "        user_map = dict(enumerate(df['customer_id'].astype('category').cat.categories))\n",
    "        vendor_map = dict(enumerate(df['vendor_id'].astype('category').cat.categories))\n",
    "        reverse_user_map = {v: k for k, v in user_map.items()}\n",
    "\n",
    "        print(f\"Data prepared: {len(user_map)} users, {len(vendor_map)} vendors\")\n",
    "        return df, interaction_matrix, user_map, vendor_map, reverse_user_map\n",
    "\n",
    "    def build_content_features(self, data=None):\n",
    "        \"\"\"Build vendor content-based features\"\"\"\n",
    "        if data is None:\n",
    "            data = self.full_data\n",
    "\n",
    "        print(\"Building content features...\")\n",
    "        vendor_features = data.groupby('vendor_id').agg({\n",
    "            'cuisine_origin': 'first',\n",
    "            'unit_price': 'mean',\n",
    "            'product_rating': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        # One-hot encode cuisine\n",
    "        cuisine_encoded = pd.get_dummies(vendor_features['cuisine_origin'])\n",
    "\n",
    "        # Normalize numerical features\n",
    "        vendor_features['unit_price_norm'] = (\n",
    "            vendor_features['unit_price'] - vendor_features['unit_price'].min()\n",
    "        ) / (vendor_features['unit_price'].max() - vendor_features['unit_price'].min())\n",
    "\n",
    "        vendor_features['product_rating_norm'] = (\n",
    "            vendor_features['product_rating'] - vendor_features['product_rating'].min()\n",
    "        ) / (vendor_features['product_rating'].max() - vendor_features['product_rating'].min())\n",
    "\n",
    "        # Combine all features\n",
    "        content_matrix = pd.concat([\n",
    "            cuisine_encoded,\n",
    "            vendor_features[['unit_price_norm', 'product_rating_norm']]\n",
    "        ], axis=1)\n",
    "        content_matrix.index = vendor_features['vendor_id']\n",
    "\n",
    "        # Compute vendor similarity\n",
    "        vendor_similarity = pd.DataFrame(\n",
    "            cosine_similarity(content_matrix),\n",
    "            index=content_matrix.index,\n",
    "            columns=content_matrix.index\n",
    "        )\n",
    "        print(\"Content features built successfully\")\n",
    "        return content_matrix, vendor_similarity\n",
    "\n",
    "    def train_als_model(self, interaction_matrix, factors=50, regularization=0.1, iterations=30):\n",
    "        \"\"\"Train the ALS model\"\"\"\n",
    "        print(\"Training ALS model...\")\n",
    "        model = AlternatingLeastSquares(\n",
    "            factors=factors,\n",
    "            regularization=regularization,\n",
    "            iterations=iterations,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(interaction_matrix.T)\n",
    "        print(\"ALS model trained successfully\")\n",
    "        return model\n",
    "\n",
    "    def split_train_test_data(self, test_ratio=0.2):\n",
    "        \"\"\"Split data into train and test sets for evaluation\"\"\"\n",
    "        print(\"Splitting data into train and test sets...\")\n",
    "\n",
    "        def split_user_data(df, test_ratio=0.2):\n",
    "            train_list, test_list = [], []\n",
    "            for user_id, user_df in df.groupby('customer_id'):\n",
    "                if len(user_df) < 2:  # Reduced minimum for more users in test\n",
    "                    continue\n",
    "                train, test = train_test_split(user_df, test_size=test_ratio, random_state=42)\n",
    "                train_list.append(train)\n",
    "                test_list.append(test)\n",
    "            return pd.concat(train_list), pd.concat(test_list)\n",
    "\n",
    "        self.train_data, self.test_data = split_user_data(self.full_data, test_ratio)\n",
    "        print(f\"Train data: {len(self.train_data)} records, {self.train_data['customer_id'].nunique()} users\")\n",
    "        print(f\"Test data: {len(self.test_data)} records, {self.test_data['customer_id'].nunique()} users\")\n",
    "        return self.train_data, self.test_data\n",
    "\n",
    "    # ==================== EVALUATION METRICS ====================\n",
    "\n",
    "    def precision_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate Precision@K\"\"\"\n",
    "        if len(recommended) == 0:\n",
    "            return 0.0\n",
    "        recommended_k = recommended[:k]\n",
    "        relevant = [1 if item in actual else 0 for item in recommended_k]\n",
    "        return sum(relevant) / len(recommended_k)\n",
    "\n",
    "    def ndcg_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate NDCG@K\"\"\"\n",
    "        if len(recommended) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        recommended_k = recommended[:k]\n",
    "        relevance = [1 if item in actual else 0 for item in recommended_k]\n",
    "\n",
    "        # Calculate DCG\n",
    "        dcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(relevance)])\n",
    "\n",
    "        # Calculate IDCG\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        idcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(ideal_relevance)])\n",
    "\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    def mrr_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate MRR@K\"\"\"\n",
    "        for idx, item in enumerate(recommended[:k]):\n",
    "            if item in actual:\n",
    "                return 1.0 / (idx + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def evaluate_metrics(self, N=10):\n",
    "        \"\"\"Evaluate all metrics on test data\"\"\"\n",
    "        print(f\"\\nüìä EVALUATING MODEL PERFORMANCE (N={N})\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if self.train_data is None or self.test_data is None:\n",
    "            print(\"Splitting data first...\")\n",
    "            self.split_train_test_data()\n",
    "\n",
    "        # Prepare training data for evaluation model\n",
    "        print(\"Training evaluation model on training data...\")\n",
    "        df_train, interaction_matrix_train, user_map_train, vendor_map_train, reverse_user_map_train = self.prepare_data(self.train_data)\n",
    "\n",
    "        # Train ALS model on training data\n",
    "        eval_model = self.train_als_model(interaction_matrix_train)\n",
    "\n",
    "        # Build content features on training data\n",
    "        content_matrix_train, vendor_similarity_train = self.build_content_features(self.train_data)\n",
    "\n",
    "        scores = []\n",
    "        test_users = self.test_data['customer_id'].unique()\n",
    "\n",
    "        print(f\"Evaluating on {len(test_users)} test users...\")\n",
    "\n",
    "        processed_count = 0\n",
    "        for user_id in test_users:\n",
    "            actual = self.test_data[self.test_data['customer_id'] == user_id]['vendor_id'].unique().tolist()\n",
    "\n",
    "            try:\n",
    "                # Skip if user not in training data\n",
    "                if user_id not in reverse_user_map_train:\n",
    "                    continue\n",
    "\n",
    "                # Get user index\n",
    "                user_idx = reverse_user_map_train[user_id]\n",
    "                user_items = interaction_matrix_train.T.tocsr()\n",
    "\n",
    "                # Get ALS recommendations\n",
    "                recommended = eval_model.recommend(user_idx, user_items[user_idx], N=N)\n",
    "                recommended_vendors = [vendor_map_train[int(i[0])] for i in recommended]\n",
    "\n",
    "                # Calculate metrics\n",
    "                prec = self.precision_at_k(recommended_vendors, actual, k=N)\n",
    "                ndcg = self.ndcg_at_k(recommended_vendors, actual, k=N)\n",
    "                mrr = self.mrr_at_k(recommended_vendors, actual, k=N)\n",
    "\n",
    "                scores.append((prec, ndcg, mrr))\n",
    "                processed_count += 1\n",
    "\n",
    "                if processed_count % 100 == 0:\n",
    "                    print(f\"Processed {processed_count}/{len(test_users)} users...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        if not scores:\n",
    "            print(\"‚ùå No valid scores computed! Check your data.\")\n",
    "            return None\n",
    "\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        results = {\n",
    "            'Precision@10': scores[:, 0].mean(),\n",
    "            'NDCG@10': scores[:, 1].mean(),\n",
    "            'MRR@10': scores[:, 2].mean(),\n",
    "            'Users_Evaluated': len(scores)\n",
    "        }\n",
    "\n",
    "        # Print results\n",
    "        print(\"\\nüìà EVALUATION RESULTS:\")\n",
    "        print(\"-\" * 40)\n",
    "        for metric, value in results.items():\n",
    "            if metric == 'Users_Evaluated':\n",
    "                print(f\"{metric}: {value}\")\n",
    "            else:\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_customer_order_history(self, customer_id):\n",
    "        \"\"\"Get detailed order history for a customer\"\"\"\n",
    "        customer_orders = self.full_data[self.full_data['customer_id'] == customer_id]\n",
    "\n",
    "        if customer_orders.empty:\n",
    "            return f\"No order history found for customer: {customer_id}\"\n",
    "\n",
    "        # Aggregate order history\n",
    "        order_summary = customer_orders.groupby('vendor_id').agg({\n",
    "            'name': 'first',\n",
    "            'cuisine_origin': 'first',\n",
    "            'order_frequency': 'sum',\n",
    "            'product_rating': 'mean',\n",
    "            'unit_price': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        return order_summary\n",
    "\n",
    "    def get_customer_taste_profile(self, customer_id):\n",
    "        \"\"\"Analyze customer taste preferences\"\"\"\n",
    "        customer_orders = self.full_data[self.full_data['customer_id'] == customer_id]\n",
    "\n",
    "        if customer_orders.empty:\n",
    "            return \"No taste profile available (new customer)\"\n",
    "\n",
    "        taste_profile = {\n",
    "            'total_orders': len(customer_orders),\n",
    "            'unique_vendors': customer_orders['vendor_id'].nunique(),\n",
    "            'preferred_cuisines': customer_orders['cuisine_origin'].value_counts().head(3).to_dict(),\n",
    "            'avg_rating_given': customer_orders['product_rating'].mean(),\n",
    "            'avg_spending': customer_orders['unit_price'].mean(),\n",
    "            'favorite_vendors': customer_orders.groupby('vendor_id')['order_frequency']\n",
    "                                                .sum().sort_values(ascending=False).head(3).to_dict()\n",
    "        }\n",
    "\n",
    "        return taste_profile\n",
    "\n",
    "    def recommend_vendors(self, customer_id, N=10):\n",
    "        \"\"\"Get ALS-based recommendations\"\"\"\n",
    "        if customer_id not in self.reverse_user_map:\n",
    "            return \"Cold-start user. Recommend popular restaurants.\"\n",
    "\n",
    "        user_idx = self.reverse_user_map[customer_id]\n",
    "        user_items = self.interaction_matrix.T.tocsr()\n",
    "\n",
    "        recommended = self.model.recommend(user_idx, user_items[user_idx], N=N)\n",
    "        recommended_vendors = [self.vendor_map[int(i[0])] for i in recommended]\n",
    "\n",
    "        return recommended_vendors\n",
    "\n",
    "    def hybrid_recommend(self, customer_id, N=10, als_weight=0.5, content_weight=0.5):\n",
    "        \"\"\"Get hybrid recommendations combining ALS and content-based\"\"\"\n",
    "        # Get user's ordered vendors from full data\n",
    "        user_vendors = self.full_data[self.full_data['customer_id'] == customer_id]['vendor_id'].unique()\n",
    "\n",
    "        if len(user_vendors) == 0:\n",
    "            return \"Cold-start user. Recommend popular restaurants.\"\n",
    "\n",
    "        # Content-based similarity scores\n",
    "        content_scores = self.vendor_similarity[user_vendors].mean(axis=1)\n",
    "        content_scores = content_scores.drop(user_vendors, errors='ignore')\n",
    "\n",
    "        # ALS recommendations\n",
    "        als_recs = self.recommend_vendors(customer_id, N=100)\n",
    "\n",
    "        if isinstance(als_recs, str):\n",
    "            return als_recs\n",
    "\n",
    "        als_scores = pd.Series([1 / (i + 1) for i in range(len(als_recs))], index=als_recs)\n",
    "\n",
    "        # Combine scores\n",
    "        hybrid_scores = pd.concat([als_scores, content_scores], axis=1).fillna(0)\n",
    "        hybrid_scores.columns = ['als', 'content']\n",
    "        hybrid_scores['hybrid'] = (als_weight * hybrid_scores['als'] +\n",
    "                                 content_weight * hybrid_scores['content'])\n",
    "\n",
    "        # Return top N\n",
    "        top_hybrid = hybrid_scores['hybrid'].sort_values(ascending=False).head(N).index.tolist()\n",
    "        return top_hybrid\n",
    "\n",
    "    def get_recommendation_details(self, vendor_ids):\n",
    "        \"\"\"Get detailed information about recommended vendors\"\"\"\n",
    "        if isinstance(vendor_ids, str):\n",
    "            return vendor_ids\n",
    "\n",
    "        vendor_details = self.full_data[self.full_data['vendor_id'].isin(vendor_ids)]\n",
    "\n",
    "        summary = vendor_details.groupby('vendor_id').agg({\n",
    "            'name': 'first',\n",
    "            'cuisine_origin': 'first',\n",
    "            'unit_price': 'mean',\n",
    "            'product_rating': 'mean',\n",
    "            'order_frequency': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def automated_customer_report(self, customer_id, N=10):\n",
    "        \"\"\"Generate complete automated report for a customer\"\"\"\n",
    "        print(f\"üîç CUSTOMER ANALYSIS REPORT: {customer_id}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # 1. Order History\n",
    "        print(\"\\nüìä ORDER HISTORY:\")\n",
    "        print(\"-\" * 30)\n",
    "        order_history = self.get_customer_order_history(customer_id)\n",
    "        if isinstance(order_history, pd.DataFrame):\n",
    "            print(order_history.to_string(index=False))\n",
    "        else:\n",
    "            print(order_history)\n",
    "\n",
    "        # 2. Taste Profile\n",
    "        print(\"\\nüë§ TASTE PROFILE:\")\n",
    "        print(\"-\" * 30)\n",
    "        taste_profile = self.get_customer_taste_profile(customer_id)\n",
    "        if isinstance(taste_profile, dict):\n",
    "            for key, value in taste_profile.items():\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "        else:\n",
    "            print(taste_profile)\n",
    "\n",
    "        # 3. Recommendations\n",
    "        print(f\"\\nüéØ HYBRID RECOMMENDATIONS (Top {N}):\")\n",
    "        print(\"-\" * 40)\n",
    "        recommendations = self.hybrid_recommend(customer_id, N=N)\n",
    "        rec_details = self.get_recommendation_details(recommendations)\n",
    "\n",
    "        if isinstance(rec_details, pd.DataFrame):\n",
    "            print(rec_details.to_string(index=False))\n",
    "        else:\n",
    "            print(rec_details)\n",
    "\n",
    "        return {\n",
    "            'customer_id': customer_id,\n",
    "            'order_history': order_history,\n",
    "            'taste_profile': taste_profile,\n",
    "            'recommendations': rec_details\n",
    "        }\n",
    "\n",
    "# ==================== FIXED MAIN FUNCTION ====================\n",
    "\n",
    "def main():\n",
    "    # Assuming full_data is your dataset\n",
    "    print(\"üöÄ INITIALIZING AUTOMATED RECOMMENDATION SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Initialize the system\n",
    "    recommender = AutomatedRecommendationSystem(full_data)\n",
    "\n",
    "    # Step 1: Prepare data and train main model\n",
    "    print(\"\\n1. üîÑ TRAINING MAIN MODEL...\")\n",
    "    df, interaction_matrix, user_map, vendor_map, reverse_user_map = recommender.prepare_data()\n",
    "    recommender.interaction_matrix = interaction_matrix\n",
    "    recommender.vendor_map = vendor_map\n",
    "    recommender.reverse_user_map = reverse_user_map\n",
    "\n",
    "    content_matrix, vendor_similarity = recommender.build_content_features()\n",
    "    recommender.content_matrix = content_matrix\n",
    "    recommender.vendor_similarity = vendor_similarity\n",
    "\n",
    "    recommender.model = recommender.train_als_model(interaction_matrix)\n",
    "\n",
    "    # Step 2: Evaluate model performance\n",
    "    print(\"\\n2. üìä EVALUATING MODEL PERFORMANCE...\")\n",
    "    evaluation_results = recommender.evaluate_metrics(N=10)\n",
    "\n",
    "    # Step 3: Generate customer reports\n",
    "    print(\"\\n3. üë• GENERATING CUSTOMER REPORTS...\")\n",
    "\n",
    "    # Test with specific customers or random ones\n",
    "    test_customers = [\"2e7276ad3a\", \"f374c8c54c\"]  # Replace with actual customer IDs\n",
    "\n",
    "    reports = {}\n",
    "    for customer_id in test_customers:\n",
    "        try:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            report = recommender.automated_customer_report(customer_id, N=10)\n",
    "            reports[customer_id] = report\n",
    "            print(f\"‚úÖ Report completed for {customer_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {customer_id}: {str(e)}\")\n",
    "\n",
    "    print(\"\\nüéâ ALL TASKS COMPLETED!\")\n",
    "    return recommender, reports, evaluation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the recommendation system...\n",
      "üöÄ INITIALIZING AUTOMATED RECOMMENDATION SYSTEM\n",
      "============================================================\n",
      "\n",
      "1. üîÑ TRAINING MAIN MODEL...\n",
      "Preparing data...\n",
      "Data prepared: 11174 users, 5818 vendors\n",
      "Building content features...\n",
      "Content features built successfully\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AutomatedRecommendationSystem.train_als_model() missing 1 required positional argument: 'interaction_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Run the complete system\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Run the complete system\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting the recommendation system...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m recommender_system, customer_reports, model_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Quick evaluation only (if you want to run just metrics)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mquick_evaluation\u001b[39m():\n",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m recommender\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[1;32m     14\u001b[0m recommender\u001b[38;5;241m.\u001b[39mbuild_content_features()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mrecommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_als_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Step 2: Evaluate model performance\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. üìä EVALUATING MODEL PERFORMANCE...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: AutomatedRecommendationSystem.train_als_model() missing 1 required positional argument: 'interaction_matrix'"
     ]
    }
   ],
   "source": [
    "# ==================== COMPLETE RUNNABLE CODE ====================\n",
    "\n",
    "def main():\n",
    "    # Assuming full_data is your dataset\n",
    "    print(\"üöÄ INITIALIZING AUTOMATED RECOMMENDATION SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Initialize the system\n",
    "    recommender = AutomatedRecommendationSystem(full_data)\n",
    "\n",
    "    # Step 1: Prepare data and train main model\n",
    "    print(\"\\n1. üîÑ TRAINING MAIN MODEL...\")\n",
    "    recommender.prepare_data()\n",
    "    recommender.build_content_features()\n",
    "    recommender.train_als_model()\n",
    "\n",
    "    # Step 2: Evaluate model performance\n",
    "    print(\"\\n2. üìä EVALUATING MODEL PERFORMANCE...\")\n",
    "    evaluation_results = recommender.evaluate_metrics(N=10)\n",
    "\n",
    "    # Step 3: Generate customer reports\n",
    "    print(\"\\n3. üë• GENERATING CUSTOMER REPORTS...\")\n",
    "\n",
    "    # Test with specific customers or random ones\n",
    "    test_customers = [\"2e7276ad3a\", \"f374c8c54c\"]  # Replace with actual customer IDs\n",
    "\n",
    "    reports = {}\n",
    "    for customer_id in test_customers:\n",
    "        try:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            report = recommender.automated_customer_report(customer_id, N=10)\n",
    "            reports[customer_id] = report\n",
    "            print(f\"‚úÖ Report completed for {customer_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {customer_id}: {str(e)}\")\n",
    "\n",
    "    print(\"\\nüéâ ALL TASKS COMPLETED!\")\n",
    "    return recommender, reports, evaluation_results\n",
    "\n",
    "# Run the complete system\n",
    "# Run the complete system\n",
    "print(\"Starting the recommendation system...\")\n",
    "recommender_system, customer_reports, model_metrics = main()\n",
    "\n",
    "# Quick evaluation only (if you want to run just metrics)\n",
    "def quick_evaluation():\n",
    "    \"\"\"Run just the evaluation metrics\"\"\"\n",
    "    print(\"üìä RUNNING QUICK MODEL EVALUATION...\")\n",
    "    recommender = AutomatedRecommendationSystem(full_data)\n",
    "    results = recommender.evaluate_metrics(N=10)\n",
    "    return results\n",
    "\n",
    "# Uncomment to run evaluation only:\n",
    "# eval_results = quick_evaluation()\n",
    "# print(\"\\nQuick Evaluation Results:\")\n",
    "# for metric, value in eval_results.items():\n",
    "#     print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the recommendation system...\n",
      "üöÄ INITIALIZING AUTOMATED RECOMMENDATION SYSTEM\n",
      "============================================================\n",
      "\n",
      "1. üîÑ TRAINING MAIN MODEL...\n",
      "Preparing data...\n",
      "Data prepared: 11174 users, 5818 vendors\n",
      "Building content features...\n",
      "Content features built successfully\n",
      "Training ALS model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alnd/.pyenv/versions/food-delivery-rec/lib/python3.10/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0028009414672851562 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4321b56410549aeb3a2a7ca091e7f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model trained successfully\n",
      "\n",
      "2. üìä EVALUATING MODEL PERFORMANCE...\n",
      "\n",
      "üìä EVALUATING MODEL PERFORMANCE (N=10)\n",
      "==================================================\n",
      "Splitting data first...\n",
      "Splitting data into train and test sets...\n",
      "Train data: 74671 records, 9306 users\n",
      "Test data: 23461 records, 9306 users\n",
      "Training evaluation model on training data...\n",
      "Preparing data...\n",
      "Data prepared: 9306 users, 5632 vendors\n",
      "Training ALS model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alnd/.pyenv/versions/food-delivery-rec/lib/python3.10/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0011942386627197266 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4fb5f94af746b9beb662b417db2c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model trained successfully\n",
      "Building content features...\n",
      "Content features built successfully\n",
      "Evaluating on 9306 test users...\n",
      "Processed 100/9306 users...\n",
      "Processed 200/9306 users...\n",
      "Processed 300/9306 users...\n",
      "Processed 400/9306 users...\n",
      "Processed 500/9306 users...\n",
      "Processed 600/9306 users...\n",
      "Processed 700/9306 users...\n",
      "Processed 800/9306 users...\n",
      "Processed 900/9306 users...\n",
      "Processed 1000/9306 users...\n",
      "Processed 1100/9306 users...\n",
      "Processed 1200/9306 users...\n",
      "Processed 1300/9306 users...\n",
      "Processed 1400/9306 users...\n",
      "Processed 1500/9306 users...\n",
      "Processed 1600/9306 users...\n",
      "Processed 1700/9306 users...\n",
      "Processed 1800/9306 users...\n",
      "Processed 1900/9306 users...\n",
      "Processed 2000/9306 users...\n",
      "Processed 2100/9306 users...\n",
      "Processed 2200/9306 users...\n",
      "Processed 2300/9306 users...\n",
      "Processed 2400/9306 users...\n",
      "Processed 2500/9306 users...\n",
      "Processed 2600/9306 users...\n",
      "Processed 2700/9306 users...\n",
      "Processed 2800/9306 users...\n",
      "Processed 2900/9306 users...\n",
      "Processed 3000/9306 users...\n",
      "Processed 3100/9306 users...\n",
      "Processed 3200/9306 users...\n",
      "Processed 3300/9306 users...\n",
      "Processed 3400/9306 users...\n",
      "Processed 3500/9306 users...\n",
      "Processed 3600/9306 users...\n",
      "Processed 3700/9306 users...\n",
      "Processed 3800/9306 users...\n",
      "Processed 3900/9306 users...\n",
      "Processed 4000/9306 users...\n",
      "Processed 4100/9306 users...\n",
      "Processed 4200/9306 users...\n",
      "Processed 4300/9306 users...\n",
      "Processed 4400/9306 users...\n",
      "Processed 4500/9306 users...\n",
      "Processed 4600/9306 users...\n",
      "Processed 4700/9306 users...\n",
      "Processed 4800/9306 users...\n",
      "Processed 4900/9306 users...\n",
      "Processed 5000/9306 users...\n",
      "Processed 5100/9306 users...\n",
      "Processed 5200/9306 users...\n",
      "Processed 5300/9306 users...\n",
      "Processed 5400/9306 users...\n",
      "Processed 5500/9306 users...\n",
      "Processed 5600/9306 users...\n",
      "Processed 5700/9306 users...\n",
      "Processed 5800/9306 users...\n",
      "Processed 5900/9306 users...\n",
      "Processed 6000/9306 users...\n",
      "Processed 6100/9306 users...\n",
      "Processed 6200/9306 users...\n",
      "Processed 6300/9306 users...\n",
      "Processed 6400/9306 users...\n",
      "Processed 6500/9306 users...\n",
      "Processed 6600/9306 users...\n",
      "Processed 6700/9306 users...\n",
      "Processed 6800/9306 users...\n",
      "Processed 6900/9306 users...\n",
      "Processed 7000/9306 users...\n",
      "Processed 7100/9306 users...\n",
      "Processed 7200/9306 users...\n",
      "Processed 7300/9306 users...\n",
      "Processed 7400/9306 users...\n",
      "Processed 7500/9306 users...\n",
      "Processed 7600/9306 users...\n",
      "Processed 7700/9306 users...\n",
      "Processed 7800/9306 users...\n",
      "Processed 7900/9306 users...\n",
      "Processed 8000/9306 users...\n",
      "Processed 8100/9306 users...\n",
      "Processed 8200/9306 users...\n",
      "Processed 8300/9306 users...\n",
      "Processed 8400/9306 users...\n",
      "Processed 8500/9306 users...\n",
      "Processed 8600/9306 users...\n",
      "Processed 8700/9306 users...\n",
      "Processed 8800/9306 users...\n",
      "Processed 8900/9306 users...\n",
      "Processed 9000/9306 users...\n",
      "Processed 9100/9306 users...\n",
      "Processed 9200/9306 users...\n",
      "Processed 9300/9306 users...\n",
      "\n",
      "üìà EVALUATION RESULTS:\n",
      "----------------------------------------\n",
      "Precision@10: 0.0010\n",
      "NDCG@10: 0.0019\n",
      "MRR@10: 0.0019\n",
      "Users_Evaluated: 9306\n",
      "\n",
      "3. üë• GENERATING CUSTOMER REPORTS...\n",
      "\n",
      "================================================================================\n",
      "üîç CUSTOMER ANALYSIS REPORT: 2e7276ad3a\n",
      "============================================================\n",
      "\n",
      "üìä ORDER HISTORY:\n",
      "------------------------------\n",
      "vendor_id                             name cuisine_origin  order_frequency  product_rating  unit_price\n",
      " 23c3cbb7                   chocolate pint         snacks               30        4.000000    5.600000\n",
      " 24f02f22            roasted herb potatoes        italian               30        4.000000    9.800000\n",
      " 2a89ea8c le parisien ham  butter baguette         snacks               15        4.000000    4.800000\n",
      " 31883abc           green curry mild spicy           thai               60        3.500000    5.100000\n",
      " 389d8451                             coke         snacks               15        3.000000    1.200000\n",
      " 3c8b6666                    fungi risotto        italian               45        2.666667    8.266667\n",
      " 42112a93                          brisket     vietnamese               30        3.500000    6.000000\n",
      " 54a7bf39                  five guys shake       american               30        4.000000    5.200000\n",
      " 573e52c0                    original king       japanese               15        4.000000    6.800000\n",
      " 642370bd                             coke         indian               90        4.166667    6.266667\n",
      " 921b38c7                    latte regular         snacks               45        4.666667    3.733333\n",
      " b62d39b7                          diavola        italian               45        4.333333   11.600000\n",
      " e33ad7ec                      house salad        italian               60        4.250000    9.500000\n",
      " ee4f2ee0               v beef noodle soup     vietnamese               60        3.250000    4.100000\n",
      "\n",
      "üë§ TASTE PROFILE:\n",
      "------------------------------\n",
      "Total Orders: 38\n",
      "Unique Vendors: 14\n",
      "Preferred Cuisines: {'italian': 12, 'snacks': 7, 'vietnamese': 6}\n",
      "Avg Rating Given: 3.8421052631578947\n",
      "Avg Spending: 6.557894736842105\n",
      "Favorite Vendors: {'642370bd': 90, '31883abc': 60, 'ee4f2ee0': 60}\n",
      "\n",
      "üéØ HYBRID RECOMMENDATIONS (Top 10):\n",
      "----------------------------------------\n",
      "vendor_id                                                    name cuisine_origin  unit_price  product_rating  order_frequency\n",
      " 0002b34d                                    back to basics vegan         snacks    4.666667        3.666667         7.666667\n",
      " 20fe964d                                                  box of         snacks   13.600000        5.000000         4.000000\n",
      " 2f8250d5 cd half roast chicken with mushroom cream sauce   sides         snacks    9.600000        5.000000         5.000000\n",
      " 3ce26d93                           d tbone steak with beef sauce         snacks   15.600000        5.000000        17.000000\n",
      " 626a8347        lychee rose cake petite  including  pcs macarons         snacks   17.200000        5.000000         1.000000\n",
      " 7544da62                         roasted brown bobo milkoriginal         snacks    3.095652        4.347826        21.695652\n",
      " 91e15661                                       guanaja cake size         snacks   18.400000        5.000000       348.000000\n",
      " b91af74d                                all chocolate cake  inch         snacks   14.400000        5.000000         9.000000\n",
      " d51de626                                             cups bundle         snacks    9.600000        5.000000        30.000000\n",
      " eb8a64eb                                  american cowboy burger         snacks   11.600000        5.000000        19.000000\n",
      "‚úÖ Report completed for 2e7276ad3a\n",
      "\n",
      "================================================================================\n",
      "üîç CUSTOMER ANALYSIS REPORT: f374c8c54c\n",
      "============================================================\n",
      "\n",
      "üìä ORDER HISTORY:\n",
      "------------------------------\n",
      "vendor_id                     name cuisine_origin  order_frequency  product_rating  unit_price\n",
      " 21830106 chicken cutlet with rice         snacks                8             3.5         2.4\n",
      "\n",
      "üë§ TASTE PROFILE:\n",
      "------------------------------\n",
      "Total Orders: 8\n",
      "Unique Vendors: 1\n",
      "Preferred Cuisines: {'snacks': 8}\n",
      "Avg Rating Given: 3.5\n",
      "Avg Spending: 2.4000000000000004\n",
      "Favorite Vendors: {'21830106': 8}\n",
      "\n",
      "üéØ HYBRID RECOMMENDATIONS (Top 10):\n",
      "----------------------------------------\n",
      "vendor_id                             name cuisine_origin  unit_price  product_rating  order_frequency\n",
      " 0002b34d             back to basics vegan         snacks    4.666667        3.666667         7.666667\n",
      " 16da9cef           jellicious cup ËúÇËúúÂØíÂ§©‰∏âÂêà‰∏Ä         snacks    2.226667        3.633333         6.766667\n",
      " 5350877d            pearly soya milk cold         snacks    2.176471        3.558824         9.764706\n",
      " 71eb9456  lemon chicken cutlet rice Êü†Ê™¨È∏°ÊâíÈ•≠         snacks    2.400000        3.629630        11.259259\n",
      " 77b12c68 mee hoon   vegetables  mock meat         snacks    2.505263        3.631579        13.105263\n",
      " 8c2a52d3        nine fresh signature ‰πùÈ≤úÊãõÁâå         snacks    2.195556        3.644444         5.466667\n",
      " 9fcb02cb                       milo stylo         snacks    2.257143        3.642857         8.000000\n",
      " c0a1e3ac                damascus rose tea         snacks    2.312500        3.656250        11.593750\n",
      " edf9272e         storeselected half dozen         snacks    2.448485        3.636364        11.060606\n",
      " f4c98b0e             roasted chicken rice         snacks    2.400000        3.619048        15.190476\n",
      "‚úÖ Report completed for f374c8c54c\n",
      "\n",
      "üéâ ALL TASKS COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class AutomatedRecommendationSystem:\n",
    "    def __init__(self, data):\n",
    "        self.full_data = data\n",
    "        self.model = None\n",
    "        self.interaction_matrix = None\n",
    "        self.vendor_similarity = None\n",
    "        self.content_matrix = None\n",
    "        self.reverse_user_map = None\n",
    "        self.vendor_map = None\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    def prepare_data(self, data=None):\n",
    "        \"\"\"Prepare and preprocess the data\"\"\"\n",
    "        if data is None:\n",
    "            data = self.full_data\n",
    "\n",
    "        print(\"Preparing data...\")\n",
    "        df = data[['customer_id', 'vendor_id', 'order_frequency', 'product_rating']].copy()\n",
    "        df['score'] = df['order_frequency'] * df['product_rating']\n",
    "\n",
    "        # Encode users and vendors\n",
    "        df['user_code'] = df['customer_id'].astype('category').cat.codes\n",
    "        df['vendor_code'] = df['vendor_id'].astype('category').cat.codes\n",
    "\n",
    "        # Build interaction matrix\n",
    "        interaction_matrix = coo_matrix(\n",
    "            (df['score'], (df['user_code'], df['vendor_code']))\n",
    "        ).T.tocsr()\n",
    "\n",
    "        # Build lookup tables\n",
    "        user_map = dict(enumerate(df['customer_id'].astype('category').cat.categories))\n",
    "        vendor_map = dict(enumerate(df['vendor_id'].astype('category').cat.categories))\n",
    "        reverse_user_map = {v: k for k, v in user_map.items()}\n",
    "\n",
    "        print(f\"Data prepared: {len(user_map)} users, {len(vendor_map)} vendors\")\n",
    "        return df, interaction_matrix, user_map, vendor_map, reverse_user_map\n",
    "\n",
    "    def build_content_features(self, data=None):\n",
    "        \"\"\"Build vendor content-based features\"\"\"\n",
    "        if data is None:\n",
    "            data = self.full_data\n",
    "\n",
    "        print(\"Building content features...\")\n",
    "        vendor_features = data.groupby('vendor_id').agg({\n",
    "            'cuisine_origin': 'first',\n",
    "            'unit_price': 'mean',\n",
    "            'product_rating': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        # One-hot encode cuisine\n",
    "        cuisine_encoded = pd.get_dummies(vendor_features['cuisine_origin'])\n",
    "\n",
    "        # Normalize numerical features\n",
    "        vendor_features['unit_price_norm'] = (\n",
    "            vendor_features['unit_price'] - vendor_features['unit_price'].min()\n",
    "        ) / (vendor_features['unit_price'].max() - vendor_features['unit_price'].min())\n",
    "\n",
    "        vendor_features['product_rating_norm'] = (\n",
    "            vendor_features['product_rating'] - vendor_features['product_rating'].min()\n",
    "        ) / (vendor_features['product_rating'].max() - vendor_features['product_rating'].min())\n",
    "\n",
    "        # Combine all features\n",
    "        content_matrix = pd.concat([\n",
    "            cuisine_encoded,\n",
    "            vendor_features[['unit_price_norm', 'product_rating_norm']]\n",
    "        ], axis=1)\n",
    "        content_matrix.index = vendor_features['vendor_id']\n",
    "\n",
    "        # Compute vendor similarity\n",
    "        vendor_similarity = pd.DataFrame(\n",
    "            cosine_similarity(content_matrix),\n",
    "            index=content_matrix.index,\n",
    "            columns=content_matrix.index\n",
    "        )\n",
    "        print(\"Content features built successfully\")\n",
    "        return content_matrix, vendor_similarity\n",
    "\n",
    "    def train_als_model(self, interaction_matrix, factors=50, regularization=0.1, iterations=30):\n",
    "        \"\"\"Train the ALS model\"\"\"\n",
    "        print(\"Training ALS model...\")\n",
    "        model = AlternatingLeastSquares(\n",
    "            factors=factors,\n",
    "            regularization=regularization,\n",
    "            iterations=iterations,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(interaction_matrix.T)\n",
    "        print(\"ALS model trained successfully\")\n",
    "        return model\n",
    "\n",
    "    def split_train_test_data(self, test_ratio=0.2):\n",
    "        \"\"\"Split data into train and test sets for evaluation\"\"\"\n",
    "        print(\"Splitting data into train and test sets...\")\n",
    "\n",
    "        def split_user_data(df, test_ratio=0.2):\n",
    "            train_list, test_list = [], []\n",
    "            for user_id, user_df in df.groupby('customer_id'):\n",
    "                if len(user_df) < 2:  # Reduced minimum for more users in test\n",
    "                    continue\n",
    "                train, test = train_test_split(user_df, test_size=test_ratio, random_state=42)\n",
    "                train_list.append(train)\n",
    "                test_list.append(test)\n",
    "            return pd.concat(train_list), pd.concat(test_list)\n",
    "\n",
    "        self.train_data, self.test_data = split_user_data(self.full_data, test_ratio)\n",
    "        print(f\"Train data: {len(self.train_data)} records, {self.train_data['customer_id'].nunique()} users\")\n",
    "        print(f\"Test data: {len(self.test_data)} records, {self.test_data['customer_id'].nunique()} users\")\n",
    "        return self.train_data, self.test_data\n",
    "\n",
    "    # ==================== EVALUATION METRICS ====================\n",
    "\n",
    "    def precision_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate Precision@K\"\"\"\n",
    "        if len(recommended) == 0:\n",
    "            return 0.0\n",
    "        recommended_k = recommended[:k]\n",
    "        relevant = [1 if item in actual else 0 for item in recommended_k]\n",
    "        return sum(relevant) / len(recommended_k)\n",
    "\n",
    "    def ndcg_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate NDCG@K\"\"\"\n",
    "        if len(recommended) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        recommended_k = recommended[:k]\n",
    "        relevance = [1 if item in actual else 0 for item in recommended_k]\n",
    "\n",
    "        # Calculate DCG\n",
    "        dcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(relevance)])\n",
    "\n",
    "        # Calculate IDCG\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        idcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(ideal_relevance)])\n",
    "\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    def mrr_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate MRR@K\"\"\"\n",
    "        for idx, item in enumerate(recommended[:k]):\n",
    "            if item in actual:\n",
    "                return 1.0 / (idx + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def evaluate_metrics(self, N=10):\n",
    "        \"\"\"Evaluate all metrics on test data\"\"\"\n",
    "        print(f\"\\nüìä EVALUATING MODEL PERFORMANCE (N={N})\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if self.train_data is None or self.test_data is None:\n",
    "            print(\"Splitting data first...\")\n",
    "            self.split_train_test_data()\n",
    "\n",
    "        # Prepare training data for evaluation model\n",
    "        print(\"Training evaluation model on training data...\")\n",
    "        df_train, interaction_matrix_train, user_map_train, vendor_map_train, reverse_user_map_train = self.prepare_data(self.train_data)\n",
    "\n",
    "        # Train ALS model on training data\n",
    "        eval_model = self.train_als_model(interaction_matrix_train)\n",
    "\n",
    "        # Build content features on training data\n",
    "        content_matrix_train, vendor_similarity_train = self.build_content_features(self.train_data)\n",
    "\n",
    "        scores = []\n",
    "        test_users = self.test_data['customer_id'].unique()\n",
    "\n",
    "        print(f\"Evaluating on {len(test_users)} test users...\")\n",
    "\n",
    "        processed_count = 0\n",
    "        for user_id in test_users:\n",
    "            actual = self.test_data[self.test_data['customer_id'] == user_id]['vendor_id'].unique().tolist()\n",
    "\n",
    "            try:\n",
    "                # Skip if user not in training data\n",
    "                if user_id not in reverse_user_map_train:\n",
    "                    continue\n",
    "\n",
    "                # Get user index\n",
    "                user_idx = reverse_user_map_train[user_id]\n",
    "                user_items = interaction_matrix_train.T.tocsr()\n",
    "\n",
    "                # Get ALS recommendations\n",
    "                recommended = eval_model.recommend(user_idx, user_items[user_idx], N=N)\n",
    "                recommended_vendors = [vendor_map_train[int(i[0])] for i in recommended]\n",
    "\n",
    "                # Calculate metrics\n",
    "                prec = self.precision_at_k(recommended_vendors, actual, k=N)\n",
    "                ndcg = self.ndcg_at_k(recommended_vendors, actual, k=N)\n",
    "                mrr = self.mrr_at_k(recommended_vendors, actual, k=N)\n",
    "\n",
    "                scores.append((prec, ndcg, mrr))\n",
    "                processed_count += 1\n",
    "\n",
    "                if processed_count % 100 == 0:\n",
    "                    print(f\"Processed {processed_count}/{len(test_users)} users...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        if not scores:\n",
    "            print(\"‚ùå No valid scores computed! Check your data.\")\n",
    "            return None\n",
    "\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        results = {\n",
    "            'Precision@10': scores[:, 0].mean(),\n",
    "            'NDCG@10': scores[:, 1].mean(),\n",
    "            'MRR@10': scores[:, 2].mean(),\n",
    "            'Users_Evaluated': len(scores)\n",
    "        }\n",
    "\n",
    "        # Print results\n",
    "        print(\"\\nüìà EVALUATION RESULTS:\")\n",
    "        print(\"-\" * 40)\n",
    "        for metric, value in results.items():\n",
    "            if metric == 'Users_Evaluated':\n",
    "                print(f\"{metric}: {value}\")\n",
    "            else:\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_customer_order_history(self, customer_id):\n",
    "        \"\"\"Get detailed order history for a customer\"\"\"\n",
    "        customer_orders = self.full_data[self.full_data['customer_id'] == customer_id]\n",
    "\n",
    "        if customer_orders.empty:\n",
    "            return f\"No order history found for customer: {customer_id}\"\n",
    "\n",
    "        # Aggregate order history\n",
    "        order_summary = customer_orders.groupby('vendor_id').agg({\n",
    "            'name': 'first',\n",
    "            'cuisine_origin': 'first',\n",
    "            'order_frequency': 'sum',\n",
    "            'product_rating': 'mean',\n",
    "            'unit_price': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        return order_summary\n",
    "\n",
    "    def get_customer_taste_profile(self, customer_id):\n",
    "        \"\"\"Analyze customer taste preferences\"\"\"\n",
    "        customer_orders = self.full_data[self.full_data['customer_id'] == customer_id]\n",
    "\n",
    "        if customer_orders.empty:\n",
    "            return \"No taste profile available (new customer)\"\n",
    "\n",
    "        taste_profile = {\n",
    "            'total_orders': len(customer_orders),\n",
    "            'unique_vendors': customer_orders['vendor_id'].nunique(),\n",
    "            'preferred_cuisines': customer_orders['cuisine_origin'].value_counts().head(3).to_dict(),\n",
    "            'avg_rating_given': customer_orders['product_rating'].mean(),\n",
    "            'avg_spending': customer_orders['unit_price'].mean(),\n",
    "            'favorite_vendors': customer_orders.groupby('vendor_id')['order_frequency']\n",
    "                                                .sum().sort_values(ascending=False).head(3).to_dict()\n",
    "        }\n",
    "\n",
    "        return taste_profile\n",
    "\n",
    "    def recommend_vendors(self, customer_id, N=10):\n",
    "        \"\"\"Get ALS-based recommendations\"\"\"\n",
    "        if customer_id not in self.reverse_user_map:\n",
    "            return \"Cold-start user. Recommend popular restaurants.\"\n",
    "\n",
    "        user_idx = self.reverse_user_map[customer_id]\n",
    "        user_items = self.interaction_matrix.T.tocsr()\n",
    "\n",
    "        recommended = self.model.recommend(user_idx, user_items[user_idx], N=N)\n",
    "        recommended_vendors = [self.vendor_map[int(i[0])] for i in recommended]\n",
    "\n",
    "        return recommended_vendors\n",
    "\n",
    "    def hybrid_recommend(self, customer_id, N=10, als_weight=0.5, content_weight=0.5):\n",
    "        \"\"\"Get hybrid recommendations combining ALS and content-based\"\"\"\n",
    "        # Get user's ordered vendors from full data\n",
    "        user_vendors = self.full_data[self.full_data['customer_id'] == customer_id]['vendor_id'].unique()\n",
    "\n",
    "        if len(user_vendors) == 0:\n",
    "            return \"Cold-start user. Recommend popular restaurants.\"\n",
    "\n",
    "        # Content-based similarity scores\n",
    "        content_scores = self.vendor_similarity[user_vendors].mean(axis=1)\n",
    "        content_scores = content_scores.drop(user_vendors, errors='ignore')\n",
    "\n",
    "        # ALS recommendations\n",
    "        als_recs = self.recommend_vendors(customer_id, N=100)\n",
    "\n",
    "        if isinstance(als_recs, str):\n",
    "            return als_recs\n",
    "\n",
    "        als_scores = pd.Series([1 / (i + 1) for i in range(len(als_recs))], index=als_recs)\n",
    "\n",
    "        # Combine scores\n",
    "        hybrid_scores = pd.concat([als_scores, content_scores], axis=1).fillna(0)\n",
    "        hybrid_scores.columns = ['als', 'content']\n",
    "        hybrid_scores['hybrid'] = (als_weight * hybrid_scores['als'] +\n",
    "                                 content_weight * hybrid_scores['content'])\n",
    "\n",
    "        # Return top N\n",
    "        top_hybrid = hybrid_scores['hybrid'].sort_values(ascending=False).head(N).index.tolist()\n",
    "        return top_hybrid\n",
    "\n",
    "    def get_recommendation_details(self, vendor_ids):\n",
    "        \"\"\"Get detailed information about recommended vendors\"\"\"\n",
    "        if isinstance(vendor_ids, str):\n",
    "            return vendor_ids\n",
    "\n",
    "        vendor_details = self.full_data[self.full_data['vendor_id'].isin(vendor_ids)]\n",
    "\n",
    "        summary = vendor_details.groupby('vendor_id').agg({\n",
    "            'name': 'first',\n",
    "            'cuisine_origin': 'first',\n",
    "            'unit_price': 'mean',\n",
    "            'product_rating': 'mean',\n",
    "            'order_frequency': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def automated_customer_report(self, customer_id, N=10):\n",
    "        \"\"\"Generate complete automated report for a customer\"\"\"\n",
    "        print(f\"üîç CUSTOMER ANALYSIS REPORT: {customer_id}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # 1. Order History\n",
    "        print(\"\\nüìä ORDER HISTORY:\")\n",
    "        print(\"-\" * 30)\n",
    "        order_history = self.get_customer_order_history(customer_id)\n",
    "        if isinstance(order_history, pd.DataFrame):\n",
    "            print(order_history.to_string(index=False))\n",
    "        else:\n",
    "            print(order_history)\n",
    "\n",
    "        # 2. Taste Profile\n",
    "        print(\"\\nüë§ TASTE PROFILE:\")\n",
    "        print(\"-\" * 30)\n",
    "        taste_profile = self.get_customer_taste_profile(customer_id)\n",
    "        if isinstance(taste_profile, dict):\n",
    "            for key, value in taste_profile.items():\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "        else:\n",
    "            print(taste_profile)\n",
    "\n",
    "        # 3. Recommendations\n",
    "        print(f\"\\nüéØ HYBRID RECOMMENDATIONS (Top {N}):\")\n",
    "        print(\"-\" * 40)\n",
    "        recommendations = self.hybrid_recommend(customer_id, N=N)\n",
    "        rec_details = self.get_recommendation_details(recommendations)\n",
    "\n",
    "        if isinstance(rec_details, pd.DataFrame):\n",
    "            print(rec_details.to_string(index=False))\n",
    "        else:\n",
    "            print(rec_details)\n",
    "\n",
    "        return {\n",
    "            'customer_id': customer_id,\n",
    "            'order_history': order_history,\n",
    "            'taste_profile': taste_profile,\n",
    "            'recommendations': rec_details\n",
    "        }\n",
    "\n",
    "# ==================== FIXED MAIN FUNCTION ====================\n",
    "\n",
    "def main():\n",
    "    # Assuming full_data is your dataset\n",
    "    print(\"üöÄ INITIALIZING AUTOMATED RECOMMENDATION SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Initialize the system\n",
    "    recommender = AutomatedRecommendationSystem(full_data)\n",
    "\n",
    "    # Step 1: Prepare data and train main model\n",
    "    print(\"\\n1. üîÑ TRAINING MAIN MODEL...\")\n",
    "    df, interaction_matrix, user_map, vendor_map, reverse_user_map = recommender.prepare_data()\n",
    "    recommender.interaction_matrix = interaction_matrix\n",
    "    recommender.vendor_map = vendor_map\n",
    "    recommender.reverse_user_map = reverse_user_map\n",
    "\n",
    "    content_matrix, vendor_similarity = recommender.build_content_features()\n",
    "    recommender.content_matrix = content_matrix\n",
    "    recommender.vendor_similarity = vendor_similarity\n",
    "\n",
    "    recommender.model = recommender.train_als_model(interaction_matrix)\n",
    "\n",
    "    # Step 2: Evaluate model performance\n",
    "    print(\"\\n2. üìä EVALUATING MODEL PERFORMANCE...\")\n",
    "    evaluation_results = recommender.evaluate_metrics(N=10)\n",
    "\n",
    "    # Step 3: Generate customer reports\n",
    "    print(\"\\n3. üë• GENERATING CUSTOMER REPORTS...\")\n",
    "\n",
    "    # Test with specific customers or random ones\n",
    "    test_customers = [\"2e7276ad3a\", \"f374c8c54c\"]  # Replace with actual customer IDs\n",
    "\n",
    "    reports = {}\n",
    "    for customer_id in test_customers:\n",
    "        try:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            report = recommender.automated_customer_report(customer_id, N=10)\n",
    "            reports[customer_id] = report\n",
    "            print(f\"‚úÖ Report completed for {customer_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {customer_id}: {str(e)}\")\n",
    "\n",
    "    print(\"\\nüéâ ALL TASKS COMPLETED!\")\n",
    "    return recommender, reports, evaluation_results\n",
    "\n",
    "# Run the complete system\n",
    "print(\"Starting the recommendation system...\")\n",
    "recommender_system, customer_reports, model_metrics = main()\n",
    "\n",
    "# Quick evaluation only (if you want to run just metrics)\n",
    "def quick_evaluation():\n",
    "    \"\"\"Run just the evaluation metrics\"\"\"\n",
    "    print(\"üìä RUNNING QUICK MODEL EVALUATION...\")\n",
    "    recommender = AutomatedRecommendationSystem(full_data)\n",
    "    results = recommender.evaluate_metrics(N=10)\n",
    "    return results\n",
    "\n",
    "# Uncomment to run evaluation only:\n",
    "# eval_results = quick_evaluation()\n",
    "# print(\"\\nQuick Evaluation Results:\")\n",
    "# for metric, value in eval_results.items():\n",
    "#     print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f6d8b",
   "metadata": {},
   "source": [
    "# NEW CODE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd891c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training and evaluation...\n",
      "üöÄ MODEL TRAINING AND EVALUATION\n",
      "==================================================\n",
      "üìä EVALUATING MODEL PERFORMANCE (N=10)\n",
      "==================================================\n",
      "Splitting data into train and test sets...\n",
      "Train data: 74671 records, 9306 users\n",
      "Test data: 23461 records, 9306 users\n",
      "Training evaluation model on training data...\n",
      "Preparing data...\n",
      "Data prepared: 9306 users, 5632 vendors\n",
      "Training ALS model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alnd/.pyenv/versions/food-delivery-rec/lib/python3.10/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.00037407875061035156 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c65bac55de140c4bc57ae18921af871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model trained successfully\n",
      "Evaluating on 9306 test users...\n",
      "Processed 100/9306 users...\n",
      "Processed 200/9306 users...\n",
      "Processed 300/9306 users...\n",
      "Processed 400/9306 users...\n",
      "Processed 500/9306 users...\n",
      "Processed 600/9306 users...\n",
      "Processed 700/9306 users...\n",
      "Processed 800/9306 users...\n",
      "Processed 900/9306 users...\n",
      "Processed 1000/9306 users...\n",
      "Processed 1100/9306 users...\n",
      "Processed 1200/9306 users...\n",
      "Processed 1300/9306 users...\n",
      "Processed 1400/9306 users...\n",
      "Processed 1500/9306 users...\n",
      "Processed 1600/9306 users...\n",
      "Processed 1700/9306 users...\n",
      "Processed 1800/9306 users...\n",
      "Processed 1900/9306 users...\n",
      "Processed 2000/9306 users...\n",
      "Processed 2100/9306 users...\n",
      "Processed 2200/9306 users...\n",
      "Processed 2300/9306 users...\n",
      "Processed 2400/9306 users...\n",
      "Processed 2500/9306 users...\n",
      "Processed 2600/9306 users...\n",
      "Processed 2700/9306 users...\n",
      "Processed 2800/9306 users...\n",
      "Processed 2900/9306 users...\n",
      "Processed 3000/9306 users...\n",
      "Processed 3100/9306 users...\n",
      "Processed 3200/9306 users...\n",
      "Processed 3300/9306 users...\n",
      "Processed 3400/9306 users...\n",
      "Processed 3500/9306 users...\n",
      "Processed 3600/9306 users...\n",
      "Processed 3700/9306 users...\n",
      "Processed 3800/9306 users...\n",
      "Processed 3900/9306 users...\n",
      "Processed 4000/9306 users...\n",
      "Processed 4100/9306 users...\n",
      "Processed 4200/9306 users...\n",
      "Processed 4300/9306 users...\n",
      "Processed 4400/9306 users...\n",
      "Processed 4500/9306 users...\n",
      "Processed 4600/9306 users...\n",
      "Processed 4700/9306 users...\n",
      "Processed 4800/9306 users...\n",
      "Processed 4900/9306 users...\n",
      "Processed 5000/9306 users...\n",
      "Processed 5100/9306 users...\n",
      "Processed 5200/9306 users...\n",
      "Processed 5300/9306 users...\n",
      "Processed 5400/9306 users...\n",
      "Processed 5500/9306 users...\n",
      "Processed 5600/9306 users...\n",
      "Processed 5700/9306 users...\n",
      "Processed 5800/9306 users...\n",
      "Processed 5900/9306 users...\n",
      "Processed 6000/9306 users...\n",
      "Processed 6100/9306 users...\n",
      "Processed 6200/9306 users...\n",
      "Processed 6300/9306 users...\n",
      "Processed 6400/9306 users...\n",
      "Processed 6500/9306 users...\n",
      "Processed 6600/9306 users...\n",
      "Processed 6700/9306 users...\n",
      "Processed 6800/9306 users...\n",
      "Processed 6900/9306 users...\n",
      "Processed 7000/9306 users...\n",
      "Processed 7100/9306 users...\n",
      "Processed 7200/9306 users...\n",
      "Processed 7300/9306 users...\n",
      "Processed 7400/9306 users...\n",
      "Processed 7500/9306 users...\n",
      "Processed 7600/9306 users...\n",
      "Processed 7700/9306 users...\n",
      "Processed 7800/9306 users...\n",
      "Processed 7900/9306 users...\n",
      "Processed 8000/9306 users...\n",
      "Processed 8100/9306 users...\n",
      "Processed 8200/9306 users...\n",
      "Processed 8300/9306 users...\n",
      "Processed 8400/9306 users...\n",
      "Processed 8500/9306 users...\n",
      "Processed 8600/9306 users...\n",
      "Processed 8700/9306 users...\n",
      "Processed 8800/9306 users...\n",
      "Processed 8900/9306 users...\n",
      "Processed 9000/9306 users...\n",
      "Processed 9100/9306 users...\n",
      "Processed 9200/9306 users...\n",
      "Processed 9300/9306 users...\n",
      "\n",
      "üìà EVALUATION RESULTS:\n",
      "----------------------------------------\n",
      "Precision@10: 0.0010\n",
      "NDCG@10: 0.0019\n",
      "MRR@10: 0.0019\n",
      "Users_Evaluated: 9306\n",
      "\n",
      "üîß TRAINING FINAL PRODUCTION MODEL...\n",
      "Preparing data...\n",
      "Data prepared: 11174 users, 5818 vendors\n",
      "Building content features...\n",
      "Content features built successfully\n",
      "Training ALS model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alnd/.pyenv/versions/food-delivery-rec/lib/python3.10/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0005524158477783203 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aebf512de594735a046a45906fc45fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model trained successfully\n",
      "‚úÖ Training completed! Model ready for recommendations.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class RecommendationModelTrainer:\n",
    "    def __init__(self, data):\n",
    "        self.full_data = data\n",
    "        self.model = None\n",
    "        self.interaction_matrix = None\n",
    "        self.vendor_similarity = None\n",
    "        self.content_matrix = None\n",
    "        self.reverse_user_map = None\n",
    "        self.vendor_map = None\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    def prepare_data(self, data=None):\n",
    "        \"\"\"Prepare and preprocess the data\"\"\"\n",
    "        if data is None:\n",
    "            data = self.full_data\n",
    "\n",
    "        print(\"Preparing data...\")\n",
    "        df = data[['customer_id', 'vendor_id', 'order_frequency', 'product_rating']].copy()\n",
    "        df['score'] = df['order_frequency'] * df['product_rating']\n",
    "\n",
    "        # Encode users and vendors\n",
    "        df['user_code'] = df['customer_id'].astype('category').cat.codes\n",
    "        df['vendor_code'] = df['vendor_id'].astype('category').cat.codes\n",
    "\n",
    "        # Build interaction matrix\n",
    "        interaction_matrix = coo_matrix(\n",
    "            (df['score'], (df['user_code'], df['vendor_code']))\n",
    "        ).T.tocsr()\n",
    "\n",
    "        # Build lookup tables\n",
    "        user_map = dict(enumerate(df['customer_id'].astype('category').cat.categories))\n",
    "        vendor_map = dict(enumerate(df['vendor_id'].astype('category').cat.categories))\n",
    "        reverse_user_map = {v: k for k, v in user_map.items()}\n",
    "\n",
    "        print(f\"Data prepared: {len(user_map)} users, {len(vendor_map)} vendors\")\n",
    "        return df, interaction_matrix, user_map, vendor_map, reverse_user_map\n",
    "\n",
    "    def build_content_features(self, data=None):\n",
    "        \"\"\"Build vendor content-based features\"\"\"\n",
    "        if data is None:\n",
    "            data = self.full_data\n",
    "\n",
    "        print(\"Building content features...\")\n",
    "        vendor_features = data.groupby('vendor_id').agg({\n",
    "            'cuisine_origin': 'first',\n",
    "            'unit_price': 'mean',\n",
    "            'product_rating': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        # One-hot encode cuisine\n",
    "        cuisine_encoded = pd.get_dummies(vendor_features['cuisine_origin'])\n",
    "\n",
    "        # Normalize numerical features\n",
    "        vendor_features['unit_price_norm'] = (\n",
    "            vendor_features['unit_price'] - vendor_features['unit_price'].min()\n",
    "        ) / (vendor_features['unit_price'].max() - vendor_features['unit_price'].min())\n",
    "\n",
    "        vendor_features['product_rating_norm'] = (\n",
    "            vendor_features['product_rating'] - vendor_features['product_rating'].min()\n",
    "        ) / (vendor_features['product_rating'].max() - vendor_features['product_rating'].min())\n",
    "\n",
    "        # Combine all features\n",
    "        content_matrix = pd.concat([\n",
    "            cuisine_encoded,\n",
    "            vendor_features[['unit_price_norm', 'product_rating_norm']]\n",
    "        ], axis=1)\n",
    "        content_matrix.index = vendor_features['vendor_id']\n",
    "\n",
    "        # Compute vendor similarity\n",
    "        vendor_similarity = pd.DataFrame(\n",
    "            cosine_similarity(content_matrix),\n",
    "            index=content_matrix.index,\n",
    "            columns=content_matrix.index\n",
    "        )\n",
    "        print(\"Content features built successfully\")\n",
    "        return content_matrix, vendor_similarity\n",
    "\n",
    "    def train_als_model(self, interaction_matrix, factors=50, regularization=0.1, iterations=30):\n",
    "        \"\"\"Train the ALS model\"\"\"\n",
    "        print(\"Training ALS model...\")\n",
    "        model = AlternatingLeastSquares(\n",
    "            factors=factors,\n",
    "            regularization=regularization,\n",
    "            iterations=iterations,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(interaction_matrix.T)\n",
    "        print(\"ALS model trained successfully\")\n",
    "        return model\n",
    "\n",
    "    def split_train_test_data(self, test_ratio=0.2):\n",
    "        \"\"\"Split data into train and test sets for evaluation\"\"\"\n",
    "        print(\"Splitting data into train and test sets...\")\n",
    "\n",
    "        def split_user_data(df, test_ratio=0.2):\n",
    "            train_list, test_list = [], []\n",
    "            for user_id, user_df in df.groupby('customer_id'):\n",
    "                if len(user_df) < 2:  # Reduced minimum for more users in test\n",
    "                    continue\n",
    "                train, test = train_test_split(user_df, test_size=test_ratio, random_state=42)\n",
    "                train_list.append(train)\n",
    "                test_list.append(test)\n",
    "            return pd.concat(train_list), pd.concat(test_list)\n",
    "\n",
    "        self.train_data, self.test_data = split_user_data(self.full_data, test_ratio)\n",
    "        print(f\"Train data: {len(self.train_data)} records, {self.train_data['customer_id'].nunique()} users\")\n",
    "        print(f\"Test data: {len(self.test_data)} records, {self.test_data['customer_id'].nunique()} users\")\n",
    "        return self.train_data, self.test_data\n",
    "\n",
    "    # ==================== EVALUATION METRICS ====================\n",
    "\n",
    "    def precision_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate Precision@K\"\"\"\n",
    "        if len(recommended) == 0:\n",
    "            return 0.0\n",
    "        recommended_k = recommended[:k]\n",
    "        relevant = [1 if item in actual else 0 for item in recommended_k]\n",
    "        return sum(relevant) / len(recommended_k)\n",
    "\n",
    "    def ndcg_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate NDCG@K\"\"\"\n",
    "        if len(recommended) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        recommended_k = recommended[:k]\n",
    "        relevance = [1 if item in actual else 0 for item in recommended_k]\n",
    "\n",
    "        # Calculate DCG\n",
    "        dcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(relevance)])\n",
    "\n",
    "        # Calculate IDCG\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        idcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(ideal_relevance)])\n",
    "\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    def mrr_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Calculate MRR@K\"\"\"\n",
    "        for idx, item in enumerate(recommended[:k]):\n",
    "            if item in actual:\n",
    "                return 1.0 / (idx + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def evaluate_model_performance(self, N=10):\n",
    "        \"\"\"Comprehensive model evaluation with train/test split\"\"\"\n",
    "        print(f\"üìä EVALUATING MODEL PERFORMANCE (N={N})\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Split data\n",
    "        self.split_train_test_data()\n",
    "\n",
    "        # Prepare training data for evaluation model\n",
    "        print(\"Training evaluation model on training data...\")\n",
    "        df_train, interaction_matrix_train, user_map_train, vendor_map_train, reverse_user_map_train = self.prepare_data(self.train_data)\n",
    "\n",
    "        # Train ALS model on training data\n",
    "        eval_model = self.train_als_model(interaction_matrix_train)\n",
    "\n",
    "        scores = []\n",
    "        test_users = self.test_data['customer_id'].unique()\n",
    "\n",
    "        print(f\"Evaluating on {len(test_users)} test users...\")\n",
    "\n",
    "        processed_count = 0\n",
    "        for user_id in test_users:\n",
    "            actual = self.test_data[self.test_data['customer_id'] == user_id]['vendor_id'].unique().tolist()\n",
    "\n",
    "            try:\n",
    "                # Skip if user not in training data\n",
    "                if user_id not in reverse_user_map_train:\n",
    "                    continue\n",
    "\n",
    "                # Get user index\n",
    "                user_idx = reverse_user_map_train[user_id]\n",
    "                user_items = interaction_matrix_train.T.tocsr()\n",
    "\n",
    "                # Get ALS recommendations\n",
    "                recommended = eval_model.recommend(user_idx, user_items[user_idx], N=N)\n",
    "                recommended_vendors = [vendor_map_train[int(i[0])] for i in recommended]\n",
    "\n",
    "                # Calculate metrics\n",
    "                prec = self.precision_at_k(recommended_vendors, actual, k=N)\n",
    "                ndcg = self.ndcg_at_k(recommended_vendors, actual, k=N)\n",
    "                mrr = self.mrr_at_k(recommended_vendors, actual, k=N)\n",
    "\n",
    "                scores.append((prec, ndcg, mrr))\n",
    "                processed_count += 1\n",
    "\n",
    "                if processed_count % 100 == 0:\n",
    "                    print(f\"Processed {processed_count}/{len(test_users)} users...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        if not scores:\n",
    "            print(\"‚ùå No valid scores computed! Check your data.\")\n",
    "            return None\n",
    "\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        results = {\n",
    "            'Precision@10': scores[:, 0].mean(),\n",
    "            'NDCG@10': scores[:, 1].mean(),\n",
    "            'MRR@10': scores[:, 2].mean(),\n",
    "            'Users_Evaluated': len(scores)\n",
    "        }\n",
    "\n",
    "        # Print results\n",
    "        print(\"\\nüìà EVALUATION RESULTS:\")\n",
    "        print(\"-\" * 40)\n",
    "        for metric, value in results.items():\n",
    "            if metric == 'Users_Evaluated':\n",
    "                print(f\"{metric}: {value}\")\n",
    "            else:\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "# ==================== TRAINING AND TESTING EXECUTION ====================\n",
    "\n",
    "def train_and_test_model():\n",
    "    \"\"\"Train the model and run comprehensive evaluation\"\"\"\n",
    "    print(\"üöÄ MODEL TRAINING AND EVALUATION\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = RecommendationModelTrainer(full_data)\n",
    "\n",
    "    # Run evaluation\n",
    "    results = trainer.evaluate_model_performance(N=10)\n",
    "\n",
    "    # Train final model on full data for production use\n",
    "    print(\"\\nüîß TRAINING FINAL PRODUCTION MODEL...\")\n",
    "    df_full, interaction_matrix_full, user_map_full, vendor_map_full, reverse_user_map_full = trainer.prepare_data()\n",
    "    content_matrix_full, vendor_similarity_full = trainer.build_content_features()\n",
    "    final_model = trainer.train_als_model(interaction_matrix_full)\n",
    "\n",
    "    # Save the trained components for the recommendation system\n",
    "    model_components = {\n",
    "        'model': final_model,\n",
    "        'interaction_matrix': interaction_matrix_full,\n",
    "        'vendor_map': vendor_map_full,\n",
    "        'reverse_user_map': reverse_user_map_full,\n",
    "        'content_matrix': content_matrix_full,\n",
    "        'vendor_similarity': vendor_similarity_full\n",
    "    }\n",
    "\n",
    "    print(\"‚úÖ Training completed! Model ready for recommendations.\")\n",
    "    return trainer, model_components, results\n",
    "\n",
    "# Run training and testing\n",
    "print(\"Starting model training and evaluation...\")\n",
    "trainer, model_components, evaluation_results = train_and_test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ccf981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting recommendation system...\n",
      "üéØ RECOMMENDATION SYSTEM\n",
      "========================================\n",
      "Generating recommendations for 2 customers...\n",
      "\n",
      "================================================================================\n",
      "üîç CUSTOMER ANALYSIS REPORT: 2e7276ad3a\n",
      "============================================================\n",
      "\n",
      "üìä ORDER HISTORY:\n",
      "------------------------------\n",
      "vendor_id                             name cuisine_origin  order_frequency  product_rating  unit_price\n",
      " 23c3cbb7                   chocolate pint         snacks               30        4.000000    5.600000\n",
      " 24f02f22            roasted herb potatoes        italian               30        4.000000    9.800000\n",
      " 2a89ea8c le parisien ham  butter baguette         snacks               15        4.000000    4.800000\n",
      " 31883abc           green curry mild spicy           thai               60        3.500000    5.100000\n",
      " 389d8451                             coke         snacks               15        3.000000    1.200000\n",
      " 3c8b6666                    fungi risotto        italian               45        2.666667    8.266667\n",
      " 42112a93                          brisket     vietnamese               30        3.500000    6.000000\n",
      " 54a7bf39                  five guys shake       american               30        4.000000    5.200000\n",
      " 573e52c0                    original king       japanese               15        4.000000    6.800000\n",
      " 642370bd                             coke         indian               90        4.166667    6.266667\n",
      " 921b38c7                    latte regular         snacks               45        4.666667    3.733333\n",
      " b62d39b7                          diavola        italian               45        4.333333   11.600000\n",
      " e33ad7ec                      house salad        italian               60        4.250000    9.500000\n",
      " ee4f2ee0               v beef noodle soup     vietnamese               60        3.250000    4.100000\n",
      "\n",
      "üë§ TASTE PROFILE:\n",
      "------------------------------\n",
      "Total Orders: 38\n",
      "Unique Vendors: 14\n",
      "Preferred Cuisines: {'italian': 12, 'snacks': 7, 'vietnamese': 6}\n",
      "Avg Rating Given: 3.8421052631578947\n",
      "Avg Spending: 6.557894736842105\n",
      "Favorite Vendors: {'642370bd': 90, '31883abc': 60, 'ee4f2ee0': 60}\n",
      "\n",
      "üéØ HYBRID RECOMMENDATIONS (Top 10):\n",
      "----------------------------------------\n",
      "vendor_id                                                    name cuisine_origin  unit_price  product_rating  order_frequency\n",
      " 0002b34d                                    back to basics vegan         snacks    4.666667        3.666667         7.666667\n",
      " 20fe964d                                                  box of         snacks   13.600000        5.000000         4.000000\n",
      " 2f8250d5 cd half roast chicken with mushroom cream sauce   sides         snacks    9.600000        5.000000         5.000000\n",
      " 3ce26d93                           d tbone steak with beef sauce         snacks   15.600000        5.000000        17.000000\n",
      " 626a8347        lychee rose cake petite  including  pcs macarons         snacks   17.200000        5.000000         1.000000\n",
      " 7544da62                         roasted brown bobo milkoriginal         snacks    3.095652        4.347826        21.695652\n",
      " 91e15661                                       guanaja cake size         snacks   18.400000        5.000000       348.000000\n",
      " b91af74d                                all chocolate cake  inch         snacks   14.400000        5.000000         9.000000\n",
      " d51de626                                             cups bundle         snacks    9.600000        5.000000        30.000000\n",
      " eb8a64eb                                  american cowboy burger         snacks   11.600000        5.000000        19.000000\n",
      "‚úÖ Report completed for 2e7276ad3a\n",
      "\n",
      "================================================================================\n",
      "üîç CUSTOMER ANALYSIS REPORT: f374c8c54c\n",
      "============================================================\n",
      "\n",
      "üìä ORDER HISTORY:\n",
      "------------------------------\n",
      "vendor_id                     name cuisine_origin  order_frequency  product_rating  unit_price\n",
      " 21830106 chicken cutlet with rice         snacks                8             3.5         2.4\n",
      "\n",
      "üë§ TASTE PROFILE:\n",
      "------------------------------\n",
      "Total Orders: 8\n",
      "Unique Vendors: 1\n",
      "Preferred Cuisines: {'snacks': 8}\n",
      "Avg Rating Given: 3.5\n",
      "Avg Spending: 2.4000000000000004\n",
      "Favorite Vendors: {'21830106': 8}\n",
      "\n",
      "üéØ HYBRID RECOMMENDATIONS (Top 10):\n",
      "----------------------------------------\n",
      "vendor_id                             name cuisine_origin  unit_price  product_rating  order_frequency\n",
      " 0002b34d             back to basics vegan         snacks    4.666667        3.666667         7.666667\n",
      " 16da9cef           jellicious cup ËúÇËúúÂØíÂ§©‰∏âÂêà‰∏Ä         snacks    2.226667        3.633333         6.766667\n",
      " 5350877d            pearly soya milk cold         snacks    2.176471        3.558824         9.764706\n",
      " 71eb9456  lemon chicken cutlet rice Êü†Ê™¨È∏°ÊâíÈ•≠         snacks    2.400000        3.629630        11.259259\n",
      " 77b12c68 mee hoon   vegetables  mock meat         snacks    2.505263        3.631579        13.105263\n",
      " 8c2a52d3        nine fresh signature ‰πùÈ≤úÊãõÁâå         snacks    2.195556        3.644444         5.466667\n",
      " 9fcb02cb                       milo stylo         snacks    2.257143        3.642857         8.000000\n",
      " c0a1e3ac                damascus rose tea         snacks    2.312500        3.656250        11.593750\n",
      " edf9272e         storeselected half dozen         snacks    2.448485        3.636364        11.060606\n",
      " f4c98b0e             roasted chicken rice         snacks    2.400000        3.619048        15.190476\n",
      "‚úÖ Report completed for f374c8c54c\n",
      "\n",
      "üéâ RECOMMENDATION SYSTEM COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "class RecommendationSystem:\n",
    "    def __init__(self, full_data, model_components):\n",
    "        self.full_data = full_data\n",
    "        self.model = model_components['model']\n",
    "        self.interaction_matrix = model_components['interaction_matrix']\n",
    "        self.vendor_map = model_components['vendor_map']\n",
    "        self.reverse_user_map = model_components['reverse_user_map']\n",
    "        self.vendor_similarity = model_components['vendor_similarity']\n",
    "\n",
    "    def get_customer_order_history(self, customer_id):\n",
    "        \"\"\"Get detailed order history for a customer\"\"\"\n",
    "        customer_orders = self.full_data[self.full_data['customer_id'] == customer_id]\n",
    "\n",
    "        if customer_orders.empty:\n",
    "            return f\"No order history found for customer: {customer_id}\"\n",
    "\n",
    "        # Aggregate order history\n",
    "        order_summary = customer_orders.groupby('vendor_id').agg({\n",
    "            'name': 'first',\n",
    "            'cuisine_origin': 'first',\n",
    "            'order_frequency': 'sum',\n",
    "            'product_rating': 'mean',\n",
    "            'unit_price': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        return order_summary\n",
    "\n",
    "    def get_customer_taste_profile(self, customer_id):\n",
    "        \"\"\"Analyze customer taste preferences\"\"\"\n",
    "        customer_orders = self.full_data[self.full_data['customer_id'] == customer_id]\n",
    "\n",
    "        if customer_orders.empty:\n",
    "            return \"No taste profile available (new customer)\"\n",
    "\n",
    "        taste_profile = {\n",
    "            'total_orders': len(customer_orders),\n",
    "            'unique_vendors': customer_orders['vendor_id'].nunique(),\n",
    "            'preferred_cuisines': customer_orders['cuisine_origin'].value_counts().head(3).to_dict(),\n",
    "            'avg_rating_given': customer_orders['product_rating'].mean(),\n",
    "            'avg_spending': customer_orders['unit_price'].mean(),\n",
    "            'favorite_vendors': customer_orders.groupby('vendor_id')['order_frequency']\n",
    "                                                .sum().sort_values(ascending=False).head(3).to_dict()\n",
    "        }\n",
    "\n",
    "        return taste_profile\n",
    "\n",
    "    def recommend_vendors(self, customer_id, N=10):\n",
    "        \"\"\"Get ALS-based recommendations\"\"\"\n",
    "        if customer_id not in self.reverse_user_map:\n",
    "            return \"Cold-start user. Recommend popular restaurants.\"\n",
    "\n",
    "        user_idx = self.reverse_user_map[customer_id]\n",
    "        user_items = self.interaction_matrix.T.tocsr()\n",
    "\n",
    "        recommended = self.model.recommend(user_idx, user_items[user_idx], N=N)\n",
    "        recommended_vendors = [self.vendor_map[int(i[0])] for i in recommended]\n",
    "\n",
    "        return recommended_vendors\n",
    "\n",
    "    def hybrid_recommend(self, customer_id, N=10, als_weight=0.5, content_weight=0.5):\n",
    "        \"\"\"Get hybrid recommendations combining ALS and content-based\"\"\"\n",
    "        # Get user's ordered vendors from full data\n",
    "        user_vendors = self.full_data[self.full_data['customer_id'] == customer_id]['vendor_id'].unique()\n",
    "\n",
    "        if len(user_vendors) == 0:\n",
    "            return \"Cold-start user. Recommend popular restaurants.\"\n",
    "\n",
    "        # Content-based similarity scores\n",
    "        content_scores = self.vendor_similarity[user_vendors].mean(axis=1)\n",
    "        content_scores = content_scores.drop(user_vendors, errors='ignore')\n",
    "\n",
    "        # ALS recommendations\n",
    "        als_recs = self.recommend_vendors(customer_id, N=100)\n",
    "\n",
    "        if isinstance(als_recs, str):\n",
    "            return als_recs\n",
    "\n",
    "        als_scores = pd.Series([1 / (i + 1) for i in range(len(als_recs))], index=als_recs)\n",
    "\n",
    "        # Combine scores\n",
    "        hybrid_scores = pd.concat([als_scores, content_scores], axis=1).fillna(0)\n",
    "        hybrid_scores.columns = ['als', 'content']\n",
    "        hybrid_scores['hybrid'] = (als_weight * hybrid_scores['als'] +\n",
    "                                 content_weight * hybrid_scores['content'])\n",
    "\n",
    "        # Return top N\n",
    "        top_hybrid = hybrid_scores['hybrid'].sort_values(ascending=False).head(N).index.tolist()\n",
    "        return top_hybrid\n",
    "\n",
    "    def get_recommendation_details(self, vendor_ids):\n",
    "        \"\"\"Get detailed information about recommended vendors\"\"\"\n",
    "        if isinstance(vendor_ids, str):\n",
    "            return vendor_ids\n",
    "\n",
    "        vendor_details = self.full_data[self.full_data['vendor_id'].isin(vendor_ids)]\n",
    "\n",
    "        summary = vendor_details.groupby('vendor_id').agg({\n",
    "            'name': 'first',\n",
    "            'cuisine_origin': 'first',\n",
    "            'unit_price': 'mean',\n",
    "            'product_rating': 'mean',\n",
    "            'order_frequency': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def generate_customer_report(self, customer_id, N=10):\n",
    "        \"\"\"Generate complete automated report for a customer\"\"\"\n",
    "        print(f\"üîç CUSTOMER ANALYSIS REPORT: {customer_id}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # 1. Order History\n",
    "        print(\"\\nüìä ORDER HISTORY:\")\n",
    "        print(\"-\" * 30)\n",
    "        order_history = self.get_customer_order_history(customer_id)\n",
    "        if isinstance(order_history, pd.DataFrame):\n",
    "            print(order_history.to_string(index=False))\n",
    "        else:\n",
    "            print(order_history)\n",
    "\n",
    "        # 2. Taste Profile\n",
    "        print(\"\\nüë§ TASTE PROFILE:\")\n",
    "        print(\"-\" * 30)\n",
    "        taste_profile = self.get_customer_taste_profile(customer_id)\n",
    "        if isinstance(taste_profile, dict):\n",
    "            for key, value in taste_profile.items():\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "        else:\n",
    "            print(taste_profile)\n",
    "\n",
    "        # 3. Recommendations\n",
    "        print(f\"\\nüéØ HYBRID RECOMMENDATIONS (Top {N}):\")\n",
    "        print(\"-\" * 40)\n",
    "        recommendations = self.hybrid_recommend(customer_id, N=N)\n",
    "        rec_details = self.get_recommendation_details(recommendations)\n",
    "\n",
    "        if isinstance(rec_details, pd.DataFrame):\n",
    "            print(rec_details.to_string(index=False))\n",
    "        else:\n",
    "            print(rec_details)\n",
    "\n",
    "        return {\n",
    "            'customer_id': customer_id,\n",
    "            'order_history': order_history,\n",
    "            'taste_profile': taste_profile,\n",
    "            'recommendations': rec_details\n",
    "        }\n",
    "\n",
    "    def batch_recommendations(self, customer_ids, N=10):\n",
    "        \"\"\"Generate recommendations for multiple customers\"\"\"\n",
    "        reports = {}\n",
    "        for customer_id in customer_ids:\n",
    "            try:\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                report = self.generate_customer_report(customer_id, N=N)\n",
    "                reports[customer_id] = report\n",
    "                print(f\"‚úÖ Report completed for {customer_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing {customer_id}: {str(e)}\")\n",
    "        return reports\n",
    "\n",
    "# ==================== RECOMMENDATION SYSTEM EXECUTION ====================\n",
    "\n",
    "def run_recommendation_system():\n",
    "    \"\"\"Run the recommendation system with the trained model\"\"\"\n",
    "    print(\"üéØ RECOMMENDATION SYSTEM\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Initialize recommendation system with trained components\n",
    "    recommender = RecommendationSystem(full_data, model_components)\n",
    "\n",
    "    # Test with specific customers\n",
    "    test_customers = [\"2e7276ad3a\", \"f374c8c54c\"]  # Replace with actual customer IDs\n",
    "\n",
    "    print(f\"Generating recommendations for {len(test_customers)} customers...\")\n",
    "\n",
    "    # Generate reports\n",
    "    reports = recommender.batch_recommendations(test_customers, N=10)\n",
    "\n",
    "    print(\"\\nüéâ RECOMMENDATION SYSTEM COMPLETED!\")\n",
    "    return recommender, reports\n",
    "\n",
    "# Run the recommendation system\n",
    "print(\"Starting recommendation system...\")\n",
    "recommender_system, customer_reports = run_recommendation_system()\n",
    "\n",
    "# ==================== QUERY INDIVIDUAL CUSTOMERS ====================\n",
    "\n",
    "def query_specific_customer(customer_id):\n",
    "    \"\"\"Query a specific customer on demand\"\"\"\n",
    "    print(f\"\\nüîç QUERYING CUSTOMER: {customer_id}\")\n",
    "    report = recommender_system.generate_customer_report(customer_id, N=10)\n",
    "    return report\n",
    "\n",
    "# Example: Query a specific customer\n",
    "# customer_report = query_specific_customer(\"2e7276ad3a\")\n",
    "\n",
    "# ==================== GET ALL CUSTOMER IDs ====================\n",
    "\n",
    "def get_all_customer_ids():\n",
    "    \"\"\"Get all customer IDs for selection\"\"\"\n",
    "    customer_ids = full_data['customer_id'].unique()\n",
    "    print(f\"Total customers in dataset: {len(customer_ids)}\")\n",
    "    print(\"Sample customer IDs:\", customer_ids[:10])  # Show first 10\n",
    "    return customer_ids\n",
    "\n",
    "# View all available customers\n",
    "# all_customers = get_all_customer_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5121e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting recommendation system evaluation...\n",
      "‚ö° RUNNING QUICK EVALUATION\n",
      "üöÄ RUNNING COMPREHENSIVE EVALUATION\n",
      "============================================================\n",
      "Splitting data for evaluation...\n",
      "Train: 74671 records, 9306 users\n",
      "Test: 23461 records, 9306 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alnd/.pyenv/versions/food-delivery-rec/lib/python3.10/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.0003921985626220703 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea9b5360f174761a67af0cb0d2fdbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 9306 test users...\n",
      "\n",
      "üìä QUICK RESULTS (Top-10):\n",
      "  Precision: 0.001\n",
      "  Recall: 0.001\n",
      "  NDCG: 0.002\n",
      "  MRR: 0.002\n",
      "  MAP: 0.001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class RecommendationEvaluator:\n",
    "    def __init__(self, data):\n",
    "        self.full_data = data\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    def split_data_stratified(self, test_ratio=0.2, min_orders=2):\n",
    "        \"\"\"Split data with stratification\"\"\"\n",
    "        print(\"Splitting data for evaluation...\")\n",
    "\n",
    "        train_list, test_list = [], []\n",
    "        for user_id, user_df in self.full_data.groupby('customer_id'):\n",
    "            if len(user_df) < min_orders:\n",
    "                continue  # Skip users with too few interactions\n",
    "            train, test = train_test_split(user_df, test_size=test_ratio, random_state=42)\n",
    "            train_list.append(train)\n",
    "            test_list.append(test)\n",
    "\n",
    "        self.train_data = pd.concat(train_list)\n",
    "        self.test_data = pd.concat(test_list)\n",
    "\n",
    "        print(f\"Train: {len(self.train_data)} records, {self.train_data['customer_id'].nunique()} users\")\n",
    "        print(f\"Test: {len(self.test_data)} records, {self.test_data['customer_id'].nunique()} users\")\n",
    "        return self.train_data, self.test_data\n",
    "\n",
    "    def prepare_evaluation_model(self, train_data):\n",
    "        \"\"\"Prepare model specifically for evaluation\"\"\"\n",
    "        df = train_data[['customer_id', 'vendor_id', 'order_frequency', 'product_rating']].copy()\n",
    "        df['score'] = df['order_frequency'] * df['product_rating']\n",
    "\n",
    "        # Encode users and vendors\n",
    "        df['user_code'] = df['customer_id'].astype('category').cat.codes\n",
    "        df['vendor_code'] = df['vendor_id'].astype('category').cat.codes\n",
    "\n",
    "        # Build interaction matrix\n",
    "        interaction_matrix = coo_matrix(\n",
    "            (df['score'], (df['user_code'], df['vendor_code']))\n",
    "        ).T.tocsr()\n",
    "\n",
    "        # Build lookup tables\n",
    "        user_map = dict(enumerate(df['customer_id'].astype('category').cat.categories))\n",
    "        vendor_map = dict(enumerate(df['vendor_id'].astype('category').cat.categories))\n",
    "        reverse_user_map = {v: k for k, v in user_map.items()}\n",
    "\n",
    "        # Train model\n",
    "        model = AlternatingLeastSquares(factors=50, regularization=0.1, iterations=30, random_state=42)\n",
    "        model.fit(interaction_matrix.T)\n",
    "\n",
    "        return model, interaction_matrix, user_map, vendor_map, reverse_user_map\n",
    "\n",
    "    def precision_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Precision@K: Percentage of relevant recommendations in top K\"\"\"\n",
    "        if len(recommended) == 0:\n",
    "            return 0.0\n",
    "        recommended_k = recommended[:k]\n",
    "        hits = len(set(recommended_k) & set(actual))\n",
    "        return hits / len(recommended_k)\n",
    "\n",
    "    def recall_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Recall@K: Percentage of actual items found in top K\"\"\"\n",
    "        if len(actual) == 0:\n",
    "            return 0.0\n",
    "        recommended_k = recommended[:k]\n",
    "        hits = len(set(recommended_k) & set(actual))\n",
    "        return hits / len(actual)\n",
    "\n",
    "    def ndcg_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Normalized Discounted Cumulative Gain@K\"\"\"\n",
    "        if len(recommended) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        recommended_k = recommended[:k]\n",
    "        relevance = [1 if item in actual else 0 for item in recommended_k]\n",
    "\n",
    "        # Calculate DCG\n",
    "        dcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(relevance)])\n",
    "\n",
    "        # Calculate IDCG\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        idcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(ideal_relevance)])\n",
    "\n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    def mrr_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Mean Reciprocal Rank@K\"\"\"\n",
    "        for idx, item in enumerate(recommended[:k]):\n",
    "            if item in actual:\n",
    "                return 1.0 / (idx + 1)\n",
    "        return 0.0\n",
    "\n",
    "    def map_at_k(self, recommended, actual, k=10):\n",
    "        \"\"\"Mean Average Precision@K\"\"\"\n",
    "        if len(actual) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        precision_scores = []\n",
    "        hits = 0\n",
    "        for i, item in enumerate(recommended[:k]):\n",
    "            if item in actual:\n",
    "                hits += 1\n",
    "                precision_scores.append(hits / (i + 1))\n",
    "\n",
    "        if not precision_scores:\n",
    "            return 0.0\n",
    "\n",
    "        return sum(precision_scores) / min(len(actual), k)\n",
    "\n",
    "    def evaluate_recommendations(self, k_values=[5, 10, 20]):\n",
    "        \"\"\"Comprehensive evaluation at different K values\"\"\"\n",
    "        print(\"üöÄ RUNNING COMPREHENSIVE EVALUATION\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Split data\n",
    "        self.split_data_stratified()\n",
    "\n",
    "        # Train model on training data\n",
    "        model, interaction_matrix, user_map, vendor_map, reverse_user_map = self.prepare_evaluation_model(self.train_data)\n",
    "\n",
    "        results = {}\n",
    "        all_user_metrics = []\n",
    "\n",
    "        test_users = self.test_data['customer_id'].unique()\n",
    "        print(f\"Evaluating on {len(test_users)} test users...\")\n",
    "\n",
    "        for user_id in test_users:\n",
    "            if user_id not in reverse_user_map:\n",
    "                continue\n",
    "\n",
    "            # Get actual interactions from test set\n",
    "            actual = self.test_data[self.test_data['customer_id'] == user_id]['vendor_id'].unique().tolist()\n",
    "\n",
    "            if not actual:  # Skip if no actual interactions\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Get recommendations\n",
    "                user_idx = reverse_user_map[user_id]\n",
    "                user_items = interaction_matrix.T.tocsr()\n",
    "                recommended = model.recommend(user_idx, user_items[user_idx], N=max(k_values))\n",
    "                recommended_vendors = [vendor_map[int(i[0])] for i in recommended]\n",
    "\n",
    "                user_metrics = {'user_id': user_id}\n",
    "                for k in k_values:\n",
    "                    user_metrics[f'precision@{k}'] = self.precision_at_k(recommended_vendors, actual, k)\n",
    "                    user_metrics[f'recall@{k}'] = self.recall_at_k(recommended_vendors, actual, k)\n",
    "                    user_metrics[f'ndcg@{k}'] = self.ndcg_at_k(recommended_vendors, actual, k)\n",
    "                    user_metrics[f'mrr@{k}'] = self.mrr_at_k(recommended_vendors, actual, k)\n",
    "                    user_metrics[f'map@{k}'] = self.map_at_k(recommended_vendors, actual, k)\n",
    "\n",
    "                all_user_metrics.append(user_metrics)\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        # Aggregate results\n",
    "        metrics_df = pd.DataFrame(all_user_metrics)\n",
    "\n",
    "        for k in k_values:\n",
    "            results[k] = {\n",
    "                'Precision': metrics_df[f'precision@{k}'].mean(),\n",
    "                'Recall': metrics_df[f'recall@{k}'].mean(),\n",
    "                'NDCG': metrics_df[f'ndcg@{k}'].mean(),\n",
    "                'MRR': metrics_df[f'mrr@{k}'].mean(),\n",
    "                'MAP': metrics_df[f'map@{k}'].mean(),\n",
    "                'Users_Evaluated': len(metrics_df)\n",
    "            }\n",
    "\n",
    "        return results, metrics_df\n",
    "\n",
    "    def print_evaluation_results(self, results):\n",
    "        \"\"\"Print formatted evaluation results\"\"\"\n",
    "        print(\"\\nüìä COMPREHENSIVE EVALUATION RESULTS\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        for k, metrics in results.items():\n",
    "            print(f\"\\nüéØ Top-{k} Recommendations:\")\n",
    "            print(\"-\" * 40)\n",
    "            for metric, value in metrics.items():\n",
    "                if metric == 'Users_Evaluated':\n",
    "                    print(f\"  {metric}: {value}\")\n",
    "                else:\n",
    "                    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "    def plot_evaluation_results(self, results):\n",
    "        \"\"\"Plot evaluation metrics\"\"\"\n",
    "        k_values = list(results.keys())\n",
    "        metrics = ['Precision', 'Recall', 'NDCG', 'MRR']\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        axes = axes.ravel()\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            values = [results[k][metric] for k in k_values]\n",
    "            axes[i].bar([str(k) for k in k_values], values, color='skyblue', alpha=0.7)\n",
    "            axes[i].set_title(f'{metric}@K')\n",
    "            axes[i].set_xlabel('K')\n",
    "            axes[i].set_ylabel(metric)\n",
    "\n",
    "            # Add value labels on bars\n",
    "            for j, v in enumerate(values):\n",
    "                axes[i].text(j, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def benchmark_against_baselines(self, k=10):\n",
    "        \"\"\"Compare against simple baselines\"\"\"\n",
    "        print(\"\\nüîç BENCHMARKING AGAINST BASELINES\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Popularity baseline (most ordered vendors)\n",
    "        popular_vendors = self.full_data['vendor_id'].value_counts().head(100).index.tolist()\n",
    "\n",
    "        # Random baseline\n",
    "        all_vendors = self.full_data['vendor_id'].unique().tolist()\n",
    "\n",
    "        baseline_results = {}\n",
    "\n",
    "        # Evaluate popularity baseline\n",
    "        pop_scores = []\n",
    "        for user_id in self.test_data['customer_id'].unique():\n",
    "            actual = self.test_data[self.test_data['customer_id'] == user_id]['vendor_id'].unique().tolist()\n",
    "            if actual:\n",
    "                pop_precision = self.precision_at_k(popular_vendors, actual, k)\n",
    "                pop_scores.append(pop_precision)\n",
    "\n",
    "        baseline_results['Popularity'] = np.mean(pop_scores) if pop_scores else 0\n",
    "\n",
    "        # Evaluate random baseline\n",
    "        random_scores = []\n",
    "        for user_id in self.test_data['customer_id'].unique():\n",
    "            actual = self.test_data[self.test_data['customer_id'] == user_id]['vendor_id'].unique().tolist()\n",
    "            if actual:\n",
    "                random_recs = np.random.choice(all_vendors, k, replace=False).tolist()\n",
    "                random_precision = self.precision_at_k(random_recs, actual, k)\n",
    "                random_scores.append(random_precision)\n",
    "\n",
    "        baseline_results['Random'] = np.mean(random_scores) if random_scores else 0\n",
    "\n",
    "        print(\"Baseline Performance (Precision@10):\")\n",
    "        for baseline, score in baseline_results.items():\n",
    "            print(f\"  {baseline}: {score:.4f}\")\n",
    "\n",
    "        return baseline_results\n",
    "\n",
    "# ==================== RUN COMPREHENSIVE EVALUATION ====================\n",
    "\n",
    "def run_complete_evaluation():\n",
    "    \"\"\"Run full evaluation pipeline\"\"\"\n",
    "    print(\"üöÄ STARTING COMPLETE RECOMMENDATION SYSTEM EVALUATION\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Initialize evaluator\n",
    "    evaluator = RecommendationEvaluator(full_data)\n",
    "\n",
    "    # Run main evaluation\n",
    "    results, detailed_metrics = evaluator.evaluate_recommendations(k_values=[5, 10, 20])\n",
    "\n",
    "    # Print results\n",
    "    evaluator.print_evaluation_results(results)\n",
    "\n",
    "    # Plot results\n",
    "    evaluator.plot_evaluation_results(results)\n",
    "\n",
    "    # Benchmark against baselines\n",
    "    baselines = evaluator.benchmark_against_baselines(k=10)\n",
    "\n",
    "    # Interpret results\n",
    "    interpret_evaluation_results(results, baselines)\n",
    "\n",
    "    return evaluator, results, detailed_metrics, baselines\n",
    "\n",
    "def interpret_evaluation_results(results, baselines):\n",
    "    \"\"\"Help interpret what the metrics mean\"\"\"\n",
    "    print(\"\\nüí° HOW TO INTERPRET THESE RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    main_metrics = results[10]  # Focus on Top-10\n",
    "\n",
    "    print(\"\\nüìà METRIC INTERPRETATION:\")\n",
    "    print(f\"Precision@10: {main_metrics['Precision']:.3f}\")\n",
    "    print(\"  ‚Üí Percentage of recommendations that are relevant\")\n",
    "    print(\"  ‚Üí Good if > 0.1, Excellent if > 0.3\")\n",
    "\n",
    "    print(f\"\\nRecall@10: {main_metrics['Recall']:.3f}\")\n",
    "    print(\"  ‚Üí Percentage of user's actual preferences found in recommendations\")\n",
    "    print(\"  ‚Üí Good if > 0.05, Excellent if > 0.15\")\n",
    "\n",
    "    print(f\"\\nNDCG@10: {main_metrics['NDCG']:.3f}\")\n",
    "    print(\"  ‚Üí Measures ranking quality (0-1 scale)\")\n",
    "    print(\"  ‚Üí Good if > 0.1, Excellent if > 0.3\")\n",
    "\n",
    "    print(f\"\\nMRR@10: {main_metrics['MRR']:.3f}\")\n",
    "    print(\"  ‚Üí How quickly you find the first relevant recommendation\")\n",
    "    print(\"  ‚Üí Good if > 0.1, Excellent if > 0.3\")\n",
    "\n",
    "    print(f\"\\nMAP@10: {main_metrics['MAP']:.3f}\")\n",
    "    print(\"  ‚Üí Overall ranking quality considering all relevant items\")\n",
    "    print(\"  ‚Üí Good if > 0.05, Excellent if > 0.2\")\n",
    "\n",
    "    print(f\"\\nüéØ PERFORMANCE ASSESSMENT:\")\n",
    "\n",
    "    # Overall assessment\n",
    "    precision_score = main_metrics['Precision']\n",
    "    ndcg_score = main_metrics['NDCG']\n",
    "\n",
    "    if precision_score > 0.3 and ndcg_score > 0.3:\n",
    "        print(\"‚úÖ EXCELLENT - Your system is performing very well!\")\n",
    "    elif precision_score > 0.15 and ndcg_score > 0.15:\n",
    "        print(\"‚úÖ GOOD - Your system is performing well\")\n",
    "    elif precision_score > 0.05 and ndcg_score > 0.05:\n",
    "        print(\"‚ö†Ô∏è  FAIR - There's room for improvement\")\n",
    "    else:\n",
    "        print(\"‚ùå POOR - Consider revising your approach\")\n",
    "\n",
    "    # Compare with baselines\n",
    "    your_precision = main_metrics['Precision']\n",
    "    pop_precision = baselines.get('Popularity', 0)\n",
    "    random_precision = baselines.get('Random', 0)\n",
    "\n",
    "    print(f\"\\nüìä COMPARED TO BASELINES:\")\n",
    "    print(f\"Your model: {your_precision:.3f}\")\n",
    "    print(f\"Popularity: {pop_precision:.3f}\")\n",
    "    print(f\"Random: {random_precision:.3f}\")\n",
    "\n",
    "    if your_precision > pop_precision * 1.5:\n",
    "        print(\"‚úÖ You're significantly better than simple popularity!\")\n",
    "    elif your_precision > pop_precision:\n",
    "        print(\"‚ö†Ô∏è  You're better than popularity, but could improve more\")\n",
    "    else:\n",
    "        print(\"‚ùå You're not beating simple popularity - needs work\")\n",
    "\n",
    "# ==================== QUICK EVALUATION ====================\n",
    "\n",
    "def quick_evaluation():\n",
    "    \"\"\"Run a quick evaluation for fast feedback\"\"\"\n",
    "    print(\"‚ö° RUNNING QUICK EVALUATION\")\n",
    "\n",
    "    evaluator = RecommendationEvaluator(full_data)\n",
    "    results, detailed_metrics = evaluator.evaluate_recommendations(k_values=[10])\n",
    "\n",
    "    print(\"\\nüìä QUICK RESULTS (Top-10):\")\n",
    "    metrics = results[10]\n",
    "    for metric, value in metrics.items():\n",
    "        if metric != 'Users_Evaluated':\n",
    "            print(f\"  {metric}: {value:.3f}\")\n",
    "\n",
    "    return results[10]\n",
    "\n",
    "# ==================== RUN THE EVALUATION ====================\n",
    "\n",
    "print(\"Starting recommendation system evaluation...\")\n",
    "\n",
    "# Option 1: Quick evaluation (fast)\n",
    "quick_results = quick_evaluation()\n",
    "\n",
    "# Option 2: Complete evaluation (comprehensive)\n",
    "# evaluator, full_results, detailed_metrics, baselines = run_complete_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62fcff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° RUNNING QUICK EVALUATION\n",
      "üöÄ RUNNING COMPREHENSIVE EVALUATION\n",
      "============================================================\n",
      "Splitting data for evaluation...\n",
      "Train: 74671 records, 9306 users\n",
      "Test: 23461 records, 9306 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alnd/.pyenv/versions/food-delivery-rec/lib/python3.10/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.00030493736267089844 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d8a392c20a48828701c510a2e753ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 9306 test users...\n",
      "\n",
      "üìä QUICK RESULTS (Top-10):\n",
      "  Precision: 0.001\n",
      "  Recall: 0.001\n",
      "  NDCG: 0.002\n",
      "  MRR: 0.002\n",
      "  MAP: 0.001\n",
      "\n",
      "üéØ SYSTEM QUALITY CHECK:\n",
      "========================================\n",
      "‚ùå NEEDS WORK - The system isn't capturing user preferences well\n",
      "   Consider feature engineering or algorithm tuning\n",
      "‚ö†Ô∏è  Ranking could be improved\n",
      "   Relevant items aren't appearing early enough\n"
     ]
    }
   ],
   "source": [
    "# Run this to see if your system is good\n",
    "def check_system_quality():\n",
    "    \"\"\"Simple function to check if your recommendation system is good\"\"\"\n",
    "    results = quick_evaluation()\n",
    "\n",
    "    precision = results['Precision']\n",
    "    ndcg = results['NDCG']\n",
    "\n",
    "    print(\"\\nüéØ SYSTEM QUALITY CHECK:\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    if precision > 0.3:\n",
    "        print(\"‚úÖ EXCELLENT! Your Precision@10 is great!\")\n",
    "        print(\"   Users will find many relevant recommendations\")\n",
    "    elif precision > 0.15:\n",
    "        print(\"‚úÖ GOOD! Your system is working well\")\n",
    "        print(\"   Most recommendations are relevant to users\")\n",
    "    elif precision > 0.05:\n",
    "        print(\"‚ö†Ô∏è  FAIR - There's room for improvement\")\n",
    "        print(\"   Some recommendations are relevant, but many aren't\")\n",
    "    else:\n",
    "        print(\"‚ùå NEEDS WORK - The system isn't capturing user preferences well\")\n",
    "        print(\"   Consider feature engineering or algorithm tuning\")\n",
    "\n",
    "    if ndcg > 0.3:\n",
    "        print(\"‚úÖ EXCELLENT ranking quality!\")\n",
    "        print(\"   You're putting the most relevant items first\")\n",
    "    elif ndcg > 0.15:\n",
    "        print(\"‚úÖ GOOD ranking - relevant items appear early\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Ranking could be improved\")\n",
    "        print(\"   Relevant items aren't appearing early enough\")\n",
    "\n",
    "    return precision, ndcg\n",
    "\n",
    "# Get your answer!\n",
    "precision_score, ndcg_score = check_system_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6fe663a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: 'Package                   Version': Expected end or semicolon (after name and no valid version specifier)\n",
      "    Package                   Version\n",
      "                              ^ (from line 1 of requirements.txt)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf9eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food-delivery-rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
