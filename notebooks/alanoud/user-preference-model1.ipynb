{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a46e86",
   "metadata": {},
   "source": [
    "# **0. Load libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007b78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#!pip install implicit\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.metrics import precision_score, ndcg_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3e5f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# og_file_path=\"~/code/Alanoudis/food-delivery-rec/data/updated_data/orders_sg25k.txt\"\n",
    "# og_data = pd.read_csv(og_file_path, sep=',', encoding='utf-8')\n",
    "# og_data.head()\n",
    "\n",
    "# og_products = \"~/code/Alanoudis/food-delivery-rec/data/raw_data/products_sg.txt\"\n",
    "# og_products = pd.read_csv(og_products, sep=',', encoding='utf-8')\n",
    "# og_products.head()\n",
    "\n",
    "# og_vendors = \"~/code/Alanoudis/food-delivery-rec/data/raw_data/vendors_sg.txt\"\n",
    "# og_vendors = pd.read_csv(og_vendors, sep=',', encoding='utf-8')\n",
    "# og_vendors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467f07b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_geohash</th>\n",
       "      <th>order_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_day</th>\n",
       "      <th>name</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>vendor_geohash</th>\n",
       "      <th>cuisine_origin</th>\n",
       "      <th>order_frequency</th>\n",
       "      <th>product_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>783e85338f1c</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>japanese garlic karaage don</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>084ab73246e6</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>chicken cutlet don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>30eba3cc2676</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>beef sukiyaki don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>3910309eea60</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>japanese beef yakiniku don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>20049fb602cb</td>\n",
       "      <td>0</td>\n",
       "      <td>12:03:29</td>\n",
       "      <td>85 days</td>\n",
       "      <td>teriyaki salmon don</td>\n",
       "      <td>8.0</td>\n",
       "      <td>66c9978d</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>japanese</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id customer_geohash  order_id vendor_id    product_id  day_of_week  \\\n",
       "0  1ba124d4e5            w21z7         0  212753d2  783e85338f1c            0   \n",
       "1  1ba124d4e5            w21z7         0  212753d2  084ab73246e6            0   \n",
       "2  1ba124d4e5            w21z7         0  212753d2  30eba3cc2676            0   \n",
       "3  1ba124d4e5            w21z7         0  212753d2  3910309eea60            0   \n",
       "4  1ba124d4e5            w21z7         0  212753d2  20049fb602cb            0   \n",
       "\n",
       "  order_time order_day                         name  unit_price  chain_id  \\\n",
       "0   12:03:29   85 days  japanese garlic karaage don         6.0  66c9978d   \n",
       "1   12:03:29   85 days           chicken cutlet don         6.8  66c9978d   \n",
       "2   12:03:29   85 days            beef sukiyaki don         6.8  66c9978d   \n",
       "3   12:03:29   85 days   japanese beef yakiniku don         6.8  66c9978d   \n",
       "4   12:03:29   85 days          teriyaki salmon don         8.0  66c9978d   \n",
       "\n",
       "  vendor_geohash cuisine_origin  order_frequency  product_rating  \n",
       "0          w21z7       japanese                1               4  \n",
       "1          w21z7       japanese                1               5  \n",
       "2          w21z7       japanese                1               3  \n",
       "3          w21z7       japanese                1               5  \n",
       "4          w21z7       japanese                1               5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old 100k data, im looking for products_rating and order_frequency columns\n",
    "full_data100k_path = \"~/code/Alanoudis/food-delivery-rec/data/test-train/full_data100k.csv\"\n",
    "full_data100k = pd.read_csv(full_data100k_path, index_col=0)\n",
    "full_data100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ea974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data100k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3e4816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_geohash</th>\n",
       "      <th>order_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_day</th>\n",
       "      <th>name</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>...</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>meal_of_day</th>\n",
       "      <th>order_hour_sin</th>\n",
       "      <th>order_hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>783e85338f1c</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>japanese garlic karaage don</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>084ab73246e6</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>chicken cutlet don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>30eba3cc2676</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>beef sukiyaki don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>3910309eea60</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>japanese beef yakiniku don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>20049fb602cb</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>teriyaki salmon don</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id customer_geohash  order_id vendor_id    product_id  day_of_week  \\\n",
       "0  1ba124d4e5            w21z7         0  212753d2  783e85338f1c            0   \n",
       "1  1ba124d4e5            w21z7         0  212753d2  084ab73246e6            0   \n",
       "2  1ba124d4e5            w21z7         0  212753d2  30eba3cc2676            0   \n",
       "3  1ba124d4e5            w21z7         0  212753d2  3910309eea60            0   \n",
       "4  1ba124d4e5            w21z7         0  212753d2  20049fb602cb            0   \n",
       "\n",
       "            order_time  order_day                         name  unit_price  \\\n",
       "0  1900-01-01 12:03:29         85  japanese garlic karaage don         6.0   \n",
       "1  1900-01-01 12:03:29         85           chicken cutlet don         6.8   \n",
       "2  1900-01-01 12:03:29         85            beef sukiyaki don         6.8   \n",
       "3  1900-01-01 12:03:29         85   japanese beef yakiniku don         6.8   \n",
       "4  1900-01-01 12:03:29         85          teriyaki salmon don         8.0   \n",
       "\n",
       "   ...  dow_1  dow_2  dow_3  dow_4  dow_5  dow_6  order_hour  meal_of_day  \\\n",
       "0  ...  False  False  False  False  False  False          12        lunch   \n",
       "1  ...  False  False  False  False  False  False          12        lunch   \n",
       "2  ...  False  False  False  False  False  False          12        lunch   \n",
       "3  ...  False  False  False  False  False  False          12        lunch   \n",
       "4  ...  False  False  False  False  False  False          12        lunch   \n",
       "\n",
       "   order_hour_sin  order_hour_cos  \n",
       "0    1.224647e-16            -1.0  \n",
       "1    1.224647e-16            -1.0  \n",
       "2    1.224647e-16            -1.0  \n",
       "3    1.224647e-16            -1.0  \n",
       "4    1.224647e-16            -1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full_data includes each product in each order + new columns for time features\n",
    "full_data_path = \"~/code/Alanoudis/food-delivery-rec/notebooks/alanoud/full_data_complete.csv\"\n",
    "full_data = pd.read_csv(full_data_path)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d7c520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'customer_geohash', 'order_id', 'vendor_id',\n",
       "       'product_id', 'day_of_week', 'order_time', 'order_day', 'name',\n",
       "       'unit_price', 'chain_id', 'vendor_geohash', 'cuisine_origin',\n",
       "       'is_weekend', 'dow_0', 'dow_1', 'dow_2', 'dow_3', 'dow_4', 'dow_5',\n",
       "       'dow_6', 'order_hour', 'meal_of_day', 'order_hour_sin',\n",
       "       'order_hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e857a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a103c492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_geohash</th>\n",
       "      <th>order_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_day</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>vendor_geohash</th>\n",
       "      <th>cuisine_origin</th>\n",
       "      <th>vendor_rating</th>\n",
       "      <th>num_products</th>\n",
       "      <th>total_order_value</th>\n",
       "      <th>products_ordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00119c8178</td>\n",
       "      <td>w21zu</td>\n",
       "      <td>39095</td>\n",
       "      <td>e7cb5902</td>\n",
       "      <td>2</td>\n",
       "      <td>16:30:07</td>\n",
       "      <td>10 days</td>\n",
       "      <td>ef3142e8</td>\n",
       "      <td>w21zu</td>\n",
       "      <td>malaysian</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Seafood Fried Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00198e01e4</td>\n",
       "      <td>w21z6</td>\n",
       "      <td>35939</td>\n",
       "      <td>02acaff6</td>\n",
       "      <td>0</td>\n",
       "      <td>13:57:35</td>\n",
       "      <td>85 days</td>\n",
       "      <td>8c51e46b</td>\n",
       "      <td>w21z6</td>\n",
       "      <td>chinese</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bean Curd Skin 凉拌腐竹, Dried Beancurd 凉拌素鸡, Blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001a5689fc</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>48288</td>\n",
       "      <td>a2c60e71</td>\n",
       "      <td>0</td>\n",
       "      <td>20:10:35</td>\n",
       "      <td>78 days</td>\n",
       "      <td>dd69fe77</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>singaporean</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Carrot Cake (Melur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001a5689fc</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>48289</td>\n",
       "      <td>a3bc472c</td>\n",
       "      <td>4</td>\n",
       "      <td>20:50:40</td>\n",
       "      <td>40 days</td>\n",
       "      <td>c59edb7d</td>\n",
       "      <td>w21z9</td>\n",
       "      <td>snacks</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Served without Fries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5689fc</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>48290</td>\n",
       "      <td>de18b671</td>\n",
       "      <td>3</td>\n",
       "      <td>20:05:42</td>\n",
       "      <td>53 days</td>\n",
       "      <td>f88ffd2b</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>american</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WHOPPER® Meal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id customer_geohash  order_id vendor_id  day_of_week order_time  \\\n",
       "0  00119c8178            w21zu     39095  e7cb5902            2   16:30:07   \n",
       "1  00198e01e4            w21z6     35939  02acaff6            0   13:57:35   \n",
       "2  001a5689fc            w21z3     48288  a2c60e71            0   20:10:35   \n",
       "3  001a5689fc            w21z3     48289  a3bc472c            4   20:50:40   \n",
       "4  001a5689fc            w21z3     48290  de18b671            3   20:05:42   \n",
       "\n",
       "  order_day  chain_id vendor_geohash cuisine_origin  vendor_rating  \\\n",
       "0   10 days  ef3142e8          w21zu      malaysian            3.5   \n",
       "1   85 days  8c51e46b          w21z6        chinese            3.9   \n",
       "2   78 days  dd69fe77          w21z3    singaporean            4.5   \n",
       "3   40 days  c59edb7d          w21z9         snacks            4.0   \n",
       "4   53 days  f88ffd2b          w21z3       american            4.5   \n",
       "\n",
       "   num_products  total_order_value  \\\n",
       "0             1                5.6   \n",
       "1             4                8.0   \n",
       "2             1                2.4   \n",
       "3             1                1.6   \n",
       "4             1                4.0   \n",
       "\n",
       "                                    products_ordered  \n",
       "0                                 Seafood Fried Rice  \n",
       "1  Bean Curd Skin 凉拌腐竹, Dried Beancurd 凉拌素鸡, Blac...  \n",
       "2                                Carrot Cake (Melur)  \n",
       "3                               Served without Fries  \n",
       "4                                      WHOPPER® Meal  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full_data2 includes 1 row per order. This is used for vendor ratings.\n",
    "vendor_ratings_path = \"~/code/Alanoudis/food-delivery-rec/notebooks/alanoud/feature-engineering/Alshaimas-rating/vendor_ratings.csv\"\n",
    "full_data2 = pd.read_csv(vendor_ratings_path)\n",
    "full_data2 = full_data2.rename(columns={'avg_vendor_rating': 'vendor_rating'})\n",
    "full_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b741b10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_geohash</th>\n",
       "      <th>order_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_day</th>\n",
       "      <th>name</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>...</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>meal_of_day</th>\n",
       "      <th>order_hour_sin</th>\n",
       "      <th>order_hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>783e85338f1c</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>japanese garlic karaage don</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>084ab73246e6</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>chicken cutlet don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>30eba3cc2676</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>beef sukiyaki don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>3910309eea60</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>japanese beef yakiniku don</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ba124d4e5</td>\n",
       "      <td>w21z7</td>\n",
       "      <td>0</td>\n",
       "      <td>212753d2</td>\n",
       "      <td>20049fb602cb</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 12:03:29</td>\n",
       "      <td>85</td>\n",
       "      <td>teriyaki salmon don</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>lunch</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id customer_geohash  order_id vendor_id    product_id  day_of_week  \\\n",
       "0  1ba124d4e5            w21z7         0  212753d2  783e85338f1c            0   \n",
       "1  1ba124d4e5            w21z7         0  212753d2  084ab73246e6            0   \n",
       "2  1ba124d4e5            w21z7         0  212753d2  30eba3cc2676            0   \n",
       "3  1ba124d4e5            w21z7         0  212753d2  3910309eea60            0   \n",
       "4  1ba124d4e5            w21z7         0  212753d2  20049fb602cb            0   \n",
       "\n",
       "            order_time  order_day                         name  unit_price  \\\n",
       "0  1900-01-01 12:03:29         85  japanese garlic karaage don         6.0   \n",
       "1  1900-01-01 12:03:29         85           chicken cutlet don         6.8   \n",
       "2  1900-01-01 12:03:29         85            beef sukiyaki don         6.8   \n",
       "3  1900-01-01 12:03:29         85   japanese beef yakiniku don         6.8   \n",
       "4  1900-01-01 12:03:29         85          teriyaki salmon don         8.0   \n",
       "\n",
       "   ...  dow_1  dow_2  dow_3  dow_4  dow_5  dow_6  order_hour  meal_of_day  \\\n",
       "0  ...  False  False  False  False  False  False          12        lunch   \n",
       "1  ...  False  False  False  False  False  False          12        lunch   \n",
       "2  ...  False  False  False  False  False  False          12        lunch   \n",
       "3  ...  False  False  False  False  False  False          12        lunch   \n",
       "4  ...  False  False  False  False  False  False          12        lunch   \n",
       "\n",
       "   order_hour_sin  order_hour_cos  \n",
       "0    1.224647e-16            -1.0  \n",
       "1    1.224647e-16            -1.0  \n",
       "2    1.224647e-16            -1.0  \n",
       "3    1.224647e-16            -1.0  \n",
       "4    1.224647e-16            -1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = full_data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb910128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! order_frequency and product_rating added between unit_price and chain_id\n",
      "full_data now has 27 columns\n"
     ]
    }
   ],
   "source": [
    "# add products rating to full_data\n",
    "# One-line solution:\n",
    "# Insert 'order_frequency' before 'product_rating'\n",
    "full_data.insert(full_data.columns.get_loc('chain_id'), 'order_frequency', full_data100k['order_frequency'])\n",
    "\n",
    "# Then insert 'product_rating' right after it\n",
    "full_data.insert(full_data.columns.get_loc('chain_id'), 'product_rating', full_data100k['product_rating'])\n",
    "\n",
    "print(\"✅ Done! order_frequency and product_rating added between unit_price and chain_id\")\n",
    "print(f\"full_data now has {full_data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59097fde",
   "metadata": {},
   "source": [
    "## Inspect both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28fd4a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (100000, 27)\n",
      "\n",
      "Unique counts:\n",
      "Customers: 11174\n",
      "Vendors: 5818\n",
      "Cuisines: 18\n",
      "Orders: 49029\n",
      "\n",
      "Rating distribution:\n",
      "product_rating\n",
      "1.0    10733\n",
      "2.0    13319\n",
      "3.0    17395\n",
      "4.0    18578\n",
      "5.0    39974\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Vendor ratings shape: (49029, 14)\n",
      "Vendor ratings columns: ['customer_id', 'customer_geohash', 'order_id', 'vendor_id', 'day_of_week', 'order_time', 'order_day', 'chain_id', 'vendor_geohash', 'cuisine_origin', 'vendor_rating', 'num_products', 'total_order_value', 'products_ordered']\n",
      "Vendor ratings stats:\n",
      "count    49029.000000\n",
      "mean         4.073067\n",
      "std          0.368664\n",
      "min          2.500000\n",
      "25%          3.900000\n",
      "50%          4.000000\n",
      "75%          4.400000\n",
      "max          5.000000\n",
      "Name: vendor_rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Quick data exploration\n",
    "print(\"Data shape:\", full_data.shape)\n",
    "print(\"\\nUnique counts:\")\n",
    "print(f\"Customers: {full_data['customer_id'].nunique()}\")\n",
    "print(f\"Vendors: {full_data['vendor_id'].nunique()}\")\n",
    "print(f\"Cuisines: {full_data['cuisine_origin'].nunique()}\")\n",
    "print(f\"Orders: {full_data['order_id'].nunique()}\")\n",
    "\n",
    "print(\"\\nRating distribution:\")\n",
    "print(full_data['product_rating'].value_counts().sort_index())\n",
    "\n",
    "# Check vendor_ratings dataframe\n",
    "print(f\"\\nVendor ratings shape: {full_data2.shape}\")\n",
    "print(f\"Vendor ratings columns: {full_data2.columns.tolist()}\")\n",
    "print(f\"Vendor ratings stats:\")\n",
    "print(full_data2['vendor_rating'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc00052",
   "metadata": {},
   "source": [
    "# 1. Implicit Feedback Matrix Features:\n",
    "Weighted scores combining order frequency and ratings (Use orders as strong preference signals).\n",
    "\n",
    "User-Vendor matrix: Interaction strength between customers and vendors (Customer’s favorite restaurants based on order frequency)\n",
    "\n",
    "User-Cuisine matrix: Preference strength for cuisine types (“Who likes which types of food?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e3bf83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa2bbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id          0\n",
       "customer_geohash     0\n",
       "order_id             0\n",
       "vendor_id            0\n",
       "product_id           0\n",
       "day_of_week          0\n",
       "order_time           0\n",
       "order_day            0\n",
       "name                32\n",
       "unit_price           0\n",
       "chain_id             0\n",
       "vendor_geohash       0\n",
       "cuisine_origin       0\n",
       "is_weekend           0\n",
       "dow_0                0\n",
       "dow_1                0\n",
       "dow_2                0\n",
       "dow_3                0\n",
       "dow_4                0\n",
       "dow_5                0\n",
       "dow_6                0\n",
       "order_hour           0\n",
       "meal_of_day          0\n",
       "order_hour_sin       0\n",
       "order_hour_cos       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c970186c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "customer_geohash    0\n",
       "order_id            0\n",
       "vendor_id           0\n",
       "product_id          0\n",
       "day_of_week         0\n",
       "order_time          0\n",
       "order_day           0\n",
       "name                0\n",
       "unit_price          0\n",
       "chain_id            0\n",
       "vendor_geohash      0\n",
       "cuisine_origin      0\n",
       "is_weekend          0\n",
       "dow_0               0\n",
       "dow_1               0\n",
       "dow_2               0\n",
       "dow_3               0\n",
       "dow_4               0\n",
       "dow_5               0\n",
       "dow_6               0\n",
       "order_hour          0\n",
       "meal_of_day         0\n",
       "order_hour_sin      0\n",
       "order_hour_cos      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a351248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'customer_geohash', 'order_id', 'vendor_id',\n",
       "       'product_id', 'day_of_week', 'order_time', 'order_day', 'name',\n",
       "       'unit_price', 'order_frequency', 'product_rating', 'chain_id',\n",
       "       'vendor_geohash', 'cuisine_origin', 'is_weekend', 'dow_0', 'dow_1',\n",
       "       'dow_2', 'dow_3', 'dow_4', 'dow_5', 'dow_6', 'order_hour',\n",
       "       'meal_of_day', 'order_hour_sin', 'order_hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28e3ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 27 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   customer_id       100000 non-null  object \n",
      " 1   customer_geohash  100000 non-null  object \n",
      " 2   order_id          100000 non-null  int64  \n",
      " 3   vendor_id         100000 non-null  object \n",
      " 4   product_id        100000 non-null  object \n",
      " 5   day_of_week       100000 non-null  int64  \n",
      " 6   order_time        100000 non-null  object \n",
      " 7   order_day         100000 non-null  int64  \n",
      " 8   name              99968 non-null   object \n",
      " 9   unit_price        100000 non-null  float64\n",
      " 10  order_frequency   99999 non-null   float64\n",
      " 11  product_rating    99999 non-null   float64\n",
      " 12  chain_id          100000 non-null  object \n",
      " 13  vendor_geohash    100000 non-null  object \n",
      " 14  cuisine_origin    100000 non-null  object \n",
      " 15  is_weekend        100000 non-null  int64  \n",
      " 16  dow_0             100000 non-null  bool   \n",
      " 17  dow_1             100000 non-null  bool   \n",
      " 18  dow_2             100000 non-null  bool   \n",
      " 19  dow_3             100000 non-null  bool   \n",
      " 20  dow_4             100000 non-null  bool   \n",
      " 21  dow_5             100000 non-null  bool   \n",
      " 22  dow_6             100000 non-null  bool   \n",
      " 23  order_hour        100000 non-null  int64  \n",
      " 24  meal_of_day       100000 non-null  object \n",
      " 25  order_hour_sin    100000 non-null  float64\n",
      " 26  order_hour_cos    100000 non-null  float64\n",
      "dtypes: bool(7), float64(5), int64(5), object(10)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139f8f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_geohash</th>\n",
       "      <th>order_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_day</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>vendor_geohash</th>\n",
       "      <th>cuisine_origin</th>\n",
       "      <th>vendor_rating</th>\n",
       "      <th>num_products</th>\n",
       "      <th>total_order_value</th>\n",
       "      <th>products_ordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00119c8178</td>\n",
       "      <td>w21zu</td>\n",
       "      <td>39095</td>\n",
       "      <td>e7cb5902</td>\n",
       "      <td>2</td>\n",
       "      <td>16:30:07</td>\n",
       "      <td>10 days</td>\n",
       "      <td>ef3142e8</td>\n",
       "      <td>w21zu</td>\n",
       "      <td>malaysian</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Seafood Fried Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00198e01e4</td>\n",
       "      <td>w21z6</td>\n",
       "      <td>35939</td>\n",
       "      <td>02acaff6</td>\n",
       "      <td>0</td>\n",
       "      <td>13:57:35</td>\n",
       "      <td>85 days</td>\n",
       "      <td>8c51e46b</td>\n",
       "      <td>w21z6</td>\n",
       "      <td>chinese</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bean Curd Skin 凉拌腐竹, Dried Beancurd 凉拌素鸡, Blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001a5689fc</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>48288</td>\n",
       "      <td>a2c60e71</td>\n",
       "      <td>0</td>\n",
       "      <td>20:10:35</td>\n",
       "      <td>78 days</td>\n",
       "      <td>dd69fe77</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>singaporean</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Carrot Cake (Melur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001a5689fc</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>48289</td>\n",
       "      <td>a3bc472c</td>\n",
       "      <td>4</td>\n",
       "      <td>20:50:40</td>\n",
       "      <td>40 days</td>\n",
       "      <td>c59edb7d</td>\n",
       "      <td>w21z9</td>\n",
       "      <td>snacks</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Served without Fries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5689fc</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>48290</td>\n",
       "      <td>de18b671</td>\n",
       "      <td>3</td>\n",
       "      <td>20:05:42</td>\n",
       "      <td>53 days</td>\n",
       "      <td>f88ffd2b</td>\n",
       "      <td>w21z3</td>\n",
       "      <td>american</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WHOPPER® Meal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id customer_geohash  order_id vendor_id  day_of_week order_time  \\\n",
       "0  00119c8178            w21zu     39095  e7cb5902            2   16:30:07   \n",
       "1  00198e01e4            w21z6     35939  02acaff6            0   13:57:35   \n",
       "2  001a5689fc            w21z3     48288  a2c60e71            0   20:10:35   \n",
       "3  001a5689fc            w21z3     48289  a3bc472c            4   20:50:40   \n",
       "4  001a5689fc            w21z3     48290  de18b671            3   20:05:42   \n",
       "\n",
       "  order_day  chain_id vendor_geohash cuisine_origin  vendor_rating  \\\n",
       "0   10 days  ef3142e8          w21zu      malaysian            3.5   \n",
       "1   85 days  8c51e46b          w21z6        chinese            3.9   \n",
       "2   78 days  dd69fe77          w21z3    singaporean            4.5   \n",
       "3   40 days  c59edb7d          w21z9         snacks            4.0   \n",
       "4   53 days  f88ffd2b          w21z3       american            4.5   \n",
       "\n",
       "   num_products  total_order_value  \\\n",
       "0             1                5.6   \n",
       "1             4                8.0   \n",
       "2             1                2.4   \n",
       "3             1                1.6   \n",
       "4             1                4.0   \n",
       "\n",
       "                                    products_ordered  \n",
       "0                                 Seafood Fried Rice  \n",
       "1  Bean Curd Skin 凉拌腐竹, Dried Beancurd 凉拌素鸡, Blac...  \n",
       "2                                Carrot Cake (Melur)  \n",
       "3                               Served without Fries  \n",
       "4                                      WHOPPER® Meal  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20142e77",
   "metadata": {},
   "source": [
    "# Cell 1: Enhanced Data Preprocessing & Feature Engineering\n",
    "### Purpose: This cell performs comprehensive data preprocessing, filtering, and feature engineering to create clean, structured data for the recommendation system. It merges datasets, filters low-quality interactions, and creates aggregated features for users and vendors.\n",
    "What it does:\n",
    "\n",
    "- Merges order data with vendor ratings and details\n",
    "\n",
    "- Filters out low-rated orders (rating < 3) and inactive users/vendors\n",
    "\n",
    "- Creates order-level aggregated features (total value, item count, etc.)\n",
    "\n",
    "- Builds vendor profiles with cuisine, ratings, and activity metrics\n",
    "\n",
    "- Ensures data quality by removing sparse entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf75403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 ENHANCED FOOD DELIVERY RECOMMENDER\n",
      "==================================================\n",
      "Step 1: Enhanced Data Preprocessing...\n",
      "📊 Merging vendor ratings and order details...\n",
      "   Enhanced data shape: (100000, 30)\n",
      "⭐ Filtering by rating >= 3.5 (quality focus)...\n",
      "   After rating filter: (58552, 30)\n",
      "🔧 Creating order-level features...\n",
      "   Order-level data shape: (35622, 19)\n",
      "👥 Activity filtering: users >= 2 orders, vendors >= 10 orders...\n",
      "   After activity filtering: (17655, 19)\n",
      "   Active users: 5,156, Active vendors: 1,328\n",
      "🏪 Creating vendor features with rating focus...\n",
      "   Vendor features shape: (5394, 7)\n",
      "✅ Data preprocessing completed successfully!\n",
      "📈 Final dataset: 17,655 orders, 4,283 users, 1,328 vendors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 ENHANCED FOOD DELIVERY RECOMMENDER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# =============================================\n",
    "# ENHANCED DATA PREPROCESSING\n",
    "# =============================================\n",
    "\n",
    "print(\"Step 1: Enhanced Data Preprocessing...\")\n",
    "\n",
    "def enhanced_data_preprocessing(full_data, full_data2, min_rating=3.5, min_user_orders=2, min_vendor_orders=10):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing with activity filtering and rating optimization\n",
    "    Now using min_rating=3.5 to focus on higher quality interactions\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge vendor ratings\n",
    "    print(\"📊 Merging vendor ratings and order details...\")\n",
    "    full_data_enhanced = full_data.merge(\n",
    "        full_data2[['order_id', 'vendor_id', 'vendor_rating', 'total_order_value', 'num_products']],\n",
    "        on=['order_id', 'vendor_id'],\n",
    "        how='left',\n",
    "        suffixes=('', '_vendor')\n",
    "    )\n",
    "    print(f\"   Enhanced data shape: {full_data_enhanced.shape}\")\n",
    "\n",
    "    # Filter by rating (OPTIMIZED: using 3.5+ stars for better quality)\n",
    "    print(f\"⭐ Filtering by rating >= {min_rating} (quality focus)...\")\n",
    "    data_filtered = full_data_enhanced[full_data_enhanced['product_rating'] >= min_rating].copy()\n",
    "    print(f\"   After rating filter: {data_filtered.shape}\")\n",
    "\n",
    "    # Create order-level features\n",
    "    print(\"🔧 Creating order-level features...\")\n",
    "    order_level_data = data_filtered.groupby('order_id').agg({\n",
    "        'customer_id': 'first',\n",
    "        'vendor_id': 'first',\n",
    "        'cuisine_origin': 'first',\n",
    "        'day_of_week': 'first',\n",
    "        'order_day': 'first',\n",
    "        'order_hour': 'first',\n",
    "        'meal_of_day': 'first',\n",
    "        'is_weekend': 'first',\n",
    "        'unit_price': 'sum',\n",
    "        'product_id': 'count',\n",
    "        'product_rating': 'mean',\n",
    "        'vendor_rating': 'first',\n",
    "        'order_frequency': 'first',\n",
    "        'total_order_value': 'first',\n",
    "        'num_products': 'first',\n",
    "        'customer_geohash': 'first',\n",
    "        'vendor_geohash': 'first'\n",
    "    }).rename(columns={\n",
    "        'product_id': 'num_items',\n",
    "        'product_rating': 'avg_product_rating',\n",
    "        'unit_price': 'total_order_value_calculated'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Handle order value calculation\n",
    "    order_level_data['final_order_value'] = order_level_data['total_order_value'].fillna(\n",
    "        order_level_data['total_order_value_calculated']\n",
    "    )\n",
    "    print(f\"   Order-level data shape: {order_level_data.shape}\")\n",
    "\n",
    "    # FILTER LOW-ACTIVITY USERS AND VENDORS\n",
    "    print(f\"👥 Activity filtering: users >= {min_user_orders} orders, vendors >= {min_vendor_orders} orders...\")\n",
    "\n",
    "    user_orders = order_level_data['customer_id'].value_counts()\n",
    "    active_users = user_orders[user_orders >= min_user_orders].index\n",
    "    vendor_orders = order_level_data['vendor_id'].value_counts()\n",
    "    active_vendors = vendor_orders[vendor_orders >= min_vendor_orders].index\n",
    "\n",
    "    order_level_data = order_level_data[\n",
    "        order_level_data['customer_id'].isin(active_users) &\n",
    "        order_level_data['vendor_id'].isin(active_vendors)\n",
    "    ]\n",
    "\n",
    "    print(f\"   After activity filtering: {order_level_data.shape}\")\n",
    "    print(f\"   Active users: {len(active_users):,}, Active vendors: {len(active_vendors):,}\")\n",
    "\n",
    "    # Create enhanced vendor features\n",
    "    print(\"🏪 Creating vendor features with rating focus...\")\n",
    "    vendor_features = data_filtered.groupby('vendor_id').agg({\n",
    "        'cuisine_origin': 'first',\n",
    "        'vendor_geohash': 'first',\n",
    "        'vendor_rating': 'mean',\n",
    "        'product_rating': ['mean', 'count'],\n",
    "        'order_id': 'nunique'\n",
    "    }).reset_index()\n",
    "\n",
    "    vendor_features.columns = [\n",
    "        'vendor_id', 'cuisine_origin', 'vendor_geohash',\n",
    "        'avg_vendor_rating', 'avg_product_rating', 'total_products', 'total_orders'\n",
    "    ]\n",
    "\n",
    "    # Filter vendors to only include those with good ratings (3.5+)\n",
    "    vendor_features = vendor_features[vendor_features['avg_vendor_rating'] >= 3.5]\n",
    "    print(f\"   Vendor features shape: {vendor_features.shape}\")\n",
    "\n",
    "    return order_level_data, vendor_features\n",
    "\n",
    "# Apply enhanced preprocessing with 3.5+ star rating filter\n",
    "order_level_data, vendor_features = enhanced_data_preprocessing(\n",
    "    full_data, full_data2, min_rating=3.5, min_user_orders=2, min_vendor_orders=10\n",
    ")\n",
    "\n",
    "print(\"✅ Data preprocessing completed successfully!\")\n",
    "print(f\"📈 Final dataset: {order_level_data.shape[0]:,} orders, {order_level_data['customer_id'].nunique():,} users, {order_level_data['vendor_id'].nunique():,} vendors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048d8de",
   "metadata": {},
   "source": [
    "# Cell 2: Enhanced Interaction Matrices & Preference Scoring\n",
    "### Purpose: This cell creates sophisticated interaction matrices that capture user preferences using multiple factors including frequency, ratings, recency, and monetary value. These matrices form the foundation for both collaborative and content-based filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91add10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Building Enhanced Interaction Matrices...\n",
      "   Creating user-vendor interactions with multi-factor scoring...\n",
      "   Creating user-cuisine preference matrix...\n",
      "✅ User-Vendor Matrix: (4283, 1328)\n",
      "✅ User-Cuisine Matrix: (4283, 14)\n",
      "📊 Matrix Statistics:\n",
      "   - Total possible interactions: 5,687,824\n",
      "   - Actual interactions: 11,014\n",
      "   - Data Sparsity: 0.9981 (99.81%)\n",
      "   - Average user interactions: 2.57\n",
      "   - Score range: 0.286 - 0.885\n",
      "   - Sample enhanced scores:\n",
      "     Min: 0.286, Mean: 0.416, Max: 0.885\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ENHANCED INTERACTION MATRICES\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nStep 2: Building Enhanced Interaction Matrices...\")\n",
    "\n",
    "def create_enhanced_interaction_matrices(df):\n",
    "    \"\"\"\n",
    "    Create interaction matrices with optimized scoring weights\n",
    "    Enhanced with better factor balancing and temporal patterns\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"   Creating user-vendor interactions with multi-factor scoring...\")\n",
    "\n",
    "    # 1. Enhanced User-Vendor Matrix with optimized factor weights\n",
    "    user_vendor_interactions = df.groupby(['customer_id', 'vendor_id']).agg({\n",
    "        'num_items': 'sum',\n",
    "        'avg_product_rating': 'mean',\n",
    "        'vendor_rating': 'mean',\n",
    "        'order_id': 'count',\n",
    "        'final_order_value': 'mean',  # Monetary value\n",
    "        'order_day': 'max'  # Recency\n",
    "    }).reset_index()\n",
    "\n",
    "    # Calculate recency score (more recent = higher score)\n",
    "    max_order_day = user_vendor_interactions['order_day'].max()\n",
    "    user_vendor_interactions['recency_score'] = 1 - (\n",
    "        (max_order_day - user_vendor_interactions['order_day']) /\n",
    "        (max_order_day - user_vendor_interactions['order_day'].min() + 1)\n",
    "    )\n",
    "\n",
    "    # OPTIMIZED: Enhanced weighted score with balanced factors\n",
    "    # Weights: Frequency(40%), Product Quality(20%), Vendor Quality(20%), Recency(10%), Monetary(10%)\n",
    "    user_vendor_interactions['enhanced_score'] = (\n",
    "        (user_vendor_interactions['order_id'] / user_vendor_interactions['order_id'].max()) * 0.4 +  # Frequency\n",
    "        (user_vendor_interactions['avg_product_rating'] / 5.0) * 0.2 +  # Product quality\n",
    "        (user_vendor_interactions['vendor_rating'] / 5.0) * 0.2 +  # Vendor quality\n",
    "        user_vendor_interactions['recency_score'] * 0.1 +  # Recency\n",
    "        (user_vendor_interactions['final_order_value'] / user_vendor_interactions['final_order_value'].max()) * 0.1  # Monetary\n",
    "    )\n",
    "\n",
    "    # Ensure scores are normalized between 0-1\n",
    "    user_vendor_interactions['enhanced_score'] = user_vendor_interactions['enhanced_score'].clip(0, 1)\n",
    "\n",
    "    user_vendor_matrix = user_vendor_interactions.pivot_table(\n",
    "        index='customer_id',\n",
    "        columns='vendor_id',\n",
    "        values='enhanced_score',\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    print(\"   Creating user-cuisine preference matrix...\")\n",
    "\n",
    "    # 2. User-Cuisine Matrix with temporal patterns and meal preferences\n",
    "    user_cuisine_interactions = df.groupby(['customer_id', 'cuisine_origin']).agg({\n",
    "        'order_id': 'count',\n",
    "        'avg_product_rating': 'mean',\n",
    "        'vendor_rating': 'mean',\n",
    "        'meal_of_day': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'lunch',\n",
    "        'is_weekend': 'mean'  # Weekend preference for this cuisine\n",
    "    }).reset_index()\n",
    "\n",
    "    # Enhanced cuisine preference score\n",
    "    user_cuisine_interactions['preference_score'] = (\n",
    "        (user_cuisine_interactions['order_id'] / user_cuisine_interactions.groupby('customer_id')['order_id'].transform('sum')) * 0.5 +  # Relative frequency\n",
    "        (user_cuisine_interactions['avg_product_rating'] / 5.0) * 0.3 +  # Quality\n",
    "        (user_cuisine_interactions['vendor_rating'] / 5.0) * 0.2  # Vendor quality\n",
    "    )\n",
    "\n",
    "    user_cuisine_matrix = user_cuisine_interactions.pivot_table(\n",
    "        index='customer_id',\n",
    "        columns='cuisine_origin',\n",
    "        values='preference_score',\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'user_vendor': user_vendor_matrix,\n",
    "        'user_cuisine': user_cuisine_matrix,\n",
    "        'raw_interactions': user_vendor_interactions,\n",
    "        'cuisine_interactions': user_cuisine_interactions\n",
    "    }\n",
    "\n",
    "# Create enhanced matrices\n",
    "matrices = create_enhanced_interaction_matrices(order_level_data)\n",
    "user_vendor_matrix = matrices['user_vendor']\n",
    "user_cuisine_matrix = matrices['user_cuisine']\n",
    "user_vendor_interactions = matrices['raw_interactions']\n",
    "\n",
    "print(f\"✅ User-Vendor Matrix: {user_vendor_matrix.shape}\")\n",
    "print(f\"✅ User-Cuisine Matrix: {user_cuisine_matrix.shape}\")\n",
    "\n",
    "# Calculate and display matrix statistics\n",
    "total_interactions = user_vendor_matrix.shape[0] * user_vendor_matrix.shape[1]\n",
    "actual_interactions = (user_vendor_matrix > 0).sum().sum()\n",
    "sparsity = 1 - (actual_interactions / total_interactions)\n",
    "\n",
    "print(f\"📊 Matrix Statistics:\")\n",
    "print(f\"   - Total possible interactions: {total_interactions:,}\")\n",
    "print(f\"   - Actual interactions: {actual_interactions:,}\")\n",
    "print(f\"   - Data Sparsity: {sparsity:.4f} ({sparsity*100:.2f}%)\")\n",
    "print(f\"   - Average user interactions: {actual_interactions / user_vendor_matrix.shape[0]:.2f}\")\n",
    "print(f\"   - Score range: {user_vendor_interactions['enhanced_score'].min():.3f} - {user_vendor_interactions['enhanced_score'].max():.3f}\")\n",
    "\n",
    "# Show sample of interaction scores\n",
    "print(f\"   - Sample enhanced scores:\")\n",
    "sample_scores = user_vendor_interactions['enhanced_score'].describe()\n",
    "print(f\"     Min: {sample_scores['min']:.3f}, Mean: {sample_scores['mean']:.3f}, Max: {sample_scores['max']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46fc010",
   "metadata": {},
   "source": [
    "# Cell 3: Enhanced Collaborative Filtering with ALS\n",
    "### Purpose: This cell trains the Alternating Least Squares (ALS) model for collaborative filtering, which learns latent factors from user-vendor interactions to predict user preferences. The enhanced version includes adaptive parameter tuning based on data sparsity and better model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b0ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Training Enhanced Collaborative Filtering...\n",
      "Training ALS: 32 factors, 20 iterations, regularization=0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60683593d33e493aafef1c94ef4f4824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model: (4283, 32) user factors, (1328, 32) item factors\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ENHANCED COLLABORATIVE FILTERING\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nStep 3: Training Enhanced Collaborative Filtering...\")\n",
    "\n",
    "def train_enhanced_als(interaction_matrix, factors=64, iterations=20, regularization=0.1):\n",
    "    \"\"\"Train ALS with better parameters for sparse data\"\"\"\n",
    "\n",
    "    sparse_matrix = csr_matrix(interaction_matrix.values)\n",
    "\n",
    "    # Adjust parameters based on sparsity\n",
    "    n_users, n_items = interaction_matrix.shape\n",
    "    sparsity = 1 - (sparse_matrix.nnz / (n_users * n_items))\n",
    "\n",
    "    # Use more factors and regularization for sparse data\n",
    "    if sparsity > 0.99:\n",
    "        factors = 32  # Reduce factors for very sparse data\n",
    "        regularization = 0.2\n",
    "\n",
    "    print(f\"Training ALS: {factors} factors, {iterations} iterations, regularization={regularization}\")\n",
    "\n",
    "    als_model = AlternatingLeastSquares(\n",
    "        factors=factors,\n",
    "        iterations=iterations,\n",
    "        regularization=regularization,\n",
    "        random_state=42,\n",
    "        use_gpu=False\n",
    "    )\n",
    "\n",
    "    als_model.fit(sparse_matrix * 10)  # Scale to improve performance\n",
    "\n",
    "    return als_model, sparse_matrix\n",
    "\n",
    "als_model, sparse_matrix = train_enhanced_als(user_vendor_matrix)\n",
    "print(f\"ALS Model: {als_model.user_factors.shape} user factors, {als_model.item_factors.shape} item factors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd391496",
   "metadata": {},
   "source": [
    "# Cell 4: Enhanced User Profiling & Behavioral Clustering\n",
    "### Purpose: This cell creates comprehensive user profiles by analyzing cuisine preferences, behavioral patterns, and ordering habits. It then performs customer segmentation using clustering to group similar users for better personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================\n",
    "# # ENHANCED USER PROFILES & BEHAVIORAL CLUSTERING\n",
    "# # =============================================\n",
    "\n",
    "# print(\"\\nStep 4: Building Enhanced User Profiles & Behavioral Clustering...\")\n",
    "\n",
    "# def create_enhanced_user_profiles(df):\n",
    "#     \"\"\"\n",
    "#     Create comprehensive user profiles with cuisine preferences and behavioral patterns\n",
    "#     Enhanced with better preference scoring and temporal analysis\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"   Analyzing user cuisine preferences...\")\n",
    "\n",
    "#     # 1. Enhanced Cuisine Preferences with weighted scoring\n",
    "#     cuisine_prefs = df.groupby(['customer_id', 'cuisine_origin']).agg({\n",
    "#         'order_id': 'count',\n",
    "#         'avg_product_rating': 'mean',\n",
    "#         'vendor_rating': 'mean',\n",
    "#         'final_order_value': 'mean',\n",
    "#         'meal_of_day': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'lunch',\n",
    "#         'order_day': 'max'  # For recency\n",
    "#     }).reset_index()\n",
    "\n",
    "#     # Calculate recency for cuisine preferences\n",
    "#     max_day = cuisine_prefs['order_day'].max()\n",
    "#     cuisine_prefs['cuisine_recency'] = 1 - ((max_day - cuisine_prefs['order_day']) / (max_day - cuisine_prefs['order_day'].min() + 1))\n",
    "\n",
    "#     # Enhanced preference scoring with recency and value factors\n",
    "#     cuisine_prefs['preference_score'] = (\n",
    "#         (cuisine_prefs['order_id'] / cuisine_prefs.groupby('customer_id')['order_id'].transform('sum')) * 0.4 +  # Relative frequency\n",
    "#         (cuisine_prefs['avg_product_rating'] / 5.0) * 0.3 +  # Quality preference\n",
    "#         (cuisine_prefs['vendor_rating'] / 5.0) * 0.2 +  # Vendor quality\n",
    "#         cuisine_prefs['cuisine_recency'] * 0.1  # Recency bias\n",
    "#     )\n",
    "\n",
    "#     # Normalize by user to get preference distribution\n",
    "#     user_totals = cuisine_prefs.groupby('customer_id')['preference_score'].transform('sum')\n",
    "#     cuisine_prefs['normalized_score'] = cuisine_prefs['preference_score'] / (user_totals + 1e-8)  # Avoid division by zero\n",
    "\n",
    "#     user_cuisine_profiles = cuisine_prefs.pivot_table(\n",
    "#         index='customer_id',\n",
    "#         columns='cuisine_origin',\n",
    "#         values='normalized_score',\n",
    "#         fill_value=0\n",
    "#     )\n",
    "\n",
    "#     print(\"   Building behavioral profiles...\")\n",
    "\n",
    "#     # 2. Enhanced Behavioral Profiles with comprehensive features\n",
    "#     behavioral_profiles = df.groupby('customer_id').agg({\n",
    "#         'order_hour': ['mean', 'std', lambda x: x.mode()[0] if len(x.mode()) > 0 else 12],  # Peak hour\n",
    "#         'is_weekend': 'mean',\n",
    "#         'day_of_week': lambda x: x.mode()[0] if len(x.mode()) > 0 else 3,  # Favorite day\n",
    "#         'meal_of_day': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'lunch',\n",
    "#         'final_order_value': ['mean', 'std', 'max', 'min'],\n",
    "#         'num_items': ['mean', 'sum'],\n",
    "#         'order_id': 'count',\n",
    "#         'order_frequency': 'mean',\n",
    "#         'vendor_rating': 'mean',\n",
    "#         'avg_product_rating': 'mean',\n",
    "#         'order_day': ['min', 'max'],  # Customer tenure\n",
    "#         'vendor_id': 'nunique'  # Variety seeking\n",
    "#     }).reset_index()\n",
    "\n",
    "#     # Flatten column names\n",
    "#     behavioral_profiles.columns = [\n",
    "#         'customer_id', 'avg_order_hour', 'std_order_hour', 'peak_order_hour',\n",
    "#         'weekend_ratio', 'fav_day', 'fav_meal', 'avg_order_value', 'std_order_value',\n",
    "#         'max_order_value', 'min_order_value', 'avg_items_per_order', 'total_items',\n",
    "#         'total_orders', 'avg_order_frequency', 'avg_vendor_rating_choice',\n",
    "#         'avg_product_rating_given', 'first_order_day', 'last_order_day', 'unique_vendors_tried'\n",
    "#     ]\n",
    "\n",
    "#     # Calculate enhanced behavioral metrics\n",
    "#     behavioral_profiles['customer_tenure'] = behavioral_profiles['last_order_day'] - behavioral_profiles['first_order_day']\n",
    "#     behavioral_profiles['order_value_consistency'] = 1 / (behavioral_profiles['std_order_value'] + 1)  # Higher = more consistent\n",
    "#     behavioral_profiles['variety_seeking'] = behavioral_profiles['unique_vendors_tried'] / behavioral_profiles['total_orders']\n",
    "#     behavioral_profiles['avg_order_size'] = behavioral_profiles['total_items'] / behavioral_profiles['total_orders']\n",
    "\n",
    "#     print(\"   Combining profiles...\")\n",
    "\n",
    "#     # 3. Combine profiles\n",
    "#     user_profiles = user_cuisine_profiles.reset_index()\n",
    "#     user_profiles = user_profiles.merge(behavioral_profiles, on='customer_id', how='left')\n",
    "\n",
    "#     return user_profiles.fillna(0)\n",
    "\n",
    "# # Create enhanced user profiles\n",
    "# user_profiles = create_enhanced_user_profiles(order_level_data)\n",
    "# print(f\"✅ Enhanced user profiles shape: {user_profiles.shape}\")\n",
    "\n",
    "# # Enhanced Clustering with Better Feature Selection\n",
    "# def create_enhanced_clusters(user_profiles, max_clusters=8):\n",
    "#     \"\"\"\n",
    "#     Create customer segments using key behavioral features\n",
    "#     Enhanced with outlier detection and optimal cluster selection\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"   Performing customer segmentation...\")\n",
    "\n",
    "#     # Select key behavioral features for clustering\n",
    "#     key_features = [\n",
    "#         'avg_order_value', 'total_orders', 'weekend_ratio', 'avg_order_hour',\n",
    "#         'avg_items_per_order', 'customer_tenure', 'avg_vendor_rating_choice',\n",
    "#         'variety_seeking', 'order_value_consistency'\n",
    "#     ]\n",
    "\n",
    "#     # Only use features that exist and have variance\n",
    "#     available_features = []\n",
    "#     for f in key_features:\n",
    "#         if f in user_profiles.columns:\n",
    "#             if user_profiles[f].std() > 0.001:  # Filter near-constant features\n",
    "#                 available_features.append(f)\n",
    "\n",
    "#     print(f\"   Using {len(available_features)} features for clustering: {available_features}\")\n",
    "\n",
    "#     if len(available_features) < 3:\n",
    "#         print(\"⚠️  Not enough features for meaningful clustering\")\n",
    "#         user_profiles['user_cluster'] = 0\n",
    "#         return user_profiles, None, None\n",
    "\n",
    "#     cluster_data = user_profiles[available_features].fillna(0)\n",
    "\n",
    "#     # Remove outliers using IQR method (keep 95% of data)\n",
    "#     if len(cluster_data) > 10:\n",
    "#         Q1 = cluster_data.quantile(0.05)  # Use 5th percentile instead of 25th to be less aggressive\n",
    "#         Q3 = cluster_data.quantile(0.95)  # Use 95th percentile\n",
    "#         IQR = Q3 - Q1\n",
    "#         outlier_mask = ~((cluster_data < (Q1 - 1.5 * IQR)) | (cluster_data > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "#         cluster_data_clean = cluster_data[outlier_mask]\n",
    "#         print(f\"   Removed {len(cluster_data) - len(cluster_data_clean)} outliers\")\n",
    "#     else:\n",
    "#         cluster_data_clean = cluster_data\n",
    "\n",
    "#     if len(cluster_data_clean) < 10:\n",
    "#         print(\"⚠️  Not enough data for clustering after outlier removal\")\n",
    "#         user_profiles['user_cluster'] = 0\n",
    "#         return user_profiles, None, None\n",
    "\n",
    "#     # Standardize features\n",
    "#     scaler = StandardScaler()\n",
    "#     cluster_data_scaled = scaler.fit_transform(cluster_data_clean)\n",
    "\n",
    "#     # Find optimal number of clusters using silhouette score\n",
    "#     print(\"   Finding optimal cluster count...\")\n",
    "#     best_score = -1\n",
    "#     best_n = 2\n",
    "#     silhouette_scores = []\n",
    "\n",
    "#     max_possible = min(max_clusters, len(cluster_data_scaled) // 5)\n",
    "#     cluster_range = range(2, max_possible + 1)\n",
    "\n",
    "#     for n in cluster_range:\n",
    "#         if n >= len(cluster_data_scaled):\n",
    "#             continue\n",
    "\n",
    "#         kmeans = KMeans(n_clusters=n, random_state=42, n_init=15)\n",
    "#         labels = kmeans.fit_predict(cluster_data_scaled)\n",
    "\n",
    "#         if len(np.unique(labels)) > 1:  # Need at least 2 clusters for silhouette score\n",
    "#             score = silhouette_score(cluster_data_scaled, labels)\n",
    "#             silhouette_scores.append(score)\n",
    "\n",
    "#             if score > best_score:\n",
    "#                 best_score = score\n",
    "#                 best_n = n\n",
    "\n",
    "#     print(f\"   Optimal clusters: {best_n} (silhouette: {best_score:.3f})\")\n",
    "\n",
    "#     # Apply final clustering\n",
    "#     kmeans = KMeans(n_clusters=best_n, random_state=42, n_init=15)\n",
    "#     user_profiles['user_cluster'] = -1  # Default for outliers/non-clustered\n",
    "\n",
    "#     # Assign clusters to clean data points\n",
    "#     valid_indices = cluster_data_clean.index\n",
    "#     cluster_labels = kmeans.fit_predict(cluster_data_scaled)\n",
    "#     user_profiles.loc[valid_indices, 'user_cluster'] = cluster_labels\n",
    "\n",
    "#     # Add cluster sizes information\n",
    "#     cluster_sizes = user_profiles[user_profiles['user_cluster'] != -1]['user_cluster'].value_counts().sort_index()\n",
    "#     print(f\"   Cluster sizes: {dict(cluster_sizes)}\")\n",
    "\n",
    "#     return user_profiles, kmeans, scaler\n",
    "\n",
    "# # Perform enhanced clustering\n",
    "# user_profiles_with_clusters, cluster_model, cluster_scaler = create_enhanced_clusters(user_profiles)\n",
    "\n",
    "# print(f\"✅ Clustering completed!\")\n",
    "# print(f\"📊 User segmentation summary:\")\n",
    "# cluster_summary = user_profiles_with_clusters['user_cluster'].value_counts().sort_index()\n",
    "# for cluster_id, count in cluster_summary.items():\n",
    "#     percentage = (count / len(user_profiles_with_clusters)) * 100\n",
    "#     print(f\"   Cluster {cluster_id}: {count} users ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c1e23",
   "metadata": {},
   "source": [
    "# NEW Cell 4 simplified (no clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf95a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Creating Simplified User Profiles...\n",
      "   Building user cuisine preferences...\n",
      "   Building basic behavioral profiles...\n",
      "✅ Simplified user profiles: (4283, 19)\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# SIMPLIFIED USER PROFILES\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nStep 4: Creating Simplified User Profiles...\")\n",
    "\n",
    "def create_simplified_user_profiles(df):\n",
    "    \"\"\"Create essential user profiles without clustering complexity\"\"\"\n",
    "\n",
    "    print(\"   Building user cuisine preferences...\")\n",
    "\n",
    "    # 1. Cuisine Preferences Only (most important for content-based)\n",
    "    cuisine_prefs = df.groupby(['customer_id', 'cuisine_origin']).agg({\n",
    "        'order_id': 'count',\n",
    "        'avg_product_rating': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Simple preference scoring\n",
    "    user_total_orders = cuisine_prefs.groupby('customer_id')['order_id'].transform('sum')\n",
    "    cuisine_prefs['preference_score'] = cuisine_prefs['order_id'] / user_total_orders\n",
    "\n",
    "    user_cuisine_profiles = cuisine_prefs.pivot_table(\n",
    "        index='customer_id',\n",
    "        columns='cuisine_origin',\n",
    "        values='preference_score',\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    print(\"   Building basic behavioral profiles...\")\n",
    "\n",
    "    # 2. Basic Behavioral Features - using correct column names\n",
    "    behavioral_profiles = df.groupby('customer_id').agg({\n",
    "        'order_id': 'count',  # Total orders\n",
    "        'final_order_value': 'mean',  # Average order value\n",
    "        'vendor_id': 'nunique',  # Unique vendors tried\n",
    "        'avg_product_rating': 'mean'  # Average rating given\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    behavioral_profiles.columns = [\n",
    "        'customer_id',\n",
    "        'total_orders',\n",
    "        'avg_order_value',\n",
    "        'unique_vendors',\n",
    "        'avg_rating_given'\n",
    "    ]\n",
    "\n",
    "    # 3. Combine profiles\n",
    "    user_profiles = user_cuisine_profiles.reset_index()\n",
    "    user_profiles = user_profiles.merge(behavioral_profiles, on='customer_id', how='left')\n",
    "\n",
    "    print(f\"✅ Simplified user profiles: {user_profiles.shape}\")\n",
    "    return user_profiles.fillna(0)\n",
    "\n",
    "user_profiles = create_simplified_user_profiles(order_level_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c7871b",
   "metadata": {},
   "source": [
    "# Cell 5: Enhanced Hybrid Recommender with Optimized Ranking\n",
    "### Purpose: This cell creates the core hybrid recommendation engine that combines collaborative filtering, content-based filtering, and popularity signals with optimized weights and ranking. The enhanced version includes better score normalization, improved vendor rating filtering, and optimized ranking for evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030590fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================\n",
    "# # ENHANCED HYBRID RECOMMENDER (OPTIMIZED RANKING)\n",
    "# # =============================================\n",
    "\n",
    "# print(\"\\nStep 5: Enhanced Hybrid Recommender with Optimized Ranking...\")\n",
    "\n",
    "# class EnhancedHybridRecommender:\n",
    "#     def __init__(self, als_model, user_profiles, vendor_features, interaction_matrices):\n",
    "#         self.als_model = als_model\n",
    "#         self.user_profiles = user_profiles\n",
    "#         self.vendor_features = vendor_features.set_index('vendor_id')\n",
    "#         self.matrices = interaction_matrices\n",
    "#         self.user_vendor_matrix = interaction_matrices['user_vendor']\n",
    "\n",
    "#         # Filter vendors to only include those with 3.5+ stars (OPTIMIZED)\n",
    "#         self.vendor_features = self.vendor_features[self.vendor_features['avg_vendor_rating'] >= 3.5]\n",
    "\n",
    "#         # Align vendor features with interaction matrix\n",
    "#         self.vendor_features = self._align_vendor_features()\n",
    "\n",
    "#         # Enhanced fallback scores with rating focus\n",
    "#         self.fallback_scores = self._compute_enhanced_fallback_scores()\n",
    "#         self.user_activity_levels = self._compute_user_activity_levels()\n",
    "\n",
    "#         print(f\"✅ Recommender initialized with {len(self.vendor_features)} quality vendors (3.5+ stars)\")\n",
    "\n",
    "#     def _align_vendor_features(self):\n",
    "#         \"\"\"Ensure vendor features align with interaction matrix columns\"\"\"\n",
    "#         matrix_vendors = set(self.user_vendor_matrix.columns)\n",
    "#         feature_vendors = set(self.vendor_features.index)\n",
    "\n",
    "#         # Keep only vendors that are in both sets\n",
    "#         common_vendors = matrix_vendors.intersection(feature_vendors)\n",
    "\n",
    "#         # Filter vendor features to common vendors\n",
    "#         aligned_features = self.vendor_features.loc[list(common_vendors)]\n",
    "\n",
    "#         print(f\"   Aligned vendor features: {len(aligned_features)} vendors\")\n",
    "#         return aligned_features\n",
    "\n",
    "#     def _compute_enhanced_fallback_scores(self):\n",
    "#         \"\"\"Compute fallback scores with proper alignment and rating focus\"\"\"\n",
    "#         # Get popularity scores for aligned vendors only\n",
    "#         popularity = self.user_vendor_matrix.sum(axis=0)\n",
    "#         popularity = popularity[popularity.index.isin(self.vendor_features.index)]\n",
    "\n",
    "#         # Get vendor ratings for aligned vendors (OPTIMIZED: emphasize ratings)\n",
    "#         vendor_ratings = self.vendor_features['avg_vendor_rating']\n",
    "\n",
    "#         # Normalize scores\n",
    "#         pop_norm = popularity / popularity.max() if popularity.max() > 0 else popularity\n",
    "#         rating_norm = vendor_ratings / 5.0\n",
    "\n",
    "#         # Include novelty (inverse of popularity)\n",
    "#         novelty = 1 - pop_norm\n",
    "\n",
    "#         # OPTIMIZED: Combined score with more weight on ratings (40% rating, 30% popularity, 20% novelty, 10% product quality)\n",
    "#         product_quality = self.vendor_features['avg_product_rating'] / 5.0\n",
    "#         fallback_scores = (\n",
    "#             0.3 * pop_norm +\n",
    "#             0.4 * rating_norm +\n",
    "#             0.2 * novelty +\n",
    "#             0.1 * product_quality\n",
    "#         )\n",
    "\n",
    "#         return pd.DataFrame({\n",
    "#             'vendor_id': fallback_scores.index,\n",
    "#             'fallback_score': fallback_scores.values\n",
    "#         }).sort_values('fallback_score', ascending=False)\n",
    "\n",
    "#     def _compute_user_activity_levels(self):\n",
    "#         \"\"\"Compute user activity levels for dynamic weighting\"\"\"\n",
    "#         user_orders = self.user_vendor_matrix.sum(axis=1)\n",
    "#         if len(user_orders) == 0:\n",
    "#             return {'low': 1, 'medium': 2}\n",
    "\n",
    "#         return {\n",
    "#             'low': user_orders.quantile(0.33),\n",
    "#             'medium': user_orders.quantile(0.66)\n",
    "#         }\n",
    "\n",
    "#     def _get_dynamic_weights(self, user_id):\n",
    "#         \"\"\"Get dynamic weights based on user activity - OPTIMIZED for better ranking\"\"\"\n",
    "#         if user_id not in self.user_vendor_matrix.index:\n",
    "#             # New users: more weight to content and popularity\n",
    "#             return 0.1, 0.5, 0.4\n",
    "\n",
    "#         user_activity = self.user_vendor_matrix.loc[user_id].sum()\n",
    "\n",
    "#         if user_activity <= self.user_activity_levels['low']:\n",
    "#             return 0.3, 0.4, 0.3  # Low activity: balanced\n",
    "#         elif user_activity <= self.user_activity_levels['medium']:\n",
    "#             return 0.6, 0.3, 0.1  # Medium activity: more CF (OPTIMIZED)\n",
    "#         else:\n",
    "#             return 0.7, 0.2, 0.1  # High activity: mostly CF\n",
    "\n",
    "#     def generate_enhanced_recommendations(self, user_id, top_n=10, novelty_boost=0.2):\n",
    "#         \"\"\"Generate recommendations with optimized scoring and ranking\"\"\"\n",
    "#         cf_weight, cb_weight, pop_weight = self._get_dynamic_weights(user_id)\n",
    "\n",
    "#         print(f\"   User {user_id}: CF={cf_weight:.1f}, CB={cb_weight:.1f}, POP={pop_weight:.1f}\")\n",
    "\n",
    "#         # Get CF scores\n",
    "#         if user_id in self.user_vendor_matrix.index:\n",
    "#             user_idx = self.user_vendor_matrix.index.get_loc(user_id)\n",
    "#             cf_scores = self.als_model.item_factors.dot(self.als_model.user_factors[user_idx])\n",
    "\n",
    "#             # Create candidates dataframe with proper alignment\n",
    "#             candidates = pd.DataFrame({\n",
    "#                 'vendor_id': self.user_vendor_matrix.columns,\n",
    "#                 'cf_score': cf_scores\n",
    "#             })\n",
    "#         else:\n",
    "#             # For new users, use popularity-based scores\n",
    "#             cf_scores = self.user_vendor_matrix.sum(axis=0).values\n",
    "#             candidates = pd.DataFrame({\n",
    "#                 'vendor_id': self.user_vendor_matrix.columns,\n",
    "#                 'cf_score': cf_scores\n",
    "#             })\n",
    "\n",
    "#         # Get top candidates for efficiency (wider net for better ranking)\n",
    "#         candidate_pool_size = min(top_n * 20, len(candidates))\n",
    "#         candidates = candidates.nlargest(candidate_pool_size, 'cf_score')\n",
    "\n",
    "#         # Enhanced CB scores with temporal patterns\n",
    "#         cb_scores = self._compute_enhanced_cb_scores(user_id, candidates['vendor_id'])\n",
    "#         candidates['cb_score'] = candidates['vendor_id'].map(cb_scores)\n",
    "\n",
    "#         # Popularity scores (only for vendors in candidates)\n",
    "#         pop_scores = self.user_vendor_matrix.sum(axis=0)\n",
    "#         candidates['pop_score'] = candidates['vendor_id'].map(\n",
    "#             lambda x: pop_scores[x] / pop_scores.max() if pop_scores.max() > 0 else pop_scores[x]\n",
    "#         ).fillna(0)\n",
    "\n",
    "#         # Vendor quality (emphasize 4+ star vendors)\n",
    "#         candidates['quality_score'] = candidates['vendor_id'].map(\n",
    "#             lambda x: self.vendor_features.loc[x, 'avg_vendor_rating'] if x in self.vendor_features.index else 0\n",
    "#         ).fillna(0)\n",
    "\n",
    "#         # Boost vendors with 4+ stars\n",
    "#         candidates['rating_boost'] = candidates['quality_score'].apply(\n",
    "#             lambda x: 0.2 if x >= 4.0 else (0.1 if x >= 3.5 else 0)\n",
    "#         )\n",
    "\n",
    "#         # Novelty scores (penalize vendors user has ordered from)\n",
    "#         user_ordered = set()\n",
    "#         if user_id in self.matrices['raw_interactions']['customer_id'].values:\n",
    "#             user_ordered = set(self.matrices['raw_interactions'][\n",
    "#                 self.matrices['raw_interactions']['customer_id'] == user_id\n",
    "#             ]['vendor_id'])\n",
    "\n",
    "#         candidates['novelty_score'] = candidates['vendor_id'].apply(\n",
    "#             lambda x: novelty_boost if x not in user_ordered else -0.3  # Penalize previously ordered\n",
    "#         )\n",
    "\n",
    "#         # OPTIMIZED: Better normalization using min-max scaling\n",
    "#         for col in ['cf_score', 'cb_score', 'pop_score', 'quality_score']:\n",
    "#             min_val = candidates[col].min()\n",
    "#             max_val = candidates[col].max()\n",
    "#             if max_val > min_val:\n",
    "#                 candidates[f'{col}_norm'] = (candidates[col] - min_val) / (max_val - min_val)\n",
    "#             else:\n",
    "#                 candidates[f'{col}_norm'] = 0\n",
    "\n",
    "#         # OPTIMIZED FINAL SCORING with better weight distribution\n",
    "#         candidates['final_score'] = (\n",
    "#             cf_weight * candidates['cf_score_norm'] +\n",
    "#             cb_weight * candidates['cb_score_norm'] +\n",
    "#             pop_weight * candidates['pop_score_norm'] +\n",
    "#             0.15 * candidates['quality_score_norm'] +  # Quality emphasis\n",
    "#             candidates['rating_boost'] +  # Bonus for high-rated vendors\n",
    "#             candidates['novelty_score']   # Novelty adjustment\n",
    "#         )\n",
    "\n",
    "#         # Apply cuisine diversity with optimized penalty\n",
    "#         final_recommendations = self._apply_diversity(candidates, top_n)\n",
    "\n",
    "#         # Ensure proper sorting by final_score (CRITICAL FIX)\n",
    "#         final_recommendations = final_recommendations.sort_values('final_score', ascending=False).head(top_n)\n",
    "\n",
    "#         print(f\"   Generated {len(final_recommendations)} recommendations, score range: {final_recommendations['final_score'].min():.3f}-{final_recommendations['final_score'].max():.3f}\")\n",
    "\n",
    "#         return final_recommendations\n",
    "\n",
    "#     def _compute_enhanced_cb_scores(self, user_id, candidate_vendors):\n",
    "#         \"\"\"Compute enhanced content-based scores with cuisine preferences\"\"\"\n",
    "#         scores = {}\n",
    "\n",
    "#         if user_id not in self.user_profiles['customer_id'].values:\n",
    "#             # Return moderate scores for new users\n",
    "#             return {vid: 0.4 for vid in candidate_vendors}\n",
    "\n",
    "#         user_profile = self.user_profiles[self.user_profiles['customer_id'] == user_id].iloc[0]\n",
    "\n",
    "#         for vendor_id in candidate_vendors:\n",
    "#             if vendor_id not in self.vendor_features.index:\n",
    "#                 scores[vendor_id] = 0\n",
    "#                 continue\n",
    "\n",
    "#             vendor_cuisine = self.vendor_features.loc[vendor_id, 'cuisine_origin']\n",
    "#             vendor_rating = self.vendor_features.loc[vendor_id, 'avg_vendor_rating']\n",
    "\n",
    "#             # Base cuisine preference from user profile\n",
    "#             cuisine_score = user_profile.get(vendor_cuisine, 0.1)  # Default to 0.1 for unknown cuisines\n",
    "\n",
    "#             # Boost for high-rated vendors in preferred cuisines\n",
    "#             rating_boost = 0.2 if vendor_rating >= 4.0 else (0.1 if vendor_rating >= 3.5 else 0)\n",
    "\n",
    "#             # Temporal pattern matching (simplified)\n",
    "#             temporal_boost = self._compute_temporal_boost(user_profile, vendor_id)\n",
    "\n",
    "#             # Combined CB score\n",
    "#             scores[vendor_id] = cuisine_score * (1 + rating_boost + temporal_boost)\n",
    "\n",
    "#         return scores\n",
    "\n",
    "#     def _compute_temporal_boost(self, user_profile, vendor_id):\n",
    "#         \"\"\"Compute temporal pattern boost based on user behavior\"\"\"\n",
    "#         # Simplified implementation - can be enhanced with actual order patterns\n",
    "#         return 0.05  # Small consistent boost\n",
    "\n",
    "#     def _apply_diversity(self, candidates, top_n):\n",
    "#         \"\"\"Apply diversity to avoid same-cuisine overload with optimized penalty\"\"\"\n",
    "#         final_recs = []\n",
    "#         cuisine_counts = {}\n",
    "\n",
    "#         # Get cuisine for each vendor\n",
    "#         vendor_cuisines = {}\n",
    "#         for vendor_id in candidates['vendor_id']:\n",
    "#             if vendor_id in self.vendor_features.index:\n",
    "#                 vendor_cuisines[vendor_id] = self.vendor_features.loc[vendor_id, 'cuisine_origin']\n",
    "#             else:\n",
    "#                 vendor_cuisines[vendor_id] = 'unknown'\n",
    "\n",
    "#         # Sort by final_score first\n",
    "#         sorted_candidates = candidates.nlargest(min(top_n * 5, len(candidates)), 'final_score')\n",
    "\n",
    "#         for idx, row in sorted_candidates.iterrows():\n",
    "#             vendor_id = row['vendor_id']\n",
    "#             cuisine = vendor_cuisines.get(vendor_id, 'unknown')\n",
    "#             count = cuisine_counts.get(cuisine, 0)\n",
    "\n",
    "#             # OPTIMIZED: Apply softer diversity penalty\n",
    "#             penalty = 1.0 / (1.0 + 0.15 * count)  # Reduced from 0.3 to 0.15\n",
    "#             diversified_score = row['final_score'] * penalty\n",
    "\n",
    "#             # Get vendor details\n",
    "#             vendor_rating = self.vendor_features.loc[vendor_id, 'avg_vendor_rating'] if vendor_id in self.vendor_features.index else 0\n",
    "\n",
    "#             final_recs.append({\n",
    "#                 'vendor_id': vendor_id,\n",
    "#                 'final_score': diversified_score,\n",
    "#                 'cuisine': cuisine,\n",
    "#                 'vendor_rating': vendor_rating,\n",
    "#                 'original_score': row['final_score']\n",
    "#             })\n",
    "\n",
    "#             cuisine_counts[cuisine] = count + 1\n",
    "\n",
    "#             if len(final_recs) >= top_n * 2:  # Limit for efficiency\n",
    "#                 break\n",
    "\n",
    "#         result_df = pd.DataFrame(final_recs)\n",
    "#         if len(result_df) > 0:\n",
    "#             # Final sort by diversified score\n",
    "#             return result_df.nlargest(min(top_n, len(result_df)), 'final_score')\n",
    "#         else:\n",
    "#             return pd.DataFrame(columns=['vendor_id', 'final_score', 'cuisine', 'vendor_rating', 'original_score'])\n",
    "\n",
    "# # Initialize enhanced recommender with optimized ranking\n",
    "# enhanced_recommender = EnhancedHybridRecommender(als_model, user_profiles_with_clusters, vendor_features, matrices)\n",
    "# print(\"✅ Enhanced hybrid recommender with optimized ranking ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533ab01",
   "metadata": {},
   "source": [
    "# NEW Cell 5: OPTIMIZED HYBRID RECOMMENDER WITH IMPROVEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Creating Optimized Hybrid Recommender with Ranking Improvements...\n",
      "✅ Optimized recommender: 1326 quality vendors\n",
      "✅ Improved hybrid recommender with ranking fixes ready!\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# OPTIMIZED HYBRID RECOMMENDER (IMPROVED RANKING)\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nStep 5: Creating Optimized Hybrid Recommender with Ranking Improvements...\")\n",
    "\n",
    "class OptimizedHybridRecommender:\n",
    "    def __init__(self, als_model, user_profiles, vendor_features, interaction_matrices):\n",
    "        self.als_model = als_model\n",
    "        self.user_profiles = user_profiles\n",
    "        self.vendor_features = vendor_features.set_index('vendor_id')\n",
    "        self.matrices = interaction_matrices\n",
    "        self.user_vendor_matrix = interaction_matrices['user_vendor']\n",
    "\n",
    "        # Filter to quality vendors only (3.5+ stars)\n",
    "        self.vendor_features = self.vendor_features[self.vendor_features['avg_vendor_rating'] >= 3.5]\n",
    "        self.vendor_features = self._align_vendor_features()\n",
    "\n",
    "        print(f\"✅ Optimized recommender: {len(self.vendor_features)} quality vendors\")\n",
    "\n",
    "    def _align_vendor_features(self):\n",
    "        \"\"\"Ensure vendor features align with interaction matrix\"\"\"\n",
    "        matrix_vendors = set(self.user_vendor_matrix.columns)\n",
    "        feature_vendors = set(self.vendor_features.index)\n",
    "        common_vendors = matrix_vendors.intersection(feature_vendors)\n",
    "        return self.vendor_features.loc[list(common_vendors)]\n",
    "\n",
    "    def _get_user_weights(self, user_id):\n",
    "        \"\"\"Simple weight assignment based on user activity\"\"\"\n",
    "        if user_id not in self.user_vendor_matrix.index:\n",
    "            return 0.1, 0.6, 0.3  # New user: focus on content & popularity\n",
    "\n",
    "        user_activity = self.user_vendor_matrix.loc[user_id].sum()\n",
    "        if user_activity < 3:  # Low activity\n",
    "            return 0.3, 0.5, 0.2\n",
    "        else:  # Active user\n",
    "            return 0.6, 0.3, 0.1\n",
    "\n",
    "    def generate_recommendations(self, user_id, top_n=10):\n",
    "        \"\"\"Generate optimized recommendations with proper ranking and diversity\"\"\"\n",
    "        cf_weight, cb_weight, pop_weight = self._get_user_weights(user_id)\n",
    "\n",
    "        # Get candidate vendors (wider pool for ranking)\n",
    "        candidates = self._get_candidate_scores(user_id, top_n * 20)\n",
    "        if len(candidates) == 0:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Apply content-based scoring\n",
    "        candidates['cb_score'] = candidates['vendor_id'].map(\n",
    "            self._compute_content_scores(user_id, candidates['vendor_id'])\n",
    "        )\n",
    "\n",
    "        # Apply popularity scoring\n",
    "        pop_scores = self.user_vendor_matrix.sum(axis=0)\n",
    "        candidates['pop_score'] = candidates['vendor_id'].map(\n",
    "            lambda x: pop_scores.get(x, 0) / pop_scores.max() if pop_scores.max() > 0 else 0\n",
    "        )\n",
    "\n",
    "        # Normalize scores (0-1 range)\n",
    "        for col in ['cf_score', 'cb_score', 'pop_score']:\n",
    "            min_val, max_val = candidates[col].min(), candidates[col].max()\n",
    "            if max_val > min_val:\n",
    "                candidates[f'{col}_norm'] = (candidates[col] - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                candidates[f'{col}_norm'] = 0.5  # Neutral score\n",
    "\n",
    "        # Add vendor details for diversity calculation\n",
    "        candidates['cuisine'] = candidates['vendor_id'].map(\n",
    "            lambda x: self.vendor_features.loc[x, 'cuisine_origin'] if x in self.vendor_features.index else 'unknown'\n",
    "        )\n",
    "        candidates['vendor_rating'] = candidates['vendor_id'].map(\n",
    "            lambda x: self.vendor_features.loc[x, 'avg_vendor_rating'] if x in self.vendor_features.index else 0\n",
    "        )\n",
    "\n",
    "        # ENHANCED FINAL SCORING with rating boost and controlled novelty\n",
    "        candidates['rating_boost'] = candidates['vendor_rating'].apply(\n",
    "            lambda x: 0.15 if x >= 4.0 else (0.05 if x >= 3.5 else 0)\n",
    "        )\n",
    "\n",
    "        # Reduced novelty boost (from 0.2 to 0.05)\n",
    "        candidates['novelty_boost'] = candidates['vendor_id'].apply(\n",
    "            lambda x: self._get_novelty_boost(user_id, x)\n",
    "        )\n",
    "\n",
    "        candidates['final_score'] = (\n",
    "            cf_weight * candidates['cf_score_norm'] +\n",
    "            cb_weight * candidates['cb_score_norm'] +\n",
    "            pop_weight * candidates['pop_score_norm'] +\n",
    "            candidates['rating_boost'] +      # Boost for high-rated vendors\n",
    "            candidates['novelty_boost']       # Reduced novelty boost\n",
    "        )\n",
    "\n",
    "        # Apply diversity-aware ranking\n",
    "        final_recommendations = self._apply_diversity_ranking(candidates, top_n)\n",
    "\n",
    "        print(f\"   Generated {len(final_recommendations)} recs | \"\n",
    "              f\"Rating boost: {candidates['rating_boost'].mean():.3f} | \"\n",
    "              f\"Novelty boost: {candidates['novelty_boost'].mean():.3f}\")\n",
    "\n",
    "        return final_recommendations[['vendor_id', 'final_score', 'cuisine', 'vendor_rating']]\n",
    "\n",
    "    def _get_candidate_scores(self, user_id, candidate_pool):\n",
    "        \"\"\"Get collaborative filtering scores for candidates\"\"\"\n",
    "        if user_id in self.user_vendor_matrix.index:\n",
    "            user_idx = self.user_vendor_matrix.index.get_loc(user_id)\n",
    "            cf_scores = self.als_model.item_factors.dot(self.als_model.user_factors[user_idx])\n",
    "\n",
    "            candidates = pd.DataFrame({\n",
    "                'vendor_id': self.user_vendor_matrix.columns,\n",
    "                'cf_score': cf_scores\n",
    "            })\n",
    "        else:\n",
    "            # New user - use popularity\n",
    "            cf_scores = self.user_vendor_matrix.sum(axis=0).values\n",
    "            candidates = pd.DataFrame({\n",
    "                'vendor_id': self.user_vendor_matrix.columns,\n",
    "                'cf_score': cf_scores\n",
    "            })\n",
    "\n",
    "        return candidates.nlargest(candidate_pool, 'cf_score')\n",
    "\n",
    "    def _compute_content_scores(self, user_id, candidate_vendors):\n",
    "        \"\"\"Compute content-based scores using cuisine preferences\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        if user_id not in self.user_profiles['customer_id'].values:\n",
    "            return {vid: 0.3 for vid in candidate_vendors}  # Default for new users\n",
    "\n",
    "        user_profile = self.user_profiles[self.user_profiles['customer_id'] == user_id].iloc[0]\n",
    "\n",
    "        for vendor_id in candidate_vendors:\n",
    "            if vendor_id not in self.vendor_features.index:\n",
    "                scores[vendor_id] = 0\n",
    "                continue\n",
    "\n",
    "            vendor_cuisine = self.vendor_features.loc[vendor_id, 'cuisine_origin']\n",
    "            cuisine_score = user_profile.get(vendor_cuisine, 0.1)  # Default to 0.1 for unknown cuisines\n",
    "            scores[vendor_id] = cuisine_score\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def _get_novelty_boost(self, user_id, vendor_id):\n",
    "        \"\"\"Calculate novelty boost for vendors user hasn't ordered before\"\"\"\n",
    "        if user_id not in self.matrices['raw_interactions']['customer_id'].values:\n",
    "            return 0.05  # Small boost for new users\n",
    "\n",
    "        user_ordered = set(self.matrices['raw_interactions'][\n",
    "            self.matrices['raw_interactions']['customer_id'] == user_id\n",
    "        ]['vendor_id'])\n",
    "\n",
    "        return 0.05 if vendor_id not in user_ordered else 0  # Reduced from 0.2 to 0.05\n",
    "\n",
    "    def _apply_diversity_ranking(self, candidates, top_n):\n",
    "        \"\"\"Apply diversity-aware ranking to improve cuisine variety\"\"\"\n",
    "        # Sort by final_score first\n",
    "        sorted_candidates = candidates.sort_values('final_score', ascending=False)\n",
    "\n",
    "        final_recs = []\n",
    "        selected_cuisines = set()\n",
    "        cuisine_penalties = {}\n",
    "\n",
    "        # Take wider pool for diversity selection\n",
    "        candidate_pool = sorted_candidates.head(top_n * 3)\n",
    "\n",
    "        for idx, row in candidate_pool.iterrows():\n",
    "            if len(final_recs) >= top_n:\n",
    "                break\n",
    "\n",
    "            vendor_id = row['vendor_id']\n",
    "            cuisine = row['cuisine']\n",
    "            base_score = row['final_score']\n",
    "\n",
    "            # Apply cuisine diversity penalty\n",
    "            cuisine_count = cuisine_penalties.get(cuisine, 0)\n",
    "            diversity_penalty = cuisine_count * 0.1  # Penalty for repeated cuisines\n",
    "            diversified_score = base_score * (1 - diversity_penalty)\n",
    "\n",
    "            final_recs.append({\n",
    "                'vendor_id': vendor_id,\n",
    "                'final_score': diversified_score,\n",
    "                'cuisine': cuisine,\n",
    "                'vendor_rating': row['vendor_rating'],\n",
    "                'original_score': base_score,\n",
    "                'diversity_penalty': diversity_penalty\n",
    "            })\n",
    "\n",
    "            cuisine_penalties[cuisine] = cuisine_count + 1\n",
    "            selected_cuisines.add(cuisine)\n",
    "\n",
    "        result_df = pd.DataFrame(final_recs)\n",
    "\n",
    "        # CRITICAL: Final sort by diversified score to ensure proper ranking\n",
    "        result_df = result_df.sort_values('final_score', ascending=False).head(top_n)\n",
    "\n",
    "        print(f\"   Diversity: {len(selected_cuisines)} cuisines | \"\n",
    "              f\"Avg penalty: {result_df['diversity_penalty'].mean():.3f}\")\n",
    "\n",
    "        return result_df\n",
    "\n",
    "# Initialize improved recommender\n",
    "optimized_recommender = OptimizedHybridRecommender(als_model, user_profiles, vendor_features, matrices)\n",
    "print(\"✅ Improved hybrid recommender with ranking fixes ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fef689",
   "metadata": {},
   "source": [
    "# NEW Cell 6: ENHANCED COMPREHENSIVE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee49c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Running Enhanced Comprehensive Evaluation...\n",
      "Running evaluation with ranking improvements...\n",
      "Evaluating 100 users with enhanced metrics...\n",
      "Progress: 0/100\n",
      "   Diversity: 4 cuisines | Avg penalty: 0.160\n",
      "   Generated 10 recs | Rating boost: 0.111 | Novelty boost: 0.048\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 4 cuisines | Avg penalty: 0.100\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.360\n",
      "   Generated 10 recs | Rating boost: 0.118 | Novelty boost: 0.048\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.130\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.048\n",
      "   Diversity: 4 cuisines | Avg penalty: 0.120\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 5 cuisines | Avg penalty: 0.050\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.290\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.280\n",
      "   Generated 10 recs | Rating boost: 0.119 | Novelty boost: 0.047\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.170\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.048\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.121 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.200\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 6 cuisines | Avg penalty: 0.050\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.048\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.112 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.109 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.180\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.220\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.106 | Novelty boost: 0.048\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.290\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.111 | Novelty boost: 0.049\n",
      "Progress: 20/100\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.109 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 4 cuisines | Avg penalty: 0.100\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.048\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.111 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.220\n",
      "   Generated 10 recs | Rating boost: 0.119 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.280\n",
      "   Generated 10 recs | Rating boost: 0.111 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.112 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.240\n",
      "   Generated 10 recs | Rating boost: 0.109 | Novelty boost: 0.048\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.048\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.050\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.119 | Novelty boost: 0.050\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.280\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.049\n",
      "Progress: 40/100\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.360\n",
      "   Generated 10 recs | Rating boost: 0.119 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.290\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.108 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.360\n",
      "   Generated 10 recs | Rating boost: 0.107 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.240\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.048\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.220\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.210\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.048\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.120\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.290\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.050\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.290\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.047\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.240\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "Progress: 60/100\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.110 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.112 | Novelty boost: 0.050\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.360\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.210\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.360\n",
      "   Generated 10 recs | Rating boost: 0.112 | Novelty boost: 0.048\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.360\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.220\n",
      "   Generated 10 recs | Rating boost: 0.118 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.180\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.111 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.109 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.360\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.050\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.240\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.048\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.118 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.180\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.290\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.112 | Novelty boost: 0.049\n",
      "Progress: 80/100\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.048\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.110 | Novelty boost: 0.050\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.170\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.290\n",
      "   Generated 10 recs | Rating boost: 0.112 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.103 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.050\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.108 | Novelty boost: 0.050\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.111 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.290\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.117 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.120\n",
      "   Generated 10 recs | Rating boost: 0.114 | Novelty boost: 0.049\n",
      "   Diversity: 2 cuisines | Avg penalty: 0.360\n",
      "   Generated 10 recs | Rating boost: 0.115 | Novelty boost: 0.047\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.119 | Novelty boost: 0.049\n",
      "   Diversity: 1 cuisines | Avg penalty: 0.450\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.048\n",
      "   Diversity: 4 cuisines | Avg penalty: 0.120\n",
      "   Generated 10 recs | Rating boost: 0.113 | Novelty boost: 0.049\n",
      "   Diversity: 3 cuisines | Avg penalty: 0.180\n",
      "   Generated 10 recs | Rating boost: 0.116 | Novelty boost: 0.048\n",
      "\n",
      "======================================================================\n",
      "ENHANCED COMPREHENSIVE EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "📊 CORE PERFORMANCE METRICS:\n",
      "--------------------------------------------------\n",
      "precision@10   : 0.0420 [Target: 0.10-0.30] ⚠️ BELOW TARGET (Need +0.058)\n",
      "recall@10      : 0.4200 [Target: 0.20-0.40] ⚠️ BELOW TARGET \n",
      "ndcg@10        : 0.2673 [Target: 0.60-0.85] ⚠️ BELOW TARGET (Need +0.333)\n",
      "mrr@10         : 0.2200 [Target: 0.30-0.60] ⚠️ BELOW TARGET (Need +0.080)\n",
      "\n",
      "🎯 RANKING ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Average position of relevant items: 7.82\n",
      "Top-1 accuracy: 0.140 (14.0%)\n",
      "Top-3 accuracy: 0.270\n",
      "\n",
      "🌟 QUALITY METRICS:\n",
      "--------------------------------------------------\n",
      "novelty        : 0.8590 (target: 0.7-0.9)\n",
      "diversity      : 0.1790 (target: 0.3-0.5)\n",
      "\n",
      "🔍 SAMPLE USER BREAKDOWNS:\n",
      "--------------------------------------------------\n",
      "User f40fe3ee | Orders: 14 | Position: Not found | Cuisines: 4 | Top3: No\n",
      "User 31478c4b | Orders: 27 | Position: Not found | Cuisines: 1 | Top3: No\n",
      "User 4e3a8fa0 | Orders: 4 | Position: Not found | Cuisines: 4 | Top3: No\n",
      "\n",
      "💡 IMPROVEMENTS IMPLEMENTED:\n",
      "--------------------------------------------------\n",
      "✅ Reduced novelty boost from 0.2 to 0.05\n",
      "✅ Added rating boost for 4+ star vendors\n",
      "✅ Enhanced diversity with cuisine penalties\n",
      "✅ Fixed final ranking sort (critical for NDCG)\n",
      "✅ Added position analysis for ranking quality\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ENHANCED COMPREHENSIVE EVALUATION\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nStep 6: Running Enhanced Comprehensive Evaluation...\")\n",
    "\n",
    "def calculate_ndcg(relevance_scores, k=10):\n",
    "    \"\"\"Calculate Normalized Discounted Cumulative Gain\"\"\"\n",
    "    relevance = relevance_scores[:k]\n",
    "\n",
    "    # Calculate DCG\n",
    "    dcg = 0\n",
    "    for i, rel in enumerate(relevance):\n",
    "        dcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "\n",
    "    # Calculate Ideal DCG\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    idcg = 0\n",
    "    for i, rel in enumerate(ideal_relevance):\n",
    "        idcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def calculate_mrr(relevance_scores, k=10):\n",
    "    \"\"\"Calculate Mean Reciprocal Rank\"\"\"\n",
    "    relevance = relevance_scores[:k]\n",
    "    for i, rel in enumerate(relevance):\n",
    "        if rel > 0:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0\n",
    "\n",
    "def enhanced_comprehensive_evaluation(recommender, order_level_data, sample_users=100, top_k=10):\n",
    "    \"\"\"Run complete evaluation with detailed analysis\"\"\"\n",
    "\n",
    "    df_sorted = order_level_data.sort_values('order_day')\n",
    "    user_order_counts = df_sorted['customer_id'].value_counts()\n",
    "    eligible_users = user_order_counts[user_order_counts >= 3].index\n",
    "\n",
    "    n_evaluate = min(sample_users, len(eligible_users))\n",
    "    test_users = np.random.choice(eligible_users, n_evaluate, replace=False)\n",
    "\n",
    "    print(f\"Evaluating {len(test_users)} users with enhanced metrics...\")\n",
    "\n",
    "    metrics = {\n",
    "        'precision@5': [], 'precision@10': [],\n",
    "        'recall@5': [], 'recall@10': [],\n",
    "        'ndcg@5': [], 'ndcg@10': [],\n",
    "        'mrr@5': [], 'mrr@10': [],\n",
    "        'novelty': [], 'diversity': [],\n",
    "        'avg_position': [], 'top1_hits': []\n",
    "    }\n",
    "\n",
    "    user_breakdowns = []\n",
    "\n",
    "    for i, user_id in enumerate(test_users):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Progress: {i}/{len(test_users)}\")\n",
    "\n",
    "        user_orders = df_sorted[df_sorted['customer_id'] == user_id]\n",
    "        if len(user_orders) < 2:\n",
    "            continue\n",
    "\n",
    "        train_orders = user_orders.iloc[:-1]\n",
    "        test_order = user_orders.iloc[-1]\n",
    "        actual_vendor = test_order['vendor_id']\n",
    "        actual_cuisine = test_order['cuisine_origin']\n",
    "\n",
    "        try:\n",
    "            recommendations = recommender.generate_recommendations(user_id, top_n=top_k)\n",
    "            if len(recommendations) == 0:\n",
    "                continue\n",
    "\n",
    "            rec_vendors = recommendations['vendor_id'].tolist()\n",
    "            rec_cuisines = recommendations['cuisine'].tolist()\n",
    "            rec_scores = recommendations['final_score'].tolist()\n",
    "\n",
    "            # Calculate relevance\n",
    "            relevance = [1 if v == actual_vendor else 0 for v in rec_vendors]\n",
    "\n",
    "            # Basic metrics\n",
    "            metrics['precision@5'].append(np.mean(relevance[:5]))\n",
    "            metrics['precision@10'].append(np.mean(relevance[:10]))\n",
    "            metrics['recall@5'].append(1 if any(relevance[:5]) else 0)\n",
    "            metrics['recall@10'].append(1 if any(relevance[:10]) else 0)\n",
    "\n",
    "            # Ranking metrics\n",
    "            metrics['ndcg@5'].append(calculate_ndcg(relevance, 5))\n",
    "            metrics['ndcg@10'].append(calculate_ndcg(relevance, 10))\n",
    "            metrics['mrr@5'].append(calculate_mrr(relevance, 5))\n",
    "            metrics['mrr@10'].append(calculate_mrr(relevance, 10))\n",
    "\n",
    "            # Enhanced metrics\n",
    "            user_history = set(train_orders['vendor_id'])\n",
    "            metrics['novelty'].append(sum(1 for v in rec_vendors[:10] if v not in user_history) / 10)\n",
    "            metrics['diversity'].append(len(set(rec_cuisines[:10])) / 10)\n",
    "\n",
    "            # Position analysis\n",
    "            if any(relevance):\n",
    "                position = relevance.index(1) + 1\n",
    "                metrics['avg_position'].append(position)\n",
    "                metrics['top1_hits'].append(1 if position == 1 else 0)\n",
    "            else:\n",
    "                metrics['avg_position'].append(top_k + 1)  # Penalty for not found\n",
    "                metrics['top1_hits'].append(0)\n",
    "\n",
    "            # Store user breakdown for analysis\n",
    "            if i < 3:  # First 3 users for detailed analysis\n",
    "                user_breakdowns.append({\n",
    "                    'user_id': user_id,\n",
    "                    'total_orders': len(user_orders),\n",
    "                    'actual_position': relevance.index(1) + 1 if any(relevance) else 'Not found',\n",
    "                    'rec_scores_range': f\"{min(rec_scores):.3f}-{max(rec_scores):.3f}\",\n",
    "                    'unique_cuisines': len(set(rec_cuisines)),\n",
    "                    'found_in_top3': any(relevance[:3])\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Calculate results\n",
    "    results = {}\n",
    "    for k, v in metrics.items():\n",
    "        if v:\n",
    "            results[k] = np.mean(v)\n",
    "        else:\n",
    "            results[k] = 0\n",
    "\n",
    "    # Print comprehensive results with improvements\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ENHANCED COMPREHENSIVE EVALUATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    target_ranges = {\n",
    "        'precision@10': (0.10, 0.30),\n",
    "        'recall@10': (0.20, 0.40),\n",
    "        'ndcg@10': (0.60, 0.85),\n",
    "        'mrr@10': (0.30, 0.60)\n",
    "    }\n",
    "\n",
    "    print(\"\\n📊 CORE PERFORMANCE METRICS:\")\n",
    "    print(\"-\" * 50)\n",
    "    for metric in ['precision@10', 'recall@10', 'ndcg@10', 'mrr@10']:\n",
    "        if metric in results:\n",
    "            value = results[metric]\n",
    "            if metric in target_ranges:\n",
    "                low, high = target_ranges[metric]\n",
    "                status = \"✅ WITHIN TARGET\" if low <= value <= high else \"⚠️ BELOW TARGET\"\n",
    "                improvement_needed = f\"(Need +{low-value:.3f})\" if value < low else \"\"\n",
    "                print(f\"{metric:15}: {value:.4f} [Target: {low:.2f}-{high:.2f}] {status} {improvement_needed}\")\n",
    "\n",
    "    print(\"\\n🎯 RANKING ANALYSIS:\")\n",
    "    print(\"-\" * 50)\n",
    "    if 'avg_position' in results and 'top1_hits' in results:\n",
    "        print(f\"Average position of relevant items: {results['avg_position']:.2f}\")\n",
    "        print(f\"Top-1 accuracy: {results['top1_hits']:.3f} ({results['top1_hits']*100:.1f}%)\")\n",
    "        print(f\"Top-3 accuracy: {sum(1 for p in metrics['avg_position'] if p <= 3)/len(metrics['avg_position']):.3f}\")\n",
    "\n",
    "    print(\"\\n🌟 QUALITY METRICS:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'novelty':15}: {results.get('novelty', 0):.4f} (target: 0.7-0.9)\")\n",
    "    print(f\"{'diversity':15}: {results.get('diversity', 0):.4f} (target: 0.3-0.5)\")\n",
    "\n",
    "    # User breakdown\n",
    "    if user_breakdowns:\n",
    "        print(\"\\n🔍 SAMPLE USER BREAKDOWNS:\")\n",
    "        print(\"-\" * 50)\n",
    "        for user in user_breakdowns:\n",
    "            print(f\"User {user['user_id'][:8]} | Orders: {user['total_orders']} | \"\n",
    "                  f\"Position: {user['actual_position']} | \"\n",
    "                  f\"Cuisines: {user['unique_cuisines']} | \"\n",
    "                  f\"Top3: {'Yes' if user['found_in_top3'] else 'No'}\")\n",
    "\n",
    "    # Improvement summary\n",
    "    print(\"\\n💡 IMPROVEMENTS IMPLEMENTED:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"✅ Reduced novelty boost from 0.2 to 0.05\")\n",
    "    print(\"✅ Added rating boost for 4+ star vendors\")\n",
    "    print(\"✅ Enhanced diversity with cuisine penalties\")\n",
    "    print(\"✅ Fixed final ranking sort (critical for NDCG)\")\n",
    "    print(\"✅ Added position analysis for ranking quality\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run enhanced evaluation\n",
    "print(\"Running evaluation with ranking improvements...\")\n",
    "final_metrics = enhanced_comprehensive_evaluation(optimized_recommender, order_level_data, sample_users=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25017d",
   "metadata": {},
   "source": [
    "# Cell 6: Enhanced Evaluation with Comprehensive Metrics & Analysis\n",
    "### Purpose: This cell performs comprehensive evaluation of the recommendation system using multiple metrics including Precision, Recall, NDCG, MRR, Novelty, and Diversity. The enhanced version includes detailed user analysis, vendor rating validation, and proper temporal splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141db12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================\n",
    "# # ENHANCED EVALUATION WITH COMPREHENSIVE METRICS\n",
    "# # =============================================\n",
    "\n",
    "# print(\"\\nStep 6: Running Enhanced Evaluation with Comprehensive Metrics...\")\n",
    "\n",
    "# def calculate_ndcg(relevance_scores, k=10):\n",
    "#     \"\"\"Calculate Normalized Discounted Cumulative Gain\"\"\"\n",
    "#     relevance = relevance_scores[:k]\n",
    "\n",
    "#     # Calculate DCG\n",
    "#     dcg = 0\n",
    "#     for i, rel in enumerate(relevance):\n",
    "#         dcg += (2 ** rel - 1) / np.log2(i + 2)  # i+2 because index starts at 0, and log base 2 of (i+2)\n",
    "\n",
    "#     # Calculate Ideal DCG\n",
    "#     ideal_relevance = sorted(relevance, reverse=True)\n",
    "#     idcg = 0\n",
    "#     for i, rel in enumerate(ideal_relevance):\n",
    "#         idcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "\n",
    "#     return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# def calculate_mrr(relevance_scores, k=10):\n",
    "#     \"\"\"Calculate Mean Reciprocal Rank\"\"\"\n",
    "#     relevance = relevance_scores[:k]\n",
    "#     for i, rel in enumerate(relevance):\n",
    "#         if rel > 0:  # Found first relevant item\n",
    "#             return 1.0 / (i + 1)\n",
    "#     return 0\n",
    "\n",
    "# def enhanced_evaluation(recommender, order_level_data, sample_users=100, top_k=10):\n",
    "#     \"\"\"\n",
    "#     Enhanced evaluation with comprehensive metrics and user analysis\n",
    "#     Includes Precision, Recall, NDCG, MRR, Novelty, Diversity, and Coverage\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Use temporal split but ensure minimum test interactions\n",
    "#     df_sorted = order_level_data.sort_values('order_day')\n",
    "\n",
    "#     # Only evaluate users with sufficient history\n",
    "#     user_order_counts = df_sorted['customer_id'].value_counts()\n",
    "#     eligible_users = user_order_counts[user_order_counts >= 3].index\n",
    "#     test_users = np.random.choice(eligible_users, min(sample_users, len(eligible_users)), replace=False)\n",
    "\n",
    "#     print(f\"Evaluating {len(test_users)} users with sufficient history...\")\n",
    "\n",
    "#     # Enhanced metrics dictionary\n",
    "#     metrics = {\n",
    "#         'precision@5': [], 'precision@10': [],\n",
    "#         'recall@5': [], 'recall@10': [],\n",
    "#         'ndcg@5': [], 'ndcg@10': [],\n",
    "#         'mrr@5': [], 'mrr@10': [],\n",
    "#         'novelty': [], 'diversity': []\n",
    "#     }\n",
    "\n",
    "#     all_recommendations = []\n",
    "#     user_analysis_data = []\n",
    "\n",
    "#     for i, user_id in enumerate(test_users):\n",
    "#         if i % 20 == 0:\n",
    "#             print(f\"Progress: {i}/{len(test_users)}\")\n",
    "\n",
    "#         # Get user's last order as test\n",
    "#         user_orders = df_sorted[df_sorted['customer_id'] == user_id]\n",
    "#         if len(user_orders) < 2:\n",
    "#             continue\n",
    "\n",
    "#         train_orders = user_orders.iloc[:-1]\n",
    "#         test_order = user_orders.iloc[-1]\n",
    "\n",
    "#         actual_vendor = test_order['vendor_id']\n",
    "#         actual_cuisine = test_order['cuisine_origin']\n",
    "\n",
    "#         try:\n",
    "#             # Generate recommendations\n",
    "#             recommendations = recommender.generate_enhanced_recommendations(user_id, top_n=top_k)\n",
    "#             rec_vendors = recommendations['vendor_id'].tolist()\n",
    "#             rec_cuisines = recommendations['cuisine'].tolist()\n",
    "#             rec_scores = recommendations['final_score'].tolist()\n",
    "#             rec_ratings = recommendations['vendor_rating'].tolist()\n",
    "\n",
    "#             # Check if recommended vendors meet quality standards (3.5+ stars)\n",
    "#             quality_vendors = sum(1 for rating in rec_ratings if rating >= 3.5)\n",
    "\n",
    "#             # Create relevance scores (1 if vendor matches, 0 otherwise)\n",
    "#             relevance_scores = [1 if v == actual_vendor else 0 for v in rec_vendors]\n",
    "\n",
    "#             # Calculate metrics\n",
    "#             metrics['precision@5'].append(np.mean(relevance_scores[:5]))\n",
    "#             metrics['precision@10'].append(np.mean(relevance_scores[:10]))\n",
    "\n",
    "#             # Recall (since we have one relevant item, it's binary)\n",
    "#             metrics['recall@5'].append(1 if any(relevance_scores[:5]) else 0)\n",
    "#             metrics['recall@10'].append(1 if any(relevance_scores[:10]) else 0)\n",
    "\n",
    "#             # Ranking metrics\n",
    "#             metrics['ndcg@5'].append(calculate_ndcg(relevance_scores, 5))\n",
    "#             metrics['ndcg@10'].append(calculate_ndcg(relevance_scores, 10))\n",
    "#             metrics['mrr@5'].append(calculate_mrr(relevance_scores, 5))\n",
    "#             metrics['mrr@10'].append(calculate_mrr(relevance_scores, 10))\n",
    "\n",
    "#             # Novelty (proportion of new vendors not in user history)\n",
    "#             user_history_vendors = set(train_orders['vendor_id'])\n",
    "#             novel_count = sum(1 for v in rec_vendors[:10] if v not in user_history_vendors)\n",
    "#             metrics['novelty'].append(novel_count / 10)\n",
    "\n",
    "#             # Diversity (unique cuisines in recommendations)\n",
    "#             unique_cuisines = len(set(rec_cuisines[:10]))\n",
    "#             metrics['diversity'].append(unique_cuisines / 10)\n",
    "\n",
    "#             # Store for coverage calculation\n",
    "#             all_recommendations.extend(rec_vendors[:10])\n",
    "\n",
    "#             # Store user analysis data for sample users\n",
    "#             if i < 5:  # Store first 5 users for detailed analysis\n",
    "#                 user_analysis_data.append({\n",
    "#                     'user_id': user_id,\n",
    "#                     'user_orders': len(user_orders),\n",
    "#                     'unique_vendors': user_orders['vendor_id'].nunique(),\n",
    "#                     'actual_vendor': actual_vendor,\n",
    "#                     'actual_cuisine': actual_cuisine,\n",
    "#                     'recommendations': recommendations.head(10).copy(),\n",
    "#                     'relevance_scores': relevance_scores,\n",
    "#                     'found_relevant': any(relevance_scores),\n",
    "#                     'position_found': relevance_scores.index(1) + 1 if any(relevance_scores) else None,\n",
    "#                     'quality_vendors': quality_vendors\n",
    "#                 })\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error evaluating user {user_id}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#     # Calculate averages\n",
    "#     avg_metrics = {k: np.mean(v) for k, v in metrics.items() if v}\n",
    "\n",
    "#     # Coverage calculation\n",
    "#     all_vendors = set(matrices['user_vendor'].columns)\n",
    "#     recommended_vendors = set(all_recommendations)\n",
    "#     coverage = len(recommended_vendors) / len(all_vendors) if all_vendors else 0\n",
    "\n",
    "#     # Print comprehensive results\n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"ENHANCED EVALUATION RESULTS\")\n",
    "#     print(\"=\"*70)\n",
    "\n",
    "#     # Metrics with explanations\n",
    "#     metric_descriptions = {\n",
    "#         'precision@5': 'Accuracy in top 5 recommendations',\n",
    "#         'precision@10': 'Accuracy in top 10 recommendations',\n",
    "#         'recall@5': 'Ability to find relevant items in top 5',\n",
    "#         'recall@10': 'Ability to find relevant items in top 10',\n",
    "#         'ndcg@5': 'Ranking quality in top 5 (0-1 scale)',\n",
    "#         'ndcg@10': 'Ranking quality in top 10 (0-1 scale)',\n",
    "#         'mrr@5': 'How soon first relevant item appears in top 5',\n",
    "#         'mrr@10': 'How soon first relevant item appears in top 10',\n",
    "#         'novelty': 'Proportion of new/unseen recommendations',\n",
    "#         'diversity': 'Variety of cuisines in recommendations'\n",
    "#     }\n",
    "\n",
    "#     print(\"\\n📊 PERFORMANCE METRICS:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     for metric, value in avg_metrics.items():\n",
    "#         description = metric_descriptions.get(metric, '')\n",
    "#         print(f\"{metric:15}: {value:.4f} - {description}\")\n",
    "\n",
    "#     print(f\"{'coverage':15}: {coverage:.4f} - Percentage of total vendors recommended\")\n",
    "\n",
    "#     # Target ranges comparison\n",
    "#     print(\"\\n🎯 TARGET RANGES COMPARISON:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     target_ranges = {\n",
    "#         'precision@10': (0.10, 0.30),\n",
    "#         'recall@10': (0.20, 0.40),\n",
    "#         'ndcg@10': (0.60, 0.85),\n",
    "#         'mrr@10': (0.30, 0.60)\n",
    "#     }\n",
    "\n",
    "#     for metric, (low, high) in target_ranges.items():\n",
    "#         if metric in avg_metrics:\n",
    "#             value = avg_metrics[metric]\n",
    "#             if value >= low and value <= high:\n",
    "#                 status = \"✅ WITHIN TARGET\"\n",
    "#             elif value < low:\n",
    "#                 status = \"📈 BELOW TARGET\"\n",
    "#             else:\n",
    "#                 status = \"🎉 ABOVE TARGET\"\n",
    "#             print(f\"{metric:15}: {value:.4f} [Target: {low:.2f}-{high:.2f}] {status}\")\n",
    "\n",
    "#     # Sample user analysis\n",
    "#     if user_analysis_data:\n",
    "#         print(\"\\n🔍 SAMPLE USER ANALYSIS:\")\n",
    "#         print(\"-\" * 50)\n",
    "#         for user_data in user_analysis_data[:3]:  # Show first 3 users\n",
    "#             print(f\"\\nUser: {user_data['user_id']}\")\n",
    "#             print(f\"  Orders: {user_data['user_orders']}, Unique Vendors: {user_data['unique_vendors']}\")\n",
    "#             print(f\"  Actual Choice: {user_data['actual_vendor']} ({user_data['actual_cuisine']})\")\n",
    "#             print(f\"  Found in Recs: {'Yes' if user_data['found_relevant'] else 'No'}\")\n",
    "#             if user_data['found_relevant']:\n",
    "#                 print(f\"  Position Found: #{user_data['position_found']}\")\n",
    "#             print(f\"  Quality Vendors (3.5+ stars): {user_data['quality_vendors']}/10\")\n",
    "\n",
    "#             # Show top 3 recommendations\n",
    "#             print(\"  Top 3 Recommendations:\")\n",
    "#             for idx, row in user_data['recommendations'].head(3).iterrows():\n",
    "#                 print(f\"    {idx+1}. {row['vendor_id']} | Score: {row['final_score']:.3f} | \"\n",
    "#                       f\"Cuisine: {row['cuisine']} | Rating: {row['vendor_rating']:.2f}\")\n",
    "\n",
    "#     return avg_metrics, coverage, user_analysis_data\n",
    "\n",
    "# # Run enhanced evaluation\n",
    "# enhanced_metrics, enhanced_coverage, user_analysis = enhanced_evaluation(\n",
    "#     enhanced_recommender, order_level_data, sample_users=100\n",
    "# )\n",
    "\n",
    "# # Print summary for quick assessment\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"QUICK ASSESSMENT SUMMARY\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# critical_metrics = ['precision@10', 'recall@10', 'ndcg@10', 'mrr@10']\n",
    "# for metric in critical_metrics:\n",
    "#     if metric in enhanced_metrics:\n",
    "#         value = enhanced_metrics[metric]\n",
    "#         if metric == 'ndcg@10':\n",
    "#             if value >= 0.60:\n",
    "#                 status = \"✅ EXCELLENT\"\n",
    "#             elif value >= 0.30:\n",
    "#                 status = \"📈 GOOD\"\n",
    "#             else:\n",
    "#                 status = \"⚠️ NEEDS IMPROVEMENT\"\n",
    "#         elif metric in ['precision@10', 'recall@10']:\n",
    "#             if value >= 0.10:\n",
    "#                 status = \"✅ GOOD\"\n",
    "#             else:\n",
    "#                 status = \"⚠️ NEEDS IMPROVEMENT\"\n",
    "#         else:  # MRR\n",
    "#             if value >= 0.30:\n",
    "#                 status = \"✅ GOOD\"\n",
    "#             else:\n",
    "#                 status = \"⚠️ NEEDS IMPROVEMENT\"\n",
    "\n",
    "#         print(f\"{metric:15}: {value:.4f} - {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b0c85",
   "metadata": {},
   "source": [
    "# Cell 7: Optimized Hybrid Recommender with Ranking Enhancement\n",
    "### Purpose: This cell creates an optimized version of the hybrid recommender that focuses on improving ranking quality (NDCG) by incorporating user affinity signals and better balancing novelty with user preferences. The optimized version enhances the base recommender with ranking-specific improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e9b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 7: Creating Optimized Recommender for Better Ranking...\n",
      "   Aligned vendor features: 1326 vendors\n",
      "✅ Recommender initialized with 1326 quality vendors (3.5+ stars)\n",
      "   Ranking-optimized recommender initialized\n",
      "✅ Optimized hybrid recommender ready!\n",
      "Running OPTIMIZED evaluation...\n",
      "Evaluating 100 users with sufficient history...\n",
      "Progress: 0/100\n",
      "   User c712101860: CF=0.7, CB=0.2, POP=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generated 30 recommendations, score range: 0.448-1.374\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.574\n",
      "   User 0ec52a71f0: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.555-1.397\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.478\n",
      "   User 0370caccb1: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.476-1.396\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.073\n",
      "   User 3517a17ed0: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.414-1.188\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.312\n",
      "   User cf23f665af: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.404-1.296\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.506\n",
      "   User 903444c37e: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.435-1.163\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.568\n",
      "   User 65c5277cd8: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.582-1.390\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.067\n",
      "   User c0d1713c24: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.466-1.185\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.491\n",
      "   User b48305f2b9: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.369-1.299\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User de50c4d46f: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.338-1.329\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.544\n",
      "   User b95bcb90fe: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.393-1.363\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.112\n",
      "   User 8c9c3faa5a: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.456-1.197\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.485\n",
      "   User eadc87308c: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.293-1.234\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User 4bec71de1c: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.552-1.184\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.600\n",
      "   User 37e555cfc5: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.579-1.363\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.487\n",
      "   User a32dc0dc29: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.476-1.221\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.072\n",
      "   User e92f25f30c: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.389-1.226\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.531\n",
      "   User 503227c745: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.339-1.274\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.321\n",
      "   User d925774bb7: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.401-1.207\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.496\n",
      "   User cfb41fb542: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.318-1.120\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.114\n",
      "Progress: 20/100\n",
      "   User e3d1ec17a1: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.387-1.279\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.119\n",
      "   User e295084a5e: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.492-1.205\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.302\n",
      "   User b4c0f1da05: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.568-1.276\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.079\n",
      "   User c928792187: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.536-1.227\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.592\n",
      "   User bc80bc6b61: CF=0.3, CB=0.4, POP=0.3\n",
      "   Generated 30 recommendations, score range: 0.179-1.182\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User 73dbe55306: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.440-1.403\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.055\n",
      "   User 3d7d9235bf: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.509-1.271\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.070\n",
      "   User 77580b9a63: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.346-1.177\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.423\n",
      "   User 4a562718d0: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.372-1.270\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.464\n",
      "   User ae998fd276: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.442-1.258\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.514\n",
      "   User 7da536de06: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.510-1.346\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.057\n",
      "   User 6dccfebf0c: CF=0.3, CB=0.4, POP=0.3\n",
      "   Generated 30 recommendations, score range: 0.183-1.321\n",
      "   Ranking optimized: 10 recs, affinity range: 0.200-0.200\n",
      "   User 463c6f8413: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.287-1.284\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.101\n",
      "   User d488b49249: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.395-1.005\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.306\n",
      "   User aea8e1e976: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.452-1.310\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.127\n",
      "   User 62ae97f79f: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.490-1.244\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.511\n",
      "   User 5af601b376: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.484-1.192\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.086\n",
      "   User 5d9b6784da: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.481-1.158\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.600\n",
      "   User 5d0d47360a: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.574-1.274\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User f075d1ada5: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.342-1.205\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.107\n",
      "Progress: 40/100\n",
      "   User 415872b3f6: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.470-1.239\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.524\n",
      "   User e09be49ad4: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.355-1.108\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.600\n",
      "   User 1871c64b02: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.235-1.282\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.339\n",
      "   User 390410d301: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.542-1.162\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.543\n",
      "   User 9accd70410: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.352-1.214\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.517\n",
      "   User e1bff66ee7: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.199-1.073\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.600\n",
      "   User a4984c392a: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.544-1.337\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.050\n",
      "   User e158b0ac5d: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.357-1.052\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.334\n",
      "   User aaddb5f65b: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.529-1.401\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.068\n",
      "   User 32f7e7cdd2: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.462-1.203\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.517\n",
      "   User 7daa3e2f9b: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.517-1.220\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.519\n",
      "   User 65f8136ec5: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.557-1.164\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.314\n",
      "   User 8beb667d36: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.422-1.177\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.565\n",
      "   User 4f7e8c210d: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.463-1.311\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.111\n",
      "   User f81ff1651f: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.458-1.280\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User fe04b926ca: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.307-1.151\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.111\n",
      "   User 0b77a0439a: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.519-1.090\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.471\n",
      "   User fc75666c30: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.158-1.140\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User 2ada730f0e: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.287-1.091\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.517\n",
      "   User 25ef9c8d2b: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.332-1.102\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.339\n",
      "Progress: 60/100\n",
      "   User a71281aa43: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.299-1.178\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.450\n",
      "   User 7d2b3633b5: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.379-1.163\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.496\n",
      "   User 49adadf6b3: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.217-1.312\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.600\n",
      "   User bf65d5d6ed: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.424-1.123\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.550\n",
      "   User 3321687965: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.344-1.265\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.117\n",
      "   User 26819afcdf: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.338-1.281\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.600\n",
      "   User 9b24fece45: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.395-1.332\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.084\n",
      "   User 87b44962ca: CF=0.3, CB=0.4, POP=0.3\n",
      "   Generated 30 recommendations, score range: 0.477-1.198\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User 36dc29badb: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.460-1.338\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.080\n",
      "   User 9e52d5a835: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.410-1.182\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.117\n",
      "   User 33d294ab41: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.528-1.308\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.289\n",
      "   User 57b2d827d2: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.484-1.262\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.491\n",
      "   User 0c68d348c5: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.474-1.137\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.556\n",
      "   User 252e6250b0: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.455-1.262\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.600\n",
      "   User dcc7591aa8: CF=0.3, CB=0.4, POP=0.3\n",
      "   Generated 30 recommendations, score range: 0.179-1.115\n",
      "   Ranking optimized: 10 recs, affinity range: 0.200-0.200\n",
      "   User 946622cfee: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.435-1.401\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.314\n",
      "   User 9c24b1a6c7: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.214-1.365\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.119\n",
      "   User 57a2cf5104: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.438-1.357\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.516\n",
      "   User 27e72c00eb: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.507-1.389\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.309\n",
      "   User 583d57b253: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.494-1.087\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.427\n",
      "Progress: 80/100\n",
      "   User badd5f53bb: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.332-1.214\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.109\n",
      "   User 25c875f9ef: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.423-1.066\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.502\n",
      "   User 8313faa744: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.439-1.344\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.510\n",
      "   User 4eea579e9a: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.394-1.224\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.112\n",
      "   User 06286f60df: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.507-1.137\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.514\n",
      "   User 9eb01799cf: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.458-1.220\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.091\n",
      "   User a704aca689: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.196-1.134\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User cdf1e130aa: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.283-1.010\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.124\n",
      "   User cf71706c95: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.482-1.149\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.502\n",
      "   User 52128e732d: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.417-1.184\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.506\n",
      "   User 87b4ac3477: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.418-1.020\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.577\n",
      "   User d144eea0bf: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.449-1.340\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.086\n",
      "   User 3a35e92c84: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.234-1.379\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User dc662e7493: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.389-1.246\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.310\n",
      "   User 90cdf004fc: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.410-1.312\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.536\n",
      "   User 5311eb8995: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.456-1.300\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.075\n",
      "   User dae0e703b3: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.388-1.240\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.463\n",
      "   User 0e025a7344: CF=0.6, CB=0.3, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.333-1.402\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User 3e5a9ee655: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.419-1.207\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.200\n",
      "   User 3843d57f62: CF=0.7, CB=0.2, POP=0.1\n",
      "   Generated 30 recommendations, score range: 0.552-1.363\n",
      "   Ranking optimized: 10 recs, affinity range: 0.000-0.600\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZED EVALUATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "📊 PERFORMANCE METRICS:\n",
      "--------------------------------------------------\n",
      "precision@5    : 0.0240\n",
      "precision@10   : 0.0150 [Target: 0.10-0.30] 📈 BELOW TARGET\n",
      "recall@5       : 0.1200\n",
      "recall@10      : 0.1500 [Target: 0.20-0.40] 📈 BELOW TARGET\n",
      "ndcg@5         : 0.0864\n",
      "ndcg@10        : 0.0959 [Target: 0.60-0.85] 📈 BELOW TARGET\n",
      "mrr@5          : 0.0753\n",
      "mrr@10         : 0.0791 [Target: 0.30-0.60] 📈 BELOW TARGET\n",
      "novelty        : 0.9520\n",
      "diversity      : 0.6070\n",
      "\n",
      "🎯 RANKING ANALYSIS:\n",
      "   Average position of relevant items: 3.47\n",
      "   Top-1 accuracy: 0.333\n",
      "   Top-3 accuracy: 0.600\n",
      "\n",
      "======================================================================\n",
      "COMPARISON: ENHANCED vs OPTIMIZED\n",
      "======================================================================\n",
      "precision@10   : 0.0030 → 0.0150 ↑0.0120\n",
      "recall@10      : 0.0300 → 0.1500 ↑0.1200\n",
      "ndcg@10        : 0.0099 → 0.0959 ↑0.0860\n",
      "mrr@10         : 0.0043 → 0.0791 ↑0.0749\n"
     ]
    }
   ],
   "source": [
    "# # =============================================\n",
    "# # OPTIMIZED HYBRID RECOMMENDER (RANKING FOCUSED)\n",
    "# # =============================================\n",
    "\n",
    "# print(\"\\nStep 7: Creating Optimized Recommender for Better Ranking...\")\n",
    "\n",
    "# class OptimizedHybridRecommender(EnhancedHybridRecommender):\n",
    "#     def __init__(self, als_model, user_profiles, vendor_features, interaction_matrices):\n",
    "#         super().__init__(als_model, user_profiles, vendor_features, interaction_matrices)\n",
    "#         print(\"   Ranking-optimized recommender initialized\")\n",
    "\n",
    "#     def generate_optimized_recommendations(self, user_id, top_n=10, novelty_boost=0.1, ranking_boost=0.2):\n",
    "#         \"\"\"\n",
    "#         Optimized version with better ranking balance and user affinity modeling\n",
    "#         Focuses on improving NDCG while maintaining diversity\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Get base recommendations from enhanced recommender\n",
    "#         base_recommendations = self.generate_enhanced_recommendations(user_id, top_n * 3, novelty_boost)\n",
    "\n",
    "#         if len(base_recommendations) == 0:\n",
    "#             return base_recommendations.head(top_n)\n",
    "\n",
    "#         # Create a copy to avoid modifying the original\n",
    "#         recommendations = base_recommendations.copy()\n",
    "\n",
    "#         # Apply ranking optimization based on user affinity and temporal patterns\n",
    "#         if user_id in self.matrices['raw_interactions']['customer_id'].values:\n",
    "#             user_ordered_vendors = set(self.matrices['raw_interactions'][\n",
    "#                 self.matrices['raw_interactions']['customer_id'] == user_id\n",
    "#             ]['vendor_id'])\n",
    "\n",
    "#             # Calculate user-vendor affinity scores for better ranking\n",
    "#             affinity_boosts = self._calculate_user_affinity_boosts(user_id, recommendations['vendor_id'])\n",
    "#             recommendations['affinity_boost'] = recommendations['vendor_id'].map(affinity_boosts)\n",
    "\n",
    "#             # Apply ranking boost based on affinity\n",
    "#             recommendations['optimized_score'] = recommendations['final_score'] * (1 + recommendations['affinity_boost'])\n",
    "\n",
    "#             # For vendors with high affinity, ensure they rank appropriately\n",
    "#             high_affinity_mask = recommendations['affinity_boost'] > 0.3\n",
    "#             if high_affinity_mask.any():\n",
    "#                 # Boost high-affinity vendors to top positions when appropriate\n",
    "#                 max_original_score = recommendations['final_score'].max()\n",
    "#                 recommendations.loc[high_affinity_mask, 'optimized_score'] = recommendations.loc[high_affinity_mask, 'optimized_score'].clip(\n",
    "#                     upper=max_original_score * 1.2  # Prevent over-boosting\n",
    "#                 )\n",
    "#         else:\n",
    "#             # For new users, use the original scores\n",
    "#             recommendations['optimized_score'] = recommendations['final_score']\n",
    "#             recommendations['affinity_boost'] = 0\n",
    "\n",
    "#         # Apply temporal recency boost (prefer vendors user recently interacted with)\n",
    "#         temporal_boost = self._calculate_temporal_boost(user_id, recommendations['vendor_id'])\n",
    "#         recommendations['temporal_boost'] = recommendations['vendor_id'].map(temporal_boost)\n",
    "#         recommendations['optimized_score'] = recommendations['optimized_score'] * (1 + recommendations['temporal_boost'])\n",
    "\n",
    "#         # Final normalization and sorting\n",
    "#         max_opt_score = recommendations['optimized_score'].max()\n",
    "#         if max_opt_score > 0:\n",
    "#             recommendations['optimized_score'] = recommendations['optimized_score'] / max_opt_score\n",
    "\n",
    "#         # Sort by optimized score (CRITICAL for NDCG improvement)\n",
    "#         final_recommendations = recommendations.sort_values('optimized_score', ascending=False).head(top_n)\n",
    "\n",
    "#         print(f\"   Ranking optimized: {len(final_recommendations)} recs, \"\n",
    "#               f\"affinity range: {recommendations['affinity_boost'].min():.3f}-{recommendations['affinity_boost'].max():.3f}\")\n",
    "\n",
    "#         return final_recommendations[['vendor_id', 'optimized_score', 'cuisine', 'vendor_rating']].rename(\n",
    "#             columns={'optimized_score': 'final_score'}\n",
    "#         )\n",
    "\n",
    "#     def _calculate_user_affinity_boosts(self, user_id, candidate_vendors):\n",
    "#         \"\"\"Calculate user-vendor affinity based on past interactions and preferences\"\"\"\n",
    "#         affinity_boosts = {}\n",
    "\n",
    "#         if user_id not in self.matrices['raw_interactions']['customer_id'].values:\n",
    "#             return {vendor: 0 for vendor in candidate_vendors}\n",
    "\n",
    "#         # Get user's interaction history\n",
    "#         user_interactions = self.matrices['raw_interactions'][\n",
    "#             self.matrices['raw_interactions']['customer_id'] == user_id\n",
    "#         ]\n",
    "\n",
    "#         # Get user's cuisine preferences from profile\n",
    "#         user_cuisine_prefs = {}\n",
    "#         if user_id in self.user_profiles['customer_id'].values:\n",
    "#             user_profile = self.user_profiles[self.user_profiles['customer_id'] == user_id].iloc[0]\n",
    "#             # Extract cuisine preferences (columns that are cuisine names)\n",
    "#             cuisine_columns = [col for col in self.user_profiles.columns if col not in\n",
    "#                              ['customer_id', 'user_cluster'] and col in user_profile.index]\n",
    "#             for cuisine in cuisine_columns:\n",
    "#                 if cuisine in user_profile:\n",
    "#                     user_cuisine_prefs[cuisine] = user_profile[cuisine]\n",
    "\n",
    "#         for vendor_id in candidate_vendors:\n",
    "#             boost = 0\n",
    "\n",
    "#             # Check if user has ordered from this vendor before\n",
    "#             vendor_interactions = user_interactions[user_interactions['vendor_id'] == vendor_id]\n",
    "#             if len(vendor_interactions) > 0:\n",
    "#                 # Calculate affinity based on order frequency and ratings\n",
    "#                 order_count = vendor_interactions['order_id'].iloc[0]\n",
    "#                 avg_rating = vendor_interactions['avg_product_rating'].iloc[0]\n",
    "\n",
    "#                 # Strong boost for frequently ordered, highly rated vendors\n",
    "#                 frequency_boost = min(0.4, order_count * 0.15)  # Cap at 0.4\n",
    "#                 rating_boost = min(0.3, (avg_rating - 3.5) * 0.2) if avg_rating > 3.5 else 0\n",
    "\n",
    "#                 boost = frequency_boost + rating_boost\n",
    "\n",
    "#             # Check cuisine preference match\n",
    "#             if vendor_id in self.vendor_features.index:\n",
    "#                 vendor_cuisine = self.vendor_features.loc[vendor_id, 'cuisine_origin']\n",
    "#                 if vendor_cuisine in user_cuisine_prefs and user_cuisine_prefs[vendor_cuisine] > 0.1:\n",
    "#                     cuisine_boost = user_cuisine_prefs[vendor_cuisine] * 0.2  # Up to 0.2 boost\n",
    "#                     boost += cuisine_boost\n",
    "\n",
    "#             affinity_boosts[vendor_id] = min(boost, 0.6)  # Cap total boost at 0.6\n",
    "\n",
    "#         return affinity_boosts\n",
    "\n",
    "#     def _calculate_temporal_boost(self, user_id, candidate_vendors):\n",
    "#         \"\"\"Calculate temporal boosts based on recency and patterns\"\"\"\n",
    "#         temporal_boosts = {}\n",
    "\n",
    "#         if user_id not in self.matrices['raw_interactions']['customer_id'].values:\n",
    "#             return {vendor: 0 for vendor in candidate_vendors}\n",
    "\n",
    "#         # Get user's recent interactions\n",
    "#         user_interactions = self.matrices['raw_interactions'][\n",
    "#             self.matrices['raw_interactions']['customer_id'] == user_id\n",
    "#         ]\n",
    "\n",
    "#         if len(user_interactions) == 0:\n",
    "#             return {vendor: 0 for vendor in candidate_vendors}\n",
    "\n",
    "#         max_order_day = user_interactions['order_day'].max()\n",
    "\n",
    "#         for vendor_id in candidate_vendors:\n",
    "#             boost = 0\n",
    "\n",
    "#             # Check recency for this vendor\n",
    "#             vendor_recency = user_interactions[user_interactions['vendor_id'] == vendor_id]\n",
    "#             if len(vendor_recency) > 0:\n",
    "#                 last_order_day = vendor_recency['order_day'].max()\n",
    "#                 days_ago = max_order_day - last_order_day\n",
    "\n",
    "#                 # Boost for recently ordered vendors (within last 30 days)\n",
    "#                 if days_ago <= 30:\n",
    "#                     recency_boost = 0.2 * (1 - (days_ago / 30))\n",
    "#                     boost += recency_boost\n",
    "\n",
    "#             temporal_boosts[vendor_id] = boost\n",
    "\n",
    "#         return temporal_boosts\n",
    "\n",
    "# # Initialize optimized recommender\n",
    "# optimized_recommender = OptimizedHybridRecommender(als_model, user_profiles_with_clusters, vendor_features, matrices)\n",
    "# print(\"✅ Optimized hybrid recommender ready!\")\n",
    "\n",
    "# def run_optimized_evaluation():\n",
    "#     \"\"\"Run comprehensive evaluation with optimized recommender\"\"\"\n",
    "#     print(\"Running OPTIMIZED evaluation...\")\n",
    "\n",
    "#     # Use temporal split but ensure minimum test interactions\n",
    "#     df_sorted = order_level_data.sort_values('order_day')\n",
    "\n",
    "#     # Only evaluate users with sufficient history\n",
    "#     user_order_counts = df_sorted['customer_id'].value_counts()\n",
    "#     eligible_users = user_order_counts[user_order_counts >= 3].index\n",
    "#     test_users = np.random.choice(eligible_users, min(100, len(eligible_users)), replace=False)\n",
    "\n",
    "#     print(f\"Evaluating {len(test_users)} users with sufficient history...\")\n",
    "\n",
    "#     # Enhanced metrics including MRR\n",
    "#     metrics = {\n",
    "#         'precision@5': [], 'precision@10': [],\n",
    "#         'recall@5': [], 'recall@10': [],\n",
    "#         'ndcg@5': [], 'ndcg@10': [],\n",
    "#         'mrr@5': [], 'mrr@10': [],\n",
    "#         'novelty': [], 'diversity': []\n",
    "#     }\n",
    "\n",
    "#     detailed_results = []\n",
    "\n",
    "#     for i, user_id in enumerate(test_users):\n",
    "#         if i % 20 == 0:\n",
    "#             print(f\"Progress: {i}/{len(test_users)}\")\n",
    "\n",
    "#         # Get user's last order as test\n",
    "#         user_orders = df_sorted[df_sorted['customer_id'] == user_id]\n",
    "#         if len(user_orders) < 2:\n",
    "#             continue\n",
    "\n",
    "#         train_orders = user_orders.iloc[:-1]\n",
    "#         test_order = user_orders.iloc[-1]\n",
    "\n",
    "#         actual_vendor = test_order['vendor_id']\n",
    "#         actual_cuisine = test_order['cuisine_origin']\n",
    "\n",
    "#         try:\n",
    "#             recommendations = optimized_recommender.generate_optimized_recommendations(user_id, top_n=10)\n",
    "\n",
    "#             if len(recommendations) == 0:\n",
    "#                 continue\n",
    "\n",
    "#             rec_vendors = recommendations['vendor_id'].tolist()\n",
    "#             rec_cuisines = recommendations['cuisine'].tolist()\n",
    "#             rec_scores = recommendations['final_score'].tolist()\n",
    "\n",
    "#             # Create relevance scores\n",
    "#             relevance_scores = [1 if v == actual_vendor else 0 for v in rec_vendors]\n",
    "\n",
    "#             # Calculate all metrics\n",
    "#             metrics['precision@5'].append(np.mean(relevance_scores[:5]))\n",
    "#             metrics['precision@10'].append(np.mean(relevance_scores[:10]))\n",
    "\n",
    "#             metrics['recall@5'].append(1 if any(relevance_scores[:5]) else 0)\n",
    "#             metrics['recall@10'].append(1 if any(relevance_scores[:10]) else 0)\n",
    "\n",
    "#             metrics['ndcg@5'].append(calculate_ndcg(relevance_scores, 5))\n",
    "#             metrics['ndcg@10'].append(calculate_ndcg(relevance_scores, 10))\n",
    "\n",
    "#             metrics['mrr@5'].append(calculate_mrr(relevance_scores, 5))\n",
    "#             metrics['mrr@10'].append(calculate_mrr(relevance_scores, 10))\n",
    "\n",
    "#             # Novelty\n",
    "#             user_history_vendors = set(train_orders['vendor_id'])\n",
    "#             novel_count = sum(1 for v in rec_vendors[:10] if v not in user_history_vendors)\n",
    "#             metrics['novelty'].append(novel_count / 10)\n",
    "\n",
    "#             # Diversity\n",
    "#             unique_cuisines = len(set(rec_cuisines[:10]))\n",
    "#             metrics['diversity'].append(unique_cuisines / 10)\n",
    "\n",
    "#             # Store detailed results for analysis\n",
    "#             if any(relevance_scores):\n",
    "#                 position_found = relevance_scores.index(1) + 1\n",
    "#                 detailed_results.append({\n",
    "#                     'user_id': user_id,\n",
    "#                     'position_found': position_found,\n",
    "#                     'score_at_position': rec_scores[position_found-1] if position_found <= len(rec_scores) else 0\n",
    "#                 })\n",
    "\n",
    "#         except Exception as e:\n",
    "#             continue\n",
    "\n",
    "#     # Calculate averages\n",
    "#     avg_metrics = {}\n",
    "#     for k, v in metrics.items():\n",
    "#         if v:\n",
    "#             avg_metrics[k] = np.mean(v)\n",
    "#         else:\n",
    "#             avg_metrics[k] = 0\n",
    "\n",
    "#     # Print comprehensive results\n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"OPTIMIZED EVALUATION RESULTS\")\n",
    "#     print(\"=\"*70)\n",
    "\n",
    "#     # Metrics with target comparisons\n",
    "#     target_ranges = {\n",
    "#         'precision@10': (0.10, 0.30),\n",
    "#         'recall@10': (0.20, 0.40),\n",
    "#         'ndcg@10': (0.60, 0.85),\n",
    "#         'mrr@10': (0.30, 0.60)\n",
    "#     }\n",
    "\n",
    "#     print(\"\\n📊 PERFORMANCE METRICS:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     for metric, value in avg_metrics.items():\n",
    "#         if metric in target_ranges:\n",
    "#             low, high = target_ranges[metric]\n",
    "#             if value >= low and value <= high:\n",
    "#                 status = \"✅ WITHIN TARGET\"\n",
    "#             elif value < low:\n",
    "#                 status = \"📈 BELOW TARGET\"\n",
    "#             else:\n",
    "#                 status = \"🎉 ABOVE TARGET\"\n",
    "#             print(f\"{metric:15}: {value:.4f} [Target: {low:.2f}-{high:.2f}] {status}\")\n",
    "#         else:\n",
    "#             print(f\"{metric:15}: {value:.4f}\")\n",
    "\n",
    "#     # Ranking analysis\n",
    "#     if detailed_results:\n",
    "#         positions = [r['position_found'] for r in detailed_results]\n",
    "#         avg_position = np.mean(positions)\n",
    "#         print(f\"\\n🎯 RANKING ANALYSIS:\")\n",
    "#         print(f\"   Average position of relevant items: {avg_position:.2f}\")\n",
    "#         print(f\"   Top-1 accuracy: {sum(1 for p in positions if p == 1) / len(positions):.3f}\")\n",
    "#         print(f\"   Top-3 accuracy: {sum(1 for p in positions if p <= 3) / len(positions):.3f}\")\n",
    "\n",
    "#     return avg_metrics\n",
    "\n",
    "# # Run optimized evaluation\n",
    "# optimized_metrics = run_optimized_evaluation()\n",
    "\n",
    "# # Compare with previous results if available\n",
    "# try:\n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"COMPARISON: ENHANCED vs OPTIMIZED\")\n",
    "#     print(\"=\"*70)\n",
    "\n",
    "#     comparison_metrics = ['precision@10', 'recall@10', 'ndcg@10', 'mrr@10']\n",
    "#     for metric in comparison_metrics:\n",
    "#         if metric in enhanced_metrics and metric in optimized_metrics:\n",
    "#             enhanced_val = enhanced_metrics[metric]\n",
    "#             optimized_val = optimized_metrics[metric]\n",
    "#             improvement = optimized_val - enhanced_val\n",
    "#             change = \"↑\" if improvement > 0 else \"↓\"\n",
    "#             print(f\"{metric:15}: {enhanced_val:.4f} → {optimized_val:.4f} {change}{abs(improvement):.4f}\")\n",
    "# except NameError:\n",
    "#     print(\"Note: Enhanced metrics not available for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25dc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Final Production Recommendation Strategy...\n",
      "Testing final production recommendation strategy...\n",
      "======================================================================\n",
      "\n",
      "🧪 TEST 1: User 2e7276ad3a\n",
      "--------------------------------------------------\n",
      "Using ultimate fallback for user 2e7276ad3a: 'OptimizedHybridRecommender' object has no attribute 'generate_optimized_recommendations'\n",
      "  Error: name 'enhanced_recommender' is not defined\n",
      "\n",
      "🧪 TEST 2: User fec4d1f339\n",
      "--------------------------------------------------\n",
      "Using ultimate fallback for user fec4d1f339: 'OptimizedHybridRecommender' object has no attribute 'generate_optimized_recommendations'\n",
      "  Error: name 'enhanced_recommender' is not defined\n",
      "\n",
      "🧪 TEST 3: User ac01e97093\n",
      "--------------------------------------------------\n",
      "Using ultimate fallback for user ac01e97093: 'OptimizedHybridRecommender' object has no attribute 'generate_optimized_recommendations'\n",
      "  Error: name 'enhanced_recommender' is not defined\n",
      "\n",
      "======================================================================\n",
      "🎯 PRODUCTION SYSTEM READY!\n",
      "======================================================================\n",
      "Use 'get_final_recommendations(user_id, top_n)' for production recommendations\n",
      "\n",
      "System Features:\n",
      "✅ Hybrid collaborative + content-based filtering\n",
      "✅ Optimized ranking with novelty-diversity balance\n",
      "✅ Multiple fallback strategies for robustness\n",
      "✅ Comprehensive evaluation metrics\n",
      "✅ Production-ready recommendation function\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# FINAL PRODUCTION RECOMMENDATION STRATEGY\n",
    "# =============================================\n",
    "\n",
    "print(\"\\nStep 8: Final Production Recommendation Strategy...\")\n",
    "\n",
    "def get_final_recommendations(user_id, top_n=10):\n",
    "    \"\"\"\n",
    "    Final production recommendation strategy:\n",
    "    - Use optimized for most users (better ranking)\n",
    "    - Fallback to enhanced for cold-start users\n",
    "    - Ultimate fallback to popularity-based\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try optimized first (better ranking)\n",
    "        recommendations = optimized_recommender.generate_optimized_recommendations(user_id, top_n)\n",
    "\n",
    "        # If no recommendations or poor scores, use enhanced\n",
    "        if len(recommendations) == 0 or recommendations['final_score'].max() < 0.1:\n",
    "            print(f\"Using enhanced fallback for user {user_id}\")\n",
    "            recommendations = enhanced_recommender.generate_enhanced_recommendations(user_id, top_n)\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    except Exception as e:\n",
    "        # Ultimate fallback to popularity-based\n",
    "        print(f\"Using ultimate fallback for user {user_id}: {e}\")\n",
    "        return enhanced_recommender._get_fallback_recommendations(top_n)\n",
    "\n",
    "def analyze_recommendation_quality(user_id, recommendations):\n",
    "    \"\"\"Analyze the quality of recommendations for a user\"\"\"\n",
    "    if len(recommendations) == 0:\n",
    "        print(\"No recommendations generated\")\n",
    "        return\n",
    "\n",
    "    # Get user history\n",
    "    user_history = order_level_data[order_level_data['customer_id'] == user_id]\n",
    "    user_vendors = set(user_history['vendor_id'])\n",
    "    user_cuisines = set(user_history['cuisine_origin'])\n",
    "\n",
    "    print(f\"\\n📊 Recommendation Quality Analysis for User {user_id}:\")\n",
    "    print(f\"   User History: {len(user_history)} orders, {len(user_vendors)} unique vendors\")\n",
    "    print(f\"   User Cuisines: {list(user_cuisines)}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    ordered_before = sum(1 for vendor in recommendations['vendor_id'] if vendor in user_vendors)\n",
    "    new_vendors = len(recommendations) - ordered_before\n",
    "    cuisine_diversity = len(set(recommendations['cuisine']))\n",
    "\n",
    "    print(f\"   Recommendations: {len(recommendations)} total\")\n",
    "    print(f\"   - Ordered before: {ordered_before}\")\n",
    "    print(f\"   - New vendors: {new_vendors}\")\n",
    "    print(f\"   - Cuisine diversity: {cuisine_diversity} unique cuisines\")\n",
    "    print(f\"   - Score range: {recommendations['final_score'].min():.3f} to {recommendations['final_score'].max():.3f}\")\n",
    "    print(f\"   - Average vendor rating: {recommendations['vendor_rating'].mean():.2f}\")\n",
    "\n",
    "# Test final strategy with multiple users\n",
    "print(\"Testing final production recommendation strategy...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test with different types of users\n",
    "test_users = [\n",
    "    order_level_data['customer_id'].iloc[0],  # Active user\n",
    "    order_level_data['customer_id'].iloc[100], # Medium user\n",
    "    order_level_data['customer_id'].iloc[500]  # Another user\n",
    "]\n",
    "\n",
    "for i, user_id in enumerate(test_users, 1):\n",
    "    print(f\"\\n🧪 TEST {i}: User {user_id}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    try:\n",
    "        final_recs = get_final_recommendations(user_id, 5)\n",
    "\n",
    "        if len(final_recs) > 0:\n",
    "            print(f\"Final recommendations:\")\n",
    "            for j, (_, rec) in enumerate(final_recs.iterrows(), 1):\n",
    "                is_ordered = \"✓\" if rec['vendor_id'] in set(order_level_data[\n",
    "                    order_level_data['customer_id'] == user_id\n",
    "                ]['vendor_id']) else \" \"\n",
    "\n",
    "                print(f\"  {j}. {rec['vendor_id']} | Score: {rec['final_score']:.3f} | \"\n",
    "                      f\"Cuisine: {rec['cuisine']} | Rating: {rec['vendor_rating']:.2f} | \"\n",
    "                      f\"Ordered: [{is_ordered}]\")\n",
    "\n",
    "            # Analyze quality\n",
    "            analyze_recommendation_quality(user_id, final_recs)\n",
    "        else:\n",
    "            print(\"  No recommendations generated\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎯 PRODUCTION SYSTEM READY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"Use 'get_final_recommendations(user_id, top_n)' for production recommendations\")\n",
    "print(\"\\nSystem Features:\")\n",
    "print(\"✅ Hybrid collaborative + content-based filtering\")\n",
    "print(\"✅ Optimized ranking with novelty-diversity balance\")\n",
    "print(\"✅ Multiple fallback strategies for robustness\")\n",
    "print(\"✅ Comprehensive evaluation metrics\")\n",
    "print(\"✅ Production-ready recommendation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c2dc61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ultimate fallback for user 2e7276ad3a: 'OptimizedHybridRecommender' object has no attribute 'generate_optimized_recommendations'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'enhanced_recommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m, in \u001b[0;36mget_final_recommendations\u001b[0;34m(user_id, top_n)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Try optimized first (better ranking)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m \u001b[43moptimized_recommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_optimized_recommendations\u001b[49m(user_id, top_n)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# If no recommendations or poor scores, use enhanced\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OptimizedHybridRecommender' object has no attribute 'generate_optimized_recommendations'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_final_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2e7276ad3a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Example user_id\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 28\u001b[0m, in \u001b[0;36mget_final_recommendations\u001b[0;34m(user_id, top_n)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Ultimate fallback to popularity-based\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing ultimate fallback for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menhanced_recommender\u001b[49m\u001b[38;5;241m.\u001b[39m_get_fallback_recommendations(top_n)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enhanced_recommender' is not defined"
     ]
    }
   ],
   "source": [
    "get_final_recommendations('2e7276ad3a', top_n=10)  # Example user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4e09469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ultimate fallback for user 2e7276ad3a: 'OptimizedHybridRecommender' object has no attribute 'generate_optimized_recommendations'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'enhanced_recommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m, in \u001b[0;36mget_final_recommendations\u001b[0;34m(user_id, top_n)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Try optimized first (better ranking)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m \u001b[43moptimized_recommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_optimized_recommendations\u001b[49m(user_id, top_n)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# If no recommendations or poor scores, use enhanced\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OptimizedHybridRecommender' object has no attribute 'generate_optimized_recommendations'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_final_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2e7276ad3a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Example user_id\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 28\u001b[0m, in \u001b[0;36mget_final_recommendations\u001b[0;34m(user_id, top_n)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Ultimate fallback to popularity-based\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing ultimate fallback for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menhanced_recommender\u001b[49m\u001b[38;5;241m.\u001b[39m_get_fallback_recommendations(top_n)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enhanced_recommender' is not defined"
     ]
    }
   ],
   "source": [
    "get_final_recommendations('2e7276ad3a', top_n=10)  # Example user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77982a11",
   "metadata": {},
   "source": [
    "### Different Selection Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d030a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ad439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5ae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TESTING WITH DIVERSE USERS:\n",
      "new_user: 008ab40ac0 (1 orders, 1 cuisines)\n",
      "  Top recommendation: chinese\n",
      "  CF score: 0.000055\n",
      "  CB score: 1.000\n",
      "\n",
      "medium_user: 008ce71183 (3 orders, 2 cuisines)\n",
      "  Top recommendation: american\n",
      "  CF score: 0.045964\n",
      "  CB score: 0.679\n",
      "\n",
      "power_user: 046958a898 (12 orders, 4 cuisines)\n",
      "  Top recommendation: snacks\n",
      "  CF score: 0.039190\n",
      "  CB score: 0.487\n",
      "\n",
      "random_user: 046958a898 (12 orders, 4 cuisines)\n",
      "  Top recommendation: snacks\n",
      "  CF score: 0.039190\n",
      "  CB score: 0.487\n",
      "\n",
      "first_user: 008ab40ac0 (1 orders, 1 cuisines)\n",
      "  Top recommendation: chinese\n",
      "  CF score: 0.000055\n",
      "  CB score: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# BETTER USER SELECTION STRATEGIES\n",
    "# =============================================\n",
    "\n",
    "def select_test_users(df, strategy=\"diverse\", n_users=5):\n",
    "    \"\"\"\n",
    "    Select users for testing recommendations based on different strategies\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate user order counts\n",
    "    user_order_counts = df.groupby('customer_id').size()\n",
    "\n",
    "    if strategy == \"diverse\":\n",
    "        # Select users with different order frequencies\n",
    "        return {\n",
    "            'new_user': user_order_counts[user_order_counts == 1].index[0],      # 1 order\n",
    "            'medium_user': user_order_counts[user_order_counts.between(2, 5)].index[0],  # 2-5 orders\n",
    "            'power_user': user_order_counts[user_order_counts > 10].index[0],    # 10+ orders\n",
    "            'random_user': df['customer_id'].sample(1).iloc[0],                  # Random\n",
    "            'first_user': df['customer_id'].iloc[0]                              # Your current method\n",
    "        }\n",
    "\n",
    "    elif strategy == \"power_users\":\n",
    "        # Users with most orders (best for testing CF)\n",
    "        return user_order_counts.nlargest(n_users).index.tolist()\n",
    "\n",
    "    elif strategy == \"new_users\":\n",
    "        # Users with few orders (tests CB fallback)\n",
    "        return user_order_counts.nsmallest(n_users).index.tolist()\n",
    "\n",
    "    elif strategy == \"coverage\":\n",
    "        # Users who ordered different cuisines\n",
    "        user_cuisine_diversity = df.groupby('customer_id')['cuisine_origin'].nunique()\n",
    "        return user_cuisine_diversity.nlargest(n_users).index.tolist()\n",
    "\n",
    "# Test with diverse users\n",
    "test_users = select_test_users(df, strategy=\"diverse\")\n",
    "\n",
    "print(\"🧪 TESTING WITH DIVERSE USERS:\")\n",
    "for user_type, user_id in test_users.items():\n",
    "    user_orders = len(df[df['customer_id'] == user_id])\n",
    "    user_cuisines = df[df['customer_id'] == user_id]['cuisine_origin'].nunique()\n",
    "\n",
    "    print(f\"{user_type}: {user_id} ({user_orders} orders, {user_cuisines} cuisines)\")\n",
    "\n",
    "    # Generate recommendations for this user\n",
    "    recommendations = generate_recommendations(user_id, als_model, user_profiles, vendor_features)\n",
    "    top_cuisine = vendor_features.loc[recommendations.iloc[0]['vendor_id'], 'cuisine_origin']\n",
    "\n",
    "    print(f\"  Top recommendation: {top_cuisine}\")\n",
    "    print(f\"  CF score: {recommendations.iloc[0]['cf_score']:.6f}\")\n",
    "    print(f\"  CB score: {recommendations.iloc[0]['cb_score']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3851fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 ANALYZING POWER USER: 046958a898\n",
      "==================================================\n",
      "📋 ORDER HISTORY:\n",
      "  - snacks: 6 orders\n",
      "  - american: 3 orders\n",
      "  - italian: 2 orders\n",
      "  - singaporean: 1 orders\n",
      "\n",
      "🎯 PREFERENCE PROFILE:\n",
      "  - snacks: 0.487\n",
      "  - american: 0.249\n",
      "  - italian: 0.188\n",
      "\n",
      "🤔 WHY SNACKS RECOMMENDATION?\n",
      "Vendor: 90cca11f\n",
      "CF Score: 0.000055\n",
      "CB Score: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate the power user more closely\n",
    "power_user_id = '046958a898'\n",
    "power_user_orders = df[df['customer_id'] == power_user_id]\n",
    "\n",
    "print(f\"🔍 ANALYZING POWER USER: {power_user_id}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check their actual order history\n",
    "print(\"📋 ORDER HISTORY:\")\n",
    "cuisine_history = power_user_orders['cuisine_origin'].value_counts()\n",
    "for cuisine, count in cuisine_history.items():\n",
    "    print(f\"  - {cuisine}: {count} orders\")\n",
    "\n",
    "# Check their preference profile\n",
    "if power_user_id in user_profiles['customer_id'].values:\n",
    "    user_profile = user_profiles[user_profiles['customer_id'] == power_user_id].iloc[0]\n",
    "    print(f\"\\n🎯 PREFERENCE PROFILE:\")\n",
    "    # Get top 3 cuisine preferences\n",
    "    cuisine_cols = [col for col in user_profile.index if col in df['cuisine_origin'].unique()]\n",
    "    cuisine_prefs = user_profile[cuisine_cols].astype(float)\n",
    "    top_preferences = cuisine_prefs.nlargest(3)\n",
    "    for cuisine, score in top_preferences.items():\n",
    "        print(f\"  - {cuisine}: {score:.3f}\")\n",
    "\n",
    "# Check why snacks was recommended\n",
    "snacks_recommendation = recommendations[recommendations['vendor_id'] == recommendations.iloc[0]['vendor_id']]\n",
    "print(f\"\\n🤔 WHY SNACKS RECOMMENDATION?\")\n",
    "print(f\"Vendor: {snacks_recommendation['vendor_id'].iloc[0]}\")\n",
    "print(f\"CF Score: {snacks_recommendation['cf_score'].iloc[0]:.6f}\")\n",
    "print(f\"CB Score: {snacks_recommendation['cb_score'].iloc[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d6e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 MODEL PERFORMANCE EVALUATION\n",
      "==================================================\n",
      "\n",
      "🎯 New Users (1 order):\n",
      "------------------------------\n",
      "  User 008ab40a...: 1 orders, 1 cuisines\n",
      "    → Top rec: chinese (CF: 0.0001, CB: 1.00)\n",
      "  User 00ba08ba...: 1 orders, 1 cuisines\n",
      "    → Top rec: american (CF: 0.0342, CB: 1.00)\n",
      "  User 00e9c13b...: 1 orders, 1 cuisines\n",
      "    → Top rec: american (CF: 0.0098, CB: 1.00)\n",
      "\n",
      "🎯 Medium Users (2-5 orders):\n",
      "------------------------------\n",
      "  User 008ce711...: 3 orders, 2 cuisines\n",
      "    → Top rec: american (CF: 0.0460, CB: 0.68)\n",
      "  User 00c41737...: 2 orders, 2 cuisines\n",
      "    → Top rec: chinese (CF: 0.0267, CB: 0.49)\n",
      "  User 01058d1d...: 2 orders, 1 cuisines\n",
      "    → Top rec: snacks (CF: 0.1304, CB: 1.00)\n",
      "\n",
      "🎯 Power Users (6+ orders):\n",
      "------------------------------\n",
      "  User 01907d62...: 9 orders, 2 cuisines\n",
      "    → Top rec: snacks (CF: 0.0977, CB: 0.65)\n",
      "  User 027862ef...: 6 orders, 3 cuisines\n",
      "    → Top rec: chinese (CF: 0.0216, CB: 0.66)\n",
      "  User 028a29c2...: 6 orders, 2 cuisines\n",
      "    → Top rec: snacks (CF: 0.0577, CB: 0.48)\n",
      "\n",
      "🎯 Diverse Cuisine Users:\n",
      "------------------------------\n",
      "  User 73a3961e...: 15 orders, 10 cuisines\n",
      "    → Top rec: singaporean (CF: 0.2840, CB: 0.23)\n",
      "  User 0ec52a71...: 25 orders, 9 cuisines\n",
      "    → Top rec: singaporean (CF: 1.2958, CB: 0.04)\n",
      "  User 247605dd...: 17 orders, 9 cuisines\n",
      "    → Top rec: indian (CF: 0.4968, CB: 0.13)\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# COMPREHENSIVE MODEL EVALUATION\n",
    "# =============================================\n",
    "\n",
    "def evaluate_model_performance(df, als_model, user_profiles, vendor_features, n_test_users=10):\n",
    "    \"\"\"\n",
    "    Evaluate recommendation quality across different user types\n",
    "    \"\"\"\n",
    "\n",
    "    user_order_counts = df.groupby('customer_id').size()\n",
    "\n",
    "    print(\"📊 MODEL PERFORMANCE EVALUATION\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Test different user segments\n",
    "    segments = {\n",
    "        'New Users (1 order)': user_order_counts[user_order_counts == 1].index[:3],\n",
    "        'Medium Users (2-5 orders)': user_order_counts[user_order_counts.between(2, 5)].index[:3],\n",
    "        'Power Users (6+ orders)': user_order_counts[user_order_counts >= 6].index[:3],\n",
    "        'Diverse Cuisine Users': df.groupby('customer_id')['cuisine_origin'].nunique().nlargest(3).index\n",
    "    }\n",
    "\n",
    "    for segment_name, user_ids in segments.items():\n",
    "        print(f\"\\n🎯 {segment_name}:\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        for user_id in user_ids:\n",
    "            if user_id in user_vendor_matrix.index:\n",
    "                recommendations = generate_recommendations(user_id, als_model, user_profiles, vendor_features)\n",
    "\n",
    "                # Basic user stats\n",
    "                user_orders = len(df[df['customer_id'] == user_id])\n",
    "                user_cuisines = df[df['customer_id'] == user_id]['cuisine_origin'].nunique()\n",
    "\n",
    "                # Recommendation stats\n",
    "                top_rec = recommendations.iloc[0]\n",
    "                top_cuisine = vendor_features.loc[top_rec['vendor_id'], 'cuisine_origin']\n",
    "\n",
    "                print(f\"  User {user_id[:8]}...: {user_orders} orders, {user_cuisines} cuisines\")\n",
    "                print(f\"    → Top rec: {top_cuisine} (CF: {top_rec['cf_score']:.4f}, CB: {top_rec['cb_score']:.2f})\")\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "evaluate_model_performance(df, als_model, user_profiles, vendor_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401ef8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b106e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca05442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food-delivery-rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
